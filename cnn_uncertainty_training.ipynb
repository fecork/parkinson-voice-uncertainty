{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac83061",
   "metadata": {},
   "source": [
    "# üß† CNN con Estimaci√≥n de Incertidumbre (Epist√©mica + Aleatoria)\n",
    "\n",
    "## Pipeline de Entrenamiento e Inferencia con Cuantificaci√≥n de Incertidumbre\n",
    "\n",
    "Este notebook implementa un modelo CNN con estimaci√≥n de dos tipos de incertidumbre:\n",
    "\n",
    "### üéØ Tipos de Incertidumbre:\n",
    "1. **Epist√©mica (modelo)**: Capturada con MC Dropout ‚Üí reducible con m√°s datos\n",
    "2. **Aleatoria (datos)**: Capturada con cabeza de varianza ‚Üí irreducible\n",
    "\n",
    "### üìã Pipeline:\n",
    "1. **Setup**: Configuraci√≥n del entorno\n",
    "2. **Data Loading**: Carga de datos desde cache (augmentados)\n",
    "3. **Split**: Train/Val/Test estratificado (70/15/15)\n",
    "4. **Model**: CNN con DOS cabezas (predicci√≥n + ruido)\n",
    "5. **Training**: P√©rdida heterosced√°stica con ruido gaussiano\n",
    "6. **Evaluation**: MC Dropout para epist√©mica + œÉ¬≤ para aleatoria\n",
    "7. **Visualization**: Histogramas, reliability plot, scatter\n",
    "\n",
    "### üèóÔ∏è Arquitectura:\n",
    "- **Backbone**: 2√ó bloques Conv2D ‚Üí BN ‚Üí ReLU ‚Üí MaxPool(3√ó3) ‚Üí Dropout\n",
    "- **Cabeza A**: Predicci√≥n (logits ‚àà ‚Ñù^C)\n",
    "- **Cabeza B**: Ruido de datos (s_logit = log œÉ¬≤ ‚àà ‚Ñù^C, clamped [-10, 3])\n",
    "- **MC Dropout**: Permanece activo en inferencia\n",
    "\n",
    "### ‚öôÔ∏è Entrenamiento:\n",
    "- **P√©rdida**: Heterosced√°stica (log-likelihood con ruido gaussiano)\n",
    "- **T_noise**: 5 muestras de ruido en entrenamiento\n",
    "- **Optimizer**: AdamW (lr=1e-3, wd=1e-4)\n",
    "- **Early stopping**: Por val_loss\n",
    "\n",
    "### üî¨ Inferencia:\n",
    "- **T_test**: 30-50 pasadas MC Dropout\n",
    "- **Epist√©mica**: BALD = H(pÃÑ) - mean H(p_t)\n",
    "- **Aleatoria**: mean œÉ¬≤_t\n",
    "- **Total**: Entrop√≠a H(pÃÑ)\n",
    "\n",
    "### ‚ö†Ô∏è PREREQUISITO:\n",
    "**Ejecutar primero `data_preprocessing.ipynb`** para generar el cache de datos preprocesados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0cbb6",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6356aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üß† CNN CON ESTIMACI√ìN DE INCERTIDUMBRE\n",
      "======================================================================\n",
      "‚úÖ Librer√≠as cargadas correctamente\n",
      "üîß Dispositivo: cpu\n",
      "üì¶ PyTorch: 2.8.0+cpu\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORTS Y CONFIGURACI√ìN\n",
    "# ============================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Agregar m√≥dulos propios al path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Importar m√≥dulos propios\n",
    "from modules.augmentation import create_augmented_dataset\n",
    "from modules.dataset import to_pytorch_tensors\n",
    "from modules.uncertainty_model import UncertaintyCNN, print_uncertainty_model_summary\n",
    "from modules.uncertainty_training import train_uncertainty_model, evaluate_with_uncertainty, print_uncertainty_results\n",
    "from modules.uncertainty_visualization import (\n",
    "    plot_uncertainty_histograms,\n",
    "    plot_reliability_diagram,\n",
    "    plot_uncertainty_scatter,\n",
    "    plot_training_history_uncertainty\n",
    ")\n",
    "from modules.cnn_utils import plot_confusion_matrix\n",
    "\n",
    "# Configuraci√≥n de matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Configuraci√≥n de PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Reporte de configuraci√≥n\n",
    "print(\"=\"*70)\n",
    "print(\"üß† CNN CON ESTIMACI√ìN DE INCERTIDUMBRE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Librer√≠as cargadas correctamente\")\n",
    "print(f\"üîß Dispositivo: {device}\")\n",
    "print(f\"üì¶ PyTorch: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2f73e",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79663463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìÅ CARGANDO DATOS DESDE CACHE\n",
      "======================================================================\n",
      "\n",
      "‚öôÔ∏è  Configuraci√≥n:\n",
      "   ‚Ä¢ Augmentation: original, pitch_shift, time_stretch, noise\n",
      "   ‚Ä¢ SpecAugment versions: 2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURACI√ìN DE RUTAS\n",
    "# ============================================================\n",
    "\n",
    "DATA_PATH_HEALTHY = \"./data/vowels_healthy\"\n",
    "DATA_PATH_PARKINSON = \"./data/vowels_pk\"\n",
    "CACHE_DIR_HEALTHY = \"./cache/healthy\"\n",
    "CACHE_DIR_PARKINSON = \"./cache/parkinson\"\n",
    "\n",
    "# Configuraci√≥n de augmentation\n",
    "AUGMENTATION_TYPES = [\"original\", \"pitch_shift\", \"time_stretch\", \"noise\"]\n",
    "NUM_SPEC_AUGMENT_VERSIONS = 2\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìÅ CARGANDO DATOS DESDE CACHE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚öôÔ∏è  Configuraci√≥n:\")\n",
    "print(f\"   ‚Ä¢ Augmentation: {', '.join(AUGMENTATION_TYPES)}\")\n",
    "print(f\"   ‚Ä¢ SpecAugment versions: {NUM_SPEC_AUGMENT_VERSIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5bf30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ CARGANDO HEALTHY...\n",
      "============================================================\n",
      "   Archivos encontrados: 13\n",
      "üíæ Cargando dataset desde cache...\n",
      "   üìÅ ./cache/healthy\\augmented_dataset_c6631e32.pkl\n",
      "‚úÖ Cache cargado exitosamente: 1553 muestras\n",
      "‚ö° Tiempo ahorrado: ~6.5 min\n",
      "üìä PyTorch tensors listos:\n",
      "  - X: (1553, 1, 65, 41)\n",
      "  - y_task: (1553,)  (dist={0: 1553})\n",
      "  - y_domain: (1553,)  (K dominios=13)\n",
      "\n",
      "‚úÖ Healthy cargado:\n",
      "   ‚Ä¢ Muestras: 1553\n",
      "   ‚Ä¢ Shape: torch.Size([1553, 1, 65, 41])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CARGAR DATOS HEALTHY\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nüü¢ CARGANDO HEALTHY...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "audio_files_healthy = list(Path(DATA_PATH_HEALTHY).glob(\"*.egg\"))\n",
    "print(f\"   Archivos encontrados: {len(audio_files_healthy)}\")\n",
    "\n",
    "augmented_dataset_healthy = create_augmented_dataset(\n",
    "    audio_files_healthy,\n",
    "    augmentation_types=AUGMENTATION_TYPES,\n",
    "    apply_spec_augment=True,\n",
    "    num_spec_augment_versions=NUM_SPEC_AUGMENT_VERSIONS,\n",
    "    use_cache=True,\n",
    "    cache_dir=CACHE_DIR_HEALTHY,\n",
    "    force_regenerate=False,\n",
    "    progress_every=5\n",
    ")\n",
    "\n",
    "X_healthy, y_task_healthy, y_domain_healthy, meta_healthy = to_pytorch_tensors(\n",
    "    augmented_dataset_healthy\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Healthy cargado:\")\n",
    "print(f\"   ‚Ä¢ Muestras: {X_healthy.shape[0]}\")\n",
    "print(f\"   ‚Ä¢ Shape: {X_healthy.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466afc6",
   "metadata": {},
   "source": [
    "## 3. Modelo con Incertidumbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f11f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESUMEN DEL MODELO CON INCERTIDUMBRE\n",
      "============================================================\n",
      "UncertaintyCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): MCDropout2d()\n",
      "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (9): MCDropout2d()\n",
      "    (10): AdaptiveAvgPool2d(output_size=1)\n",
      "    (11): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (head_logits): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MCDropout()\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (head_noise): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MCDropout()\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "------------------------------------------------------------\n",
      "Par√°metros totales: 27,588\n",
      "Par√°metros entrenables: 27,588\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear modelo con dos cabezas\n",
    "model = UncertaintyCNN(\n",
    "    n_classes=2,\n",
    "    p_drop_conv=0.25,\n",
    "    p_drop_fc=0.25,\n",
    "    input_shape=(65, 41),\n",
    "    s_min=-10.0,\n",
    "    s_max=3.0\n",
    ").to(device)\n",
    "\n",
    "print_uncertainty_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038904d",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57208d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar con p√©rdida heterosced√°stica\n",
    "# (continuar con el resto del flujo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parkinson_env",
   "language": "python",
   "name": "parkinson_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
