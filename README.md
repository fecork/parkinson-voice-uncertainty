# üß† Parkinson Voice Uncertainty - Sistema de Detecci√≥n con Incertidumbre

Sistema completo de detecci√≥n de Parkinson mediante an√°lisis de voz usando redes neuronales convolucionales con **cuantificaci√≥n de incertidumbre** y **optimizaci√≥n autom√°tica de hiperpar√°metros**.

## üéØ Objetivo del Proyecto

Implementar un sistema de clasificaci√≥n binaria (Healthy vs Parkinson) usando:
- **CNN2D** con optimizaci√≥n autom√°tica de hiperpar√°metros (Talos)
- **Cuantificaci√≥n de incertidumbre** (Epistemic + Aleatoric)
- **Explicabilidad** mediante GradCAM
- **Data Augmentation** para mejorar generalizaci√≥n

## üöÄ Instalaci√≥n R√°pida

### Opci√≥n 1: Instalaci√≥n Autom√°tica
```bash
# Clonar el repositorio
git clone <repository-url>
cd parkinson-voice-uncertainty

# Instalar dependencias autom√°ticamente
python install_dependencies.py

# O instalar manualmente
pip install -r requirements.txt
```

### Opci√≥n 2: Google Colab con Git
```python
# Setup completo en Colab con Drive y Git
from modules.core.notebook_setup import setup_colab_git

# Configuraci√≥n por defecto (ZenBook, main branch)
project_path = setup_colab_git()

# Configuraci√≥n personalizada
project_path = setup_colab_git(
    computer_name="MiPC",
    project_dir="parkinson-voice-uncertainty",
    branch="dev"
)
```

Esta funci√≥n:
- Monta Google Drive autom√°ticamente
- Configura Git y cambia a la rama especificada
- Instala todas las dependencias del `requirements.txt`
- Activa autoreload para notebooks
- Retorna la ruta del proyecto configurado

### Opci√≥n 3: Configuraci√≥n Autom√°tica en Notebooks (Local)
```python
# Al inicio de cualquier notebook, usar:
from modules.core.dependency_manager import setup_notebook_environment

# Configurar entorno autom√°ticamente
setup_notebook_environment()
```

## üîß Gesti√≥n de Dependencias

El proyecto incluye un **sistema centralizado de gesti√≥n de dependencias** que:

- ‚úÖ **Detecta autom√°ticamente** el entorno (Colab vs Local)
- ‚úÖ **Instala dependencias faltantes** autom√°ticamente
- ‚úÖ **Evita duplicidad de c√≥digo** entre notebooks
- ‚úÖ **Maneja errores** de instalaci√≥n gracefully

### M√≥dulos Principales:
- `modules/core/dependency_manager.py` - Gesti√≥n centralizada
- `modules/core/notebook_setup.py` - Plantilla para notebooks
- `install_dependencies.py` - Script de instalaci√≥n
- `requirements.txt` - Lista de dependencias

## üìã Notebooks Principales

---

## üìã Orden de Ejecuci√≥n (OBLIGATORIO)

### 0Ô∏è‚É£ **`svdd_data_preparation.ipynb`** - Preparaci√≥n de Datos SVDD (OPCIONAL)
### 1Ô∏è‚É£ **`data_preprocessing.ipynb`** - Preprocesamiento de Datos
### 2Ô∏è‚É£ **`data_augmentation.ipynb`** - Augmentation de Datos  
### 3Ô∏è‚É£ **`cnn_training.ipynb`** - Entrenamiento CNN2D con Talos (NUEVO)
### 4Ô∏è‚É£ **`cnn_uncertainty_training.ipynb`** - Entrenamiento con Incertidumbre
### 5Ô∏è‚É£ **`gradcam_inference.ipynb`** - Visualizaci√≥n GradCAM

---

## üìñ Documentaci√≥n Detallada por Notebook

### 0Ô∏è‚É£ **`svdd_data_preparation.ipynb`** - Preparaci√≥n de Datos SVDD (OPCIONAL)

#### üéØ **¬øQu√© hace?**
Prepara y organiza el dataset SVDD (Saarbr√ºcken Voice Database) desde archivos ZIP anidados, filtrando solo archivos de vocal `/a/` y creando un dataset balanceado para entrenamiento.

#### üìö **Base Cient√≠fica**
- **Dataset**: SVDD - Saarbr√ºcken Voice Database
- **Prop√≥sito**: Expandir el dataset con voces patol√≥gicas y sanas adicionales
- **Metodolog√≠a**: Filtrado por vocal /a/, conversi√≥n NSP‚ÜíWAV, balanceado de clases

#### ‚öôÔ∏è **Pipeline de Preparaci√≥n**
1. **Exploraci√≥n**: An√°lisis de estructura de ZIPs anidados
2. **Filtrado**: Solo archivos `.nsp` con vocal `/a/` (patr√≥n `-a_` o `a.`)
3. **Extracci√≥n**: Conversi√≥n de archivos `.nsp` a `.wav` (44.1 kHz mono)
4. **Balanceado**: Distribuci√≥n equitativa entre Healthy y Pathological
5. **Organizaci√≥n**: Estructura final `/data/svdd_processed/`

#### üìä **¬øQu√© deber√≠a ver?**
- **Exploraci√≥n de ZIPs**: Lista de patolog√≠as encontradas
- **Progreso de extracci√≥n**: Archivos procesados por patolog√≠a
- **Estad√≠sticas de balance**: Conteo de archivos por clase
- **Estructura final**: `/data/svdd_processed/healthy/` y `/data/svdd_processed/pathological/`
- **Metadata**: `metadata.json` con informaci√≥n del proceso

#### ‚è±Ô∏è **Tiempo estimado**: 30-60 minutos (dependiendo del tama√±o del ZIP)

#### ‚úÖ **Indicadores de √©xito**:
- Archivos `.wav` generados en `/data/svdd_processed/`
- Balance aproximado entre clases (Healthy vs Pathological)
- Metadata JSON generado con estad√≠sticas
- Proceso resumible (puede continuar si se interrumpe)

#### üîß **Configuraci√≥n Requerida**:
```python
# Ruta al ZIP de SVDD (cambiar seg√∫n ubicaci√≥n)
ZIP_PATH = r"C:\Users\fecor\Downloads\16874898.zip"

# Patr√≥n para filtrar vocal /a/
VOWEL_PATTERN = r'-a_|a\.'

# Par√°metros de audio
TARGET_SAMPLE_RATE = 44100  # 44.1 kHz
```

#### üìÅ **Estructura de Salida**:
```
data/svdd_processed/
‚îú‚îÄ‚îÄ healthy/
‚îÇ   ‚îú‚îÄ‚îÄ archivo1.wav
‚îÇ   ‚îú‚îÄ‚îÄ archivo2.wav
‚îÇ   ‚îî‚îÄ‚îÄ ... (archivos de voces sanas)
‚îú‚îÄ‚îÄ pathological/
‚îÇ   ‚îú‚îÄ‚îÄ archivo1.wav
‚îÇ   ‚îú‚îÄ‚îÄ archivo2.wav
‚îÇ   ‚îî‚îÄ‚îÄ ... (archivos de voces patol√≥gicas)
‚îî‚îÄ‚îÄ metadata.json
```

#### üö® **Notas Importantes**:
- **Proceso resumible**: Si se interrumpe, puede continuar desde donde se qued√≥
- **Filtrado autom√°tico**: Solo procesa archivos con vocal `/a/`
- **Balanceado inteligente**: Distribuye muestras de diferentes patolog√≠as
- **Saltar data.zip**: Autom√°ticamente salta el ZIP problem√°tico

---

### 1Ô∏è‚É£ **`data_preprocessing.ipynb`** - Preprocesamiento de Datos

#### üéØ **¬øQu√© hace?**
Implementa el **preprocesamiento exacto** seg√∫n el paper de Ibarra et al. (2023) para convertir archivos de audio (.egg) en espectrogramas Mel normalizados.

#### üìö **Base Cient√≠fica**
- **Paper**: Ibarra et al. (2023) - "Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"
- **Metodolog√≠a**: Pipeline exacto sin augmentation para reproducibilidad

#### ‚öôÔ∏è **Pipeline de Preprocesamiento**
1. **Resample**: 44.1 kHz (est√°ndar de audio)
2. **Normalizaci√≥n**: Por amplitud m√°xima absoluta
3. **Segmentaci√≥n**: Ventanas de 400ms con 50% overlap (200ms hop)
4. **Mel Spectrogram**: 65 bandas Mel, ventana FFT 40ms, hop 10ms
5. **Conversi√≥n**: Amplitud a dB (logar√≠tmica)
6. **Normalizaci√≥n**: Z-score por espectrograma individual
7. **Dimensi√≥n final**: 65√ó41 p√≠xeles

#### üìä **¬øQu√© deber√≠a ver?**
- **Gr√°ficas de audio**: Formas de onda originales
- **Espectrogramas**: Visualizaci√≥n Mel antes/despu√©s de normalizaci√≥n
- **Estad√≠sticas**: Dimensiones, rangos de valores, distribuci√≥n
- **Cache generado**: `cache/original/healthy_ibarra.pkl` y `cache/original/parkinson_ibarra.pkl`

#### ‚è±Ô∏è **Tiempo estimado**: 2-3 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Cache generado correctamente
- Espectrogramas con dimensi√≥n 65√ó41
- Valores normalizados (media‚âà0, std‚âà1)

---

### 2Ô∏è‚É£ **`data_augmentation.ipynb`** - Augmentation de Datos

#### üéØ **¬øQu√© hace?**
Aplica **SpecAugment** a los datos Parkinson para mejorar el balance de clases y robustez del modelo.

#### üìö **Base Cient√≠fica**
- **Paper**: Park et al. (2019) - "SpecAugment: A Simple Data Augmentation Method for ASR"
- **T√©cnica**: M√°scaras de frecuencia y tiempo en espectrogramas

#### ‚öôÔ∏è **Pipeline de Augmentation**
1. **Carga datos**: Desde cache preprocesado
2. **SpecAugment**: M√°scaras conservadoras (freq=8, time=4)
3. **Generaci√≥n**: 2 versiones augmentadas por espectrograma original
4. **Guardado**: Dataset augmentado reutilizable

#### üìä **¬øQu√© deber√≠a ver?**
- **Espectrogramas originales vs augmentados**: Comparaci√≥n visual
- **M√°scaras aplicadas**: Visualizaci√≥n de las m√°scaras de SpecAugment
- **Estad√≠sticas de balance**: Conteo de muestras por clase
- **Cache generado**: `cache/augmented/augmented_dataset_specaugment.pkl`

#### ‚è±Ô∏è **Tiempo estimado**: 1-2 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Balance mejorado (m√°s muestras Parkinson)
- Espectrogramas augmentados visualmente diferentes
- Cache augmentado generado

---

### 3Ô∏è‚É£ **`cnn_uncertainty_training.ipynb`** - Entrenamiento con Incertidumbre

#### üéØ **¬øQu√© hace?**
Entrena una CNN con **dos tipos de incertidumbre**: epist√©mica (modelo) y aleatoria (datos) seg√∫n Kendall & Gal (2017).

#### üìö **Base Cient√≠fica**
- **Paper**: Kendall & Gal (2017) - "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?"
- **T√©cnica**: Heteroscedastic loss + MC Dropout

#### üèóÔ∏è **Arquitectura CNN**
```
Input: (B, 1, 65, 41) espectrograma
‚Üì
[Feature Extractor - Ibarra 2023]
Block1: Conv2D(32, 3√ó3) ‚Üí BN ‚Üí ReLU ‚Üí MaxPool(3√ó3) ‚Üí Dropout
Block2: Conv2D(64, 3√ó3) ‚Üí BN ‚Üí ReLU ‚Üí MaxPool(3√ó3) ‚Üí Dropout
‚Üì
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Prediction Head]       ‚îÇ [Noise Head]            ‚îÇ
‚îÇ FC(64) ‚Üí ReLU ‚Üí FC(2)  ‚îÇ FC(64) ‚Üí ReLU ‚Üí FC(2)   ‚îÇ
‚îÇ ‚Üì                       ‚îÇ ‚Üì                       ‚îÇ
‚îÇ logits (predicci√≥n)     ‚îÇ s_logit (ruido)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### üßÆ **Matem√°tica de Incertidumbre**
1. **Epist√©mica (BALD)**: `H(pÃÑ) - E[H(p_t)]` - Incertidumbre del modelo
2. **Aleatoria**: `E[H(p_t)]` - Incertidumbre de los datos
3. **Total**: `H(pÃÑ) = Epist√©mica + Aleatoria`
4. **Ruido**: `œÉ = exp(0.5 * s_logit)` - Desviaci√≥n est√°ndar

#### üìä **¬øQu√© deber√≠a ver?**
- **Curvas de entrenamiento**: Loss, accuracy, F1-score
- **Matriz de confusi√≥n**: Rendimiento por clase
- **Histogramas de incertidumbre**: Distribuci√≥n de incertidumbre por clase
- **Reliability diagram**: Calibraci√≥n del modelo
- **Scatter plot**: Incertidumbre vs accuracy
- **Modelo guardado**: `results/cnn_uncertainty/best_model_uncertainty.pth`

#### ‚è±Ô∏è **Tiempo estimado**: 15-20 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Accuracy > 95%
- Incertidumbre mayor en predicciones incorrectas
- Modelo bien calibrado (reliability diagram)

---

### 4Ô∏è‚É£ **`gradcam_inference.ipynb`** - Visualizaci√≥n GradCAM

#### üéØ **¬øQu√© hace?**
Genera **mapas de explicabilidad** usando GradCAM para entender qu√© regiones del espectrograma son importantes para la decisi√≥n del modelo.

#### üìö **Base Cient√≠fica**
- **Paper**: Selvaraju et al. (2017) - "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
- **T√©cnica**: Gradient-weighted Class Activation Mapping

#### üßÆ **Matem√°tica de GradCAM**
1. **Forward pass**: Obtener activaciones de la √∫ltima capa convolucional
2. **Backward pass**: Calcular gradientes de la clase objetivo
3. **Global Average Pooling**: `w = GAP(‚àÇy/‚àÇA)`
4. **Combinaci√≥n ponderada**: `CAM = ReLU(Œ£ w * A)`
5. **Normalizaci√≥n**: `CAM = (CAM - min) / (max - min)`

#### üìä **¬øQu√© deber√≠a ver?**
- **Espectrogramas originales**: Datos de entrada
- **Mapas GradCAM**: Regiones importantes (colores c√°lidos)
- **Superposiciones**: GradCAM sobre espectrograma original
- **Comparaci√≥n por clase**: Diferencias entre Healthy vs Parkinson
- **An√°lisis de casos**: Predicciones correctas vs incorrectas

#### ‚è±Ô∏è **Tiempo estimado**: 5-10 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Mapas GradCAM coherentes (regiones importantes)
- Diferencias claras entre clases
- Explicaciones visuales interpretables

---

## üîß Configuraci√≥n del Entorno

### Prerequisitos
```bash
# Instalar dependencias
pip install -r requirements.txt

# Verificar que los datos est√°n en data/
ls data/vowels_healthy/  # Archivos .egg de sujetos sanos
ls data/vowels_pk/       # Archivos .egg de pacientes Parkinson
```

### Estructura de Datos Requerida

#### **Datos B√°sicos (Requeridos)**
```
data/
‚îú‚îÄ‚îÄ vowels_healthy/     # Archivos .egg de sujetos sanos
‚îÇ   ‚îú‚îÄ‚îÄ 1022-a_lhl-egg.egg
‚îÇ   ‚îú‚îÄ‚îÄ 103-u_n-egg.egg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ vowels_pk/          # Archivos .egg de pacientes Parkinson
    ‚îú‚îÄ‚îÄ 1580-a_h-egg.egg
    ‚îú‚îÄ‚îÄ 1580-a_l-egg.egg
    ‚îî‚îÄ‚îÄ ...
```

#### **Datos SVDD (Opcionales - se generan con svdd_data_preparation.ipynb)**
```
data/
‚îî‚îÄ‚îÄ svdd_processed/       # Dataset SVDD procesado
    ‚îú‚îÄ‚îÄ healthy/          # Archivos .wav de voces sanas SVDD
    ‚îÇ   ‚îú‚îÄ‚îÄ archivo1.wav
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ pathological/     # Archivos .wav de voces patol√≥gicas SVDD
    ‚îÇ   ‚îú‚îÄ‚îÄ archivo1.wav
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ metadata.json     # Metadata del proceso SVDD
```

---

## üìä Resultados Esperados

### Despu√©s del Notebook 0 (Preparaci√≥n SVDD - OPCIONAL)
- **Dataset SVDD**: `/data/svdd_processed/` con archivos `.wav`
- **Balance de clases**: Healthy vs Pathological
- **Metadata**: `metadata.json` con estad√≠sticas del proceso
- **Tiempo**: ~30-60 minutos

### Despu√©s del Notebook 1 (Preprocesamiento)
- **Cache generado**: `cache/original/`
- **Espectrogramas**: 65√ó41 p√≠xeles, normalizados
- **Tiempo**: ~2-3 minutos

### Despu√©s del Notebook 2 (Augmentation)
- **Cache augmentado**: `cache/augmented/`
- **Balance mejorado**: +200% muestras Parkinson
- **Tiempo**: ~1-2 minutos

### Despu√©s del Notebook 3 (Entrenamiento)
- **Modelo entrenado**: `results/cnn_uncertainty/`
- **Accuracy**: >95%
- **Incertidumbre cuantificada**: Epist√©mica + Aleatoria
- **Tiempo**: ~15-20 minutos

### Despu√©s del Notebook 4 (GradCAM)
- **Mapas de explicabilidad**: `results/cnn_uncertainty/gradcam_outputs/`
- **Visualizaciones**: Espectrogramas + GradCAM
- **Tiempo**: ~5-10 minutos

---

## üö® Troubleshooting

### Error: "Cache not found"
**Soluci√≥n**: Ejecutar `data_preprocessing.ipynb` primero

### Error: "Model not found"
**Soluci√≥n**: Ejecutar `cnn_uncertainty_training.ipynb` primero

### Error: "Out of memory"
**Soluci√≥n**: Reducir `BATCH_SIZE` en el notebook de entrenamiento

### Error: "ImportError"
**Soluci√≥n**: Verificar que est√°s en la ra√≠z del proyecto

### Error: "ZIP not found" (SVDD)
**Soluci√≥n**: Verificar que `ZIP_PATH` apunta al archivo correcto en `svdd_data_preparation.ipynb`

### Error: "Proceso SVDD se interrumpe"
**Soluci√≥n**: El notebook es resumible, simplemente ejecutarlo nuevamente continuar√° desde donde se qued√≥

---

## üìö Referencias Cient√≠ficas

1. **Ibarra et al. (2023)**: "Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"
2. **Kendall & Gal (2017)**: "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?"
3. **Selvaraju et al. (2017)**: "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
4. **Park et al. (2019)**: "SpecAugment: A Simple Data Augmentation Method for ASR"

---

## üéØ Pruebas Unitarias


# 1. Validar notebook actual
python test/validate_paper_replication.py research/cnn_training.ipynb

# 2. Ejecutar pruebas unitarias
pytest test/test_paper_compliance.py -v

python -m pytest test/test_talos_*.py -v --tb=short

# 3. Ver reporte detallado
cat test/PAPER_VALIDATION_REPORT.md

---

**Autor**: Wilberth Ferney C√≥rdoba Canchala  
**Fecha**: 2025-01-21  
**Versi√≥n**: 4.0 (CNN + Uncertainty + GradCAM)  
