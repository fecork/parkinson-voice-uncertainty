# üìì Notebooks Principales - Gu√≠a de Ejecuci√≥n

Esta carpeta contiene los **4 notebooks principales** que deben ejecutarse en orden para el proyecto de detecci√≥n de Parkinson mediante an√°lisis de voz.

## üéØ Objetivo del Proyecto

Implementar un sistema de clasificaci√≥n binaria (Healthy vs Parkinson) usando redes neuronales convolucionales con **cuantificaci√≥n de incertidumbre** y **explicabilidad** mediante GradCAM.

---

## üìã Orden de Ejecuci√≥n (OBLIGATORIO)

### 1Ô∏è‚É£ **`data_preprocessing.ipynb`** - Preprocesamiento de Datos
### 2Ô∏è‚É£ **`data_augmentation.ipynb`** - Augmentation de Datos  
### 3Ô∏è‚É£ **`cnn_uncertainty_training.ipynb`** - Entrenamiento con Incertidumbre
### 4Ô∏è‚É£ **`gradcam_inference.ipynb`** - Visualizaci√≥n GradCAM

---

## üìñ Documentaci√≥n Detallada por Notebook

### 1Ô∏è‚É£ **`data_preprocessing.ipynb`** - Preprocesamiento de Datos

#### üéØ **¬øQu√© hace?**
Implementa el **preprocesamiento exacto** seg√∫n el paper de Ibarra et al. (2023) para convertir archivos de audio (.egg) en espectrogramas Mel normalizados.

#### üìö **Base Cient√≠fica**
- **Paper**: Ibarra et al. (2023) - "Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"
- **Metodolog√≠a**: Pipeline exacto sin augmentation para reproducibilidad

#### ‚öôÔ∏è **Pipeline de Preprocesamiento**
1. **Resample**: 44.1 kHz (est√°ndar de audio)
2. **Normalizaci√≥n**: Por amplitud m√°xima absoluta
3. **Segmentaci√≥n**: Ventanas de 400ms con 50% overlap (200ms hop)
4. **Mel Spectrogram**: 65 bandas Mel, ventana FFT 40ms, hop 10ms
5. **Conversi√≥n**: Amplitud a dB (logar√≠tmica)
6. **Normalizaci√≥n**: Z-score por espectrograma individual
7. **Dimensi√≥n final**: 65√ó41 p√≠xeles

#### üìä **¬øQu√© deber√≠a ver?**
- **Gr√°ficas de audio**: Formas de onda originales
- **Espectrogramas**: Visualizaci√≥n Mel antes/despu√©s de normalizaci√≥n
- **Estad√≠sticas**: Dimensiones, rangos de valores, distribuci√≥n
- **Cache generado**: `cache/original/healthy_ibarra.pkl` y `cache/original/parkinson_ibarra.pkl`

#### ‚è±Ô∏è **Tiempo estimado**: 2-3 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Cache generado correctamente
- Espectrogramas con dimensi√≥n 65√ó41
- Valores normalizados (media‚âà0, std‚âà1)

---

### 2Ô∏è‚É£ **`data_augmentation.ipynb`** - Augmentation de Datos

#### üéØ **¬øQu√© hace?**
Aplica **SpecAugment** a los datos Parkinson para mejorar el balance de clases y robustez del modelo.

#### üìö **Base Cient√≠fica**
- **Paper**: Park et al. (2019) - "SpecAugment: A Simple Data Augmentation Method for ASR"
- **T√©cnica**: M√°scaras de frecuencia y tiempo en espectrogramas

#### ‚öôÔ∏è **Pipeline de Augmentation**
1. **Carga datos**: Desde cache preprocesado
2. **SpecAugment**: M√°scaras conservadoras (freq=8, time=4)
3. **Generaci√≥n**: 2 versiones augmentadas por espectrograma original
4. **Guardado**: Dataset augmentado reutilizable

#### üìä **¬øQu√© deber√≠a ver?**
- **Espectrogramas originales vs augmentados**: Comparaci√≥n visual
- **M√°scaras aplicadas**: Visualizaci√≥n de las m√°scaras de SpecAugment
- **Estad√≠sticas de balance**: Conteo de muestras por clase
- **Cache generado**: `cache/augmented/augmented_dataset_specaugment.pkl`

#### ‚è±Ô∏è **Tiempo estimado**: 1-2 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Balance mejorado (m√°s muestras Parkinson)
- Espectrogramas augmentados visualmente diferentes
- Cache augmentado generado

---

### 3Ô∏è‚É£ **`cnn_uncertainty_training.ipynb`** - Entrenamiento con Incertidumbre

#### üéØ **¬øQu√© hace?**
Entrena una CNN con **dos tipos de incertidumbre**: epist√©mica (modelo) y aleatoria (datos) seg√∫n Kendall & Gal (2017).

#### üìö **Base Cient√≠fica**
- **Paper**: Kendall & Gal (2017) - "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?"
- **T√©cnica**: Heteroscedastic loss + MC Dropout

#### üèóÔ∏è **Arquitectura CNN**
```
Input: (B, 1, 65, 41) espectrograma
‚Üì
[Feature Extractor - Ibarra 2023]
Block1: Conv2D(32, 3√ó3) ‚Üí BN ‚Üí ReLU ‚Üí MaxPool(3√ó3) ‚Üí Dropout
Block2: Conv2D(64, 3√ó3) ‚Üí BN ‚Üí ReLU ‚Üí MaxPool(3√ó3) ‚Üí Dropout
‚Üì
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Prediction Head]       ‚îÇ [Noise Head]            ‚îÇ
‚îÇ FC(64) ‚Üí ReLU ‚Üí FC(2)  ‚îÇ FC(64) ‚Üí ReLU ‚Üí FC(2)   ‚îÇ
‚îÇ ‚Üì                       ‚îÇ ‚Üì                       ‚îÇ
‚îÇ logits (predicci√≥n)     ‚îÇ s_logit (ruido)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### üßÆ **Matem√°tica de Incertidumbre**
1. **Epist√©mica (BALD)**: `H(pÃÑ) - E[H(p_t)]` - Incertidumbre del modelo
2. **Aleatoria**: `E[H(p_t)]` - Incertidumbre de los datos
3. **Total**: `H(pÃÑ) = Epist√©mica + Aleatoria`
4. **Ruido**: `œÉ = exp(0.5 * s_logit)` - Desviaci√≥n est√°ndar

#### üìä **¬øQu√© deber√≠a ver?**
- **Curvas de entrenamiento**: Loss, accuracy, F1-score
- **Matriz de confusi√≥n**: Rendimiento por clase
- **Histogramas de incertidumbre**: Distribuci√≥n de incertidumbre por clase
- **Reliability diagram**: Calibraci√≥n del modelo
- **Scatter plot**: Incertidumbre vs accuracy
- **Modelo guardado**: `results/cnn_uncertainty/best_model_uncertainty.pth`

#### ‚è±Ô∏è **Tiempo estimado**: 15-20 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Accuracy > 95%
- Incertidumbre mayor en predicciones incorrectas
- Modelo bien calibrado (reliability diagram)

---

### 4Ô∏è‚É£ **`gradcam_inference.ipynb`** - Visualizaci√≥n GradCAM

#### üéØ **¬øQu√© hace?**
Genera **mapas de explicabilidad** usando GradCAM para entender qu√© regiones del espectrograma son importantes para la decisi√≥n del modelo.

#### üìö **Base Cient√≠fica**
- **Paper**: Selvaraju et al. (2017) - "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
- **T√©cnica**: Gradient-weighted Class Activation Mapping

#### üßÆ **Matem√°tica de GradCAM**
1. **Forward pass**: Obtener activaciones de la √∫ltima capa convolucional
2. **Backward pass**: Calcular gradientes de la clase objetivo
3. **Global Average Pooling**: `w = GAP(‚àÇy/‚àÇA)`
4. **Combinaci√≥n ponderada**: `CAM = ReLU(Œ£ w * A)`
5. **Normalizaci√≥n**: `CAM = (CAM - min) / (max - min)`

#### üìä **¬øQu√© deber√≠a ver?**
- **Espectrogramas originales**: Datos de entrada
- **Mapas GradCAM**: Regiones importantes (colores c√°lidos)
- **Superposiciones**: GradCAM sobre espectrograma original
- **Comparaci√≥n por clase**: Diferencias entre Healthy vs Parkinson
- **An√°lisis de casos**: Predicciones correctas vs incorrectas

#### ‚è±Ô∏è **Tiempo estimado**: 5-10 minutos

#### ‚úÖ **Indicadores de √©xito**:
- Mapas GradCAM coherentes (regiones importantes)
- Diferencias claras entre clases
- Explicaciones visuales interpretables

---

## üîß Configuraci√≥n del Entorno

### Prerequisitos
```bash
# Instalar dependencias
pip install -r requirements.txt

# Verificar que los datos est√°n en data/
ls data/vowels_healthy/  # Archivos .egg de sujetos sanos
ls data/vowels_pk/       # Archivos .egg de pacientes Parkinson
```

### Estructura de Datos Requerida
```
data/
‚îú‚îÄ‚îÄ vowels_healthy/     # Archivos .egg de sujetos sanos
‚îÇ   ‚îú‚îÄ‚îÄ 1022-a_lhl-egg.egg
‚îÇ   ‚îú‚îÄ‚îÄ 103-u_n-egg.egg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ vowels_pk/          # Archivos .egg de pacientes Parkinson
    ‚îú‚îÄ‚îÄ 1580-a_h-egg.egg
    ‚îú‚îÄ‚îÄ 1580-a_l-egg.egg
    ‚îî‚îÄ‚îÄ ...
```

---

## üìä Resultados Esperados

### Despu√©s del Notebook 1 (Preprocesamiento)
- **Cache generado**: `cache/original/`
- **Espectrogramas**: 65√ó41 p√≠xeles, normalizados
- **Tiempo**: ~2-3 minutos

### Despu√©s del Notebook 2 (Augmentation)
- **Cache augmentado**: `cache/augmented/`
- **Balance mejorado**: +200% muestras Parkinson
- **Tiempo**: ~1-2 minutos

### Despu√©s del Notebook 3 (Entrenamiento)
- **Modelo entrenado**: `results/cnn_uncertainty/`
- **Accuracy**: >95%
- **Incertidumbre cuantificada**: Epist√©mica + Aleatoria
- **Tiempo**: ~15-20 minutos

### Despu√©s del Notebook 4 (GradCAM)
- **Mapas de explicabilidad**: `results/cnn_uncertainty/gradcam_outputs/`
- **Visualizaciones**: Espectrogramas + GradCAM
- **Tiempo**: ~5-10 minutos

---

## üö® Troubleshooting

### Error: "Cache not found"
**Soluci√≥n**: Ejecutar `data_preprocessing.ipynb` primero

### Error: "Model not found"
**Soluci√≥n**: Ejecutar `cnn_uncertainty_training.ipynb` primero

### Error: "Out of memory"
**Soluci√≥n**: Reducir `BATCH_SIZE` en el notebook de entrenamiento

### Error: "ImportError"
**Soluci√≥n**: Verificar que est√°s en la ra√≠z del proyecto

---

## üìö Referencias Cient√≠ficas

1. **Ibarra et al. (2023)**: "Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"
2. **Kendall & Gal (2017)**: "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?"
3. **Selvaraju et al. (2017)**: "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
4. **Park et al. (2019)**: "SpecAugment: A Simple Data Augmentation Method for ASR"

---

## üéØ Resumen Ejecutivo

Este proyecto implementa un sistema completo de detecci√≥n de Parkinson que:

1. **Preprocesa** audio seg√∫n est√°ndares cient√≠ficos (Ibarra 2023)
2. **Aumenta** datos para mejorar robustez (SpecAugment)
3. **Entrena** CNN con cuantificaci√≥n de incertidumbre (Kendall & Gal 2017)
4. **Explica** decisiones mediante GradCAM (Selvaraju 2017)

**Resultado**: Sistema de clasificaci√≥n con >95% accuracy, incertidumbre cuantificada y explicabilidad visual.

---

**Autor**: Wilberth Ferney C√≥rdoba Canchala  
**Fecha**: 2025-01-21  
**Versi√≥n**: 4.0 (CNN + Uncertainty + GradCAM)  
