# DetecciÃ³n de Parkinson desde Voz con Domain Adaptation

Sistema completo de anÃ¡lisis de voz para detecciÃ³n de Parkinson usando CNN 2D con Domain Adaptation, incertidumbre epistÃ©mica (MC Dropout) y explicabilidad (Grad-CAM).

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n General](#-descripciÃ³n-general)
2. [Arquitecturas Disponibles](#-arquitecturas-disponibles)
3. [InstalaciÃ³n y Setup](#-instalaciÃ³n-y-setup)
4. [Pipeline Completo](#-pipeline-completo)
5. [Uso RÃ¡pido](#-uso-rÃ¡pido)
6. [MÃ³dulos del Sistema](#-mÃ³dulos-del-sistema)
7. [DocumentaciÃ³n Detallada](#-documentaciÃ³n-detallada)

---

## ğŸ¯ DescripciÃ³n General

### Paper de Referencia
Ibarra et al. (2023) *"Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"*

### CaracterÃ­sticas Principales

- âœ… **Preprocesamiento exacto del paper**: Mel-spectrograms 65Ã—41, z-score
- âœ… **Data Augmentation**: Pitch shift, time stretch, noise, SpecAugment
- âœ… **2 Arquitecturas CNN**:
  - Baseline: CNN2D simple
  - **Domain Adaptation**: Dual-head con GRL (Gradient Reversal Layer)
- âœ… **Incertidumbre EpistÃ©mica**: MC Dropout (30 muestras)
- âœ… **Explicabilidad**: Grad-CAM para mapas de atenciÃ³n
- âœ… **AgregaciÃ³n Multinivel**: Segmento â†’ Archivo â†’ Paciente
- âœ… **Split Speaker-Independent**: Evita data leakage
- âœ… **CÃ³digo Modular**: PEP 8, type hints, documentaciÃ³n completa

---

## ğŸ—ï¸ Arquitecturas Disponibles

### 1. CNN2D Baseline

```
Input (B, 1, 65, 41)
    â†“
Conv2D(32) â†’ BN â†’ ReLU â†’ MaxPool(2Ã—2) â†’ Dropout(0.3)
    â†“
Conv2D(64) â†’ BN â†’ ReLU â†’ MaxPool(2Ã—2) â†’ Dropout(0.3)
    â†“
Flatten â†’ FC(64) â†’ ReLU â†’ Dropout(0.5) â†’ FC(2)
    â†“
Output: HC/PD (2 clases)
```

**Uso**: ClasificaciÃ³n binaria simple  
**ParÃ¡metros**: ~674K

### 2. CNN2D con Domain Adaptation (Recomendado)

```
Input (B, 1, 65, 41)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Extractor (Shared) â”‚
â”‚  Conv2D(32) â†’ MaxPool(3Ã—3)  â”‚
â”‚  Conv2D(64) â†’ MaxPool(3Ã—3)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Features (B, 64, 17, 11)
    â†“
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“             â†“              â†“
PD Head      GRL (Î»)      Domain Head
Linear(2)       â†“          Linear(N)
    â†“       Inverted           â†“
HC/PD    Features         Domains
```

**Ventajas**:
- Features invariantes al dominio (corpus/micrÃ³fono)
- Mejor generalizaciÃ³n cross-corpus
- Menos overfitting

**ParÃ¡metros**: ~1.55M

---

## ğŸš€ InstalaciÃ³n y Setup

### Requisitos
```bash
# Python 3.8+
pip install torch torchvision torchaudio
pip install librosa soundfile scikit-learn
pip install matplotlib seaborn pandas numpy tqdm
```

### Estructura del Proyecto
```
parkinson-voice-uncertainty/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vowels_healthy/    # Datos HC (13 archivos)
â”‚   â””â”€â”€ vowels_pk/         # Datos PD (13 archivos)
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ preprocessing.py   # Preprocesamiento segÃºn paper
â”‚   â”œâ”€â”€ augmentation.py    # Data augmentation
â”‚   â”œâ”€â”€ dataset.py         # PyTorch datasets
â”‚   â”œâ”€â”€ cnn_model.py       # CNN Baseline + DA
â”‚   â”œâ”€â”€ cnn_training.py    # Pipeline de entrenamiento
â”‚   â”œâ”€â”€ cnn_utils.py       # Utilidades
â”‚   â””â”€â”€ cnn_visualization.py  # Visualizaciones
â”œâ”€â”€ parkinson_voice_analysis.ipynb  # Notebook principal
â”œâ”€â”€ train_cnn.py           # Script de entrenamiento
â””â”€â”€ README.md             # Este archivo
```

---

## ğŸ“Š Pipeline Completo

### 1. Preprocesamiento
```python
# ConfiguraciÃ³n segÃºn paper Ibarra
SAMPLE_RATE = 44100 Hz
WINDOW_MS = 400 ms (50% overlap)
N_MELS = 65 bandas
HOP_MS = 10 ms
FFT_WINDOW = 40 ms
OUTPUT_SHAPE = 65 Ã— 41
NORMALIZATION = z-score
```

### 2. Data Augmentation

**Nivel Audio** (antes de segmentar):
- Pitch shift: Â±1, Â±2 semitonos
- Time stretch: 0.9x, 1.1x
- Noise: SNR â‰ˆ30 dB

**Nivel Espectrograma** (despuÃ©s de Mel):
- SpecAugment: frequency + time masking

**Factor total**: ~10x multiplicaciÃ³n de datos

### 3. Entrenamiento

**Split**: 70% train / 15% val / 15% test (speaker-independent)

**HiperparÃ¡metros recomendados**:
```python
batch_size = 32
learning_rate = 0.01
optimizer = SGD(momentum=0.9, weight_decay=1e-4)
epochs = 100
early_stopping = 15 Ã©pocas
```

**Domain Adaptation**:
```python
alpha = 1.0  # Peso de loss_domain
lambda_scheduler = progresivo (0 â†’ 1)
```

### 4. EvaluaciÃ³n

**MÃ©tricas**:
- Accuracy, Precision, Recall, F1
- Confusion Matrix
- MC Dropout: Incertidumbre epistÃ©mica
- Grad-CAM: Explicabilidad visual

**AgregaciÃ³n**:
- Segmento (65Ã—41 espectrograma)
- Archivo (promedio probabilidades)
- Paciente (promedio por subject_id)

---

## ğŸ® Uso RÃ¡pido

### OpciÃ³n 1: Notebook (Recomendado)

```python
# Abrir parkinson_voice_analysis.ipynb
# Ejecutar celdas secuencialmente:

# 1. Setup y carga de datos
# 2. Preprocesamiento
# 3. Data Augmentation
# 4. Entrenamiento CNN-DA
# 5. EvaluaciÃ³n y visualizaciones
```

### OpciÃ³n 2: Script de LÃ­nea de Comandos

```bash
# Entrenamiento bÃ¡sico con DA
python train_cnn.py \
  --hc_dir data/vowels_healthy \
  --pd_dir data/vowels_pk \
  --architecture da \
  --batch_size 32 \
  --epochs 100 \
  --lr 0.01 \
  --mc_samples 30

# Ver todas las opciones
python train_cnn.py --help
```

### OpciÃ³n 3: API ProgramÃ¡tica

```python
from modules.cnn_model import CNN2D_DA
from modules.cnn_training import train_model_da, compute_lambda_schedule
import torch

# 1. Crear modelo
model_da = CNN2D_DA(n_domains=26).to(device)

# 2. Configurar optimizador
optimizer = torch.optim.SGD(model_da.parameters(), lr=0.01)
criterion_pd = torch.nn.CrossEntropyLoss()
criterion_domain = torch.nn.CrossEntropyLoss()

# 3. Entrenar
results = train_model_da(
    model_da, train_loader, val_loader,
    optimizer, criterion_pd, criterion_domain,
    device, n_epochs=100, alpha=1.0,
    lambda_scheduler=lambda e: compute_lambda_schedule(e, 100)
)

# 4. Visualizar
from modules.cnn_visualization import plot_da_training_progress
plot_da_training_progress(results['history'])
```

---

## ğŸ§© MÃ³dulos del Sistema

### Core

| MÃ³dulo | DescripciÃ³n | Funciones Principales |
|--------|-------------|----------------------|
| `preprocessing.py` | Preprocesamiento segÃºn paper | `preprocess_audio_paper()` |
| `augmentation.py` | Data augmentation | `preprocess_audio_with_augmentation()`, `create_augmented_dataset()` |
| `dataset.py` | PyTorch datasets | `VowelSegmentsDataset`, `build_full_pipeline()` |

### CNN

| MÃ³dulo | DescripciÃ³n | Clases/Funciones |
|--------|-------------|------------------|
| `cnn_model.py` | Arquitecturas | `CNN2D`, `CNN2D_DA`, `GradientReversalLayer`, `mc_dropout_predict()`, `GradCAM` |
| `cnn_training.py` | Entrenamiento | `train_model()`, `train_model_da()`, `evaluate_da()`, `compute_lambda_schedule()` |
| `cnn_utils.py` | Utilidades | `plot_lambda_schedule()`, `print_model_architecture()`, `calculate_class_weights()` |
| `cnn_visualization.py` | Visualizaciones | `plot_da_training_progress()`, `visualize_gradcam()`, `create_da_summary_report()` |

### Utilidades

| Script | PropÃ³sito |
|--------|-----------|
| `sample_healthy_data.py` | Muestreo balanceado de datos HC |
| `verify_sampling.py` | VerificaciÃ³n de muestreo |
| `train_cnn.py` | Script de entrenamiento CLI |

---

## ğŸ“š DocumentaciÃ³n Detallada

Para informaciÃ³n detallada sobre cada componente:

### ğŸ”¬ Preprocesamiento y Augmentation
- Ver celdas 1-13 en `parkinson_voice_analysis.ipynb`
- `modules/preprocessing.py` - ConfiguraciÃ³n exacta del paper
- `modules/augmentation.py` - Todas las tÃ©cnicas de augmentation

### ğŸ§  CNN Baseline
- `modules/cnn_model.py` - Clase `CNN2D`
- MC Dropout, Grad-CAM, agregaciÃ³n multinivel
- Ver secciÃ³n "CNN2D Baseline" arriba

### ğŸŒ Domain Adaptation (Recomendado)
- `modules/cnn_model.py` - Clases `CNN2D_DA`, `GradientReversalLayer`
- `modules/cnn_training.py` - `train_model_da()`, `compute_lambda_schedule()`
- Ver secciÃ³n "CNN2D con Domain Adaptation" arriba
- Arquitectura dual-head, lambda scheduling, multi-task learning

### ğŸ“Š Muestreo de Datos
- Script: `data_preparation/sample_healthy_data.py --help`
- Ver secciÃ³n "Quick Start" para uso bÃ¡sico

---

## ğŸ“ˆ Resultados Esperados

### Output del Entrenamiento

```
results/cnn_da/
â”œâ”€â”€ best_model_da.pth              # Mejor checkpoint
â”œâ”€â”€ training_history.json          # MÃ©tricas por Ã©poca
â”œâ”€â”€ config.json                    # ConfiguraciÃ³n
â”œâ”€â”€ training_progress.png          # 4 grÃ¡ficas: losses, accuracy, F1, lambda
â”œâ”€â”€ confusion_matrix_test.png      # Matriz de confusiÃ³n
â””â”€â”€ metrics_summary.png            # Resumen visual
```

### MÃ©tricas TÃ­picas

**Nivel Segmento**:
- Accuracy: 75-85%
- F1 Score: 0.70-0.80

**Nivel Archivo** (agregado):
- Accuracy: 80-90%
- F1 Score: 0.75-0.85

**Nivel Paciente** (agregado):
- Accuracy: 85-95%
- F1 Score: 0.80-0.90

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### HiperparÃ¡metros Clave

```python
# CNN Baseline
p_drop_conv = 0.3
p_drop_fc = 0.5

# Domain Adaptation
alpha = 1.0        # Peso loss_domain
gamma = 10.0       # Scheduler GRL
power = 0.75       # Exponente scheduler

# SpecAugment
freq_mask_param = 10
time_mask_param = 5
num_freq_masks = 2
num_time_masks = 2

# MC Dropout
n_samples = 30
```

### Lambda Scheduling (DA)

El factor Î» de GRL aumenta progresivamente:
```
Î»(epoch) = 2/(1 + exp(-Î³Â·p))^power - 1
donde p = epoch / max_epoch
```

- Ã‰poca 0: Î» â‰ˆ 0 (solo aprende tarea PD)
- Ã‰poca 50: Î» â‰ˆ 0.7
- Ã‰poca 100: Î» â‰ˆ 1.0 (mÃ¡xima inversiÃ³n)

---

## ğŸ› Troubleshooting

### Error: Dimensiones incorrectas
```python
# Verificar shape de espectrogramas
print(X_combined.shape)  # Debe ser (N, 1, 65, 41)

# Convertir labels a Long
y_task = y_task.long()
y_domain = y_domain.long()
```

### VRAM insuficiente
```bash
# Reducir batch size
python train_cnn.py --batch_size 16  # o 8
```

### Loss Domain no disminuye
```python
# Verificar alpha > 0
# Aumentar gamma para activar GRL mÃ¡s rÃ¡pido
lambda_scheduler = lambda e: compute_lambda_schedule(e, 100, gamma=15.0)
```

### Overfitting
```python
# Aumentar dropout
model_da = CNN2D_DA(p_drop_conv=0.4, p_drop_fc=0.6)

# MÃ¡s augmentation
# Reducir learning rate
# Aumentar weight_decay
```

---

## ğŸ“– Referencias

1. **Ibarra et al. (2023)**: Domain Adaptation para Parkinson
2. **Ganin & Lempitsky (2015)**: Gradient Reversal Layer
3. **Park et al. (2019)**: SpecAugment
4. **Gal & Ghahramani (2016)**: MC Dropout
5. **Selvaraju et al. (2017)**: Grad-CAM

---

## ğŸ‘¥ CrÃ©ditos

**Autor**: PhD Research Team  
**VersiÃ³n**: 2.0  
**Fecha**: Octubre 2025

ImplementaciÃ³n basada en:
- Paper Ibarra et al. (2023)
- Arquitectura MARTA
- Buenas prÃ¡cticas: PEP 8, modularidad, documentaciÃ³n

---

## ğŸ“ Licencia

Este cÃ³digo es parte de investigaciÃ³n doctoral en detecciÃ³n de Parkinson mediante anÃ¡lisis de voz.






