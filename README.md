# DetecciÃ³n de Parkinson mediante AnÃ¡lisis de Voz

Sistema de clasificaciÃ³n binaria (Healthy vs Parkinson) usando redes neuronales convolucionales (CNN2D, CNN1D, LSTM) sobre espectrogramas Mel de seÃ±ales de voz.

**ImplementaciÃ³n exacta segÃºn Ibarra et al. (2023)**: Preprocesamiento sin augmentation, espectrogramas individuales reutilizables para CNN2D y Time-CNN-LSTM.

---

## Ãndice

1. [Resumen del Proyecto](#resumen-del-proyecto)
2. [Preprocesamiento (Paper Ibarra 2023)](#preprocesamiento-paper-ibarra-2023)
3. [Estructura del Proyecto](#estructura-del-proyecto)
4. [Flujo de Trabajo](#flujo-de-trabajo)
5. [Notebooks Disponibles](#notebooks-disponibles)
6. [Pipelines Automatizados](#pipelines-automatizados)
7. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
8. [Resultados](#resultados)

---

## Resumen del Proyecto

### Objetivo
Clasificar automÃ¡ticamente seÃ±ales de voz para detectar Parkinson usando tÃ©cnicas de Deep Learning.

### MetodologÃ­a
ImplementaciÃ³n fiel al paper de Ibarra et al. (2023):
- **Preprocesamiento exacto**: Sin augmentation, segÃºn especificaciones del paper
- **Modelos**:
  - **CNN2D**: Modelo baseline sin Domain Adaptation
  - **CNN2D_DA**: Modelo con Domain Adaptation y Gradient Reversal Layer (GRL)
  - **CNN1D_DA**: CNN 1D con atenciÃ³n temporal y Domain Adaptation
  - **Time-CNN-BiLSTM-DA**: CNN time-distributed + BiLSTM con Domain Adaptation

### Referencia
Paper: **Ibarra et al. (2023)** - "Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"

---

## Preprocesamiento (Paper Ibarra 2023)

Pipeline exacto sin augmentation:

### 1. Resample a 44.1 kHz
Todos los audios se resamplea a frecuencia estÃ¡ndar de 44100 Hz (cuando aplique).

### 2. NormalizaciÃ³n por amplitud mÃ¡xima absoluta
```python
audio = audio / np.max(np.abs(audio))
```

### 3. SegmentaciÃ³n: 400ms ventanas, 50% overlap
- **DuraciÃ³n ventana**: 400 ms
- **Overlap**: 50%
- **Hop**: 200 ms

### 4. Mel Spectrogram: 65 bandas, ventana FFT 40ms, hop 10ms
- **Bandas Mel**: 65
- **Ventana FFT**: 40 ms (para vocales sostenidas)
- **Hop length**: 10 ms
- **Frecuencia mÃ¡xima**: Nyquist (22.05 kHz)

### 5. ConversiÃ³n a dB
```python
mel_db = librosa.power_to_db(mel_spec, ref=np.max)
```

### 6. NormalizaciÃ³n z-score por espectrograma individual
```python
normalized = (mel_db - mean(mel_db)) / std(mel_db)
```

### 7. DimensiÃ³n final: 65Ã—41 pÃ­xeles
- **Altura**: 65 bandas Mel (frecuencia)
- **Ancho**: 41 frames temporales

### 8. Sin augmentation (Paper Exacto)
El paper NO menciona data augmentation. Solo el preprocesamiento descrito arriba.

**IMPORTANTE**: Este preprocesamiento (sin augmentation) se usa en:
- `cnn_da_training.ipynb` (CNN2D con Domain Adaptation)
- `cnn1d_da_training.ipynb` (CNN1D)
- `time_cnn_lstm_training.ipynb` (Time-CNN-BiLSTM)

### 9. Data Augmentation (Solo para Baseline)

Para el modelo baseline CNN2D (`cnn_training.ipynb`), se aplica augmentation adicional para mejorar generalizaciÃ³n:

**Augmentation de audio**:
- Pitch shifting: Â±2 semitonos
- Time stretching: 0.9x - 1.1x
- Noise injection: factor 0.005

**Augmentation de espectrograma**:
- SpecAugment: mÃ¡scaras de frecuencia (param=10) y tiempo (param=5)

**Factor**: ~5x mÃ¡s datos

**Cache separado**: `cache/healthy_augmented.pkl` y `cache/parkinson_augmented.pkl`

### Uso de espectrogramas

#### Para CNN2D:
- **Input**: Un espectrograma (1, 65, 41) por vez
- **EvaluaciÃ³n**: Probabilidad conjunta agrupando predicciones de todos los espectrogramas del mismo paciente

#### Para Time-CNN-LSTM:
- **Input**: Secuencia de n espectrogramas consecutivos (n, 1, 65, 41) del mismo audio
- **Padding**: Zero-padding cuando hay menos de n frames
- **Masking**: LSTM ignora frames con padding
- **HiperparÃ¡metro n**: Probar con {3, 5, 7, 9} segÃºn paper

---

## ğŸ“ Estructura del Proyecto

```
parkinson-voice-uncertainty/
â”‚
â”œâ”€â”€ ğŸ““ NOTEBOOKS (Ejecutar en este orden)
â”‚   â”œâ”€â”€ 1. data_preprocessing.ipynb    â† Preprocesar datos (UNA VEZ)
â”‚   â”œâ”€â”€ 2. cnn_training.ipynb          â† CNN2D baseline
â”‚   â””â”€â”€ 3. cnn_da_training.ipynb       â† CNN2D_DA con GRL
â”‚
â”œâ”€â”€ ğŸš€ pipelines/                      â† Scripts automatizados
â”‚   â”œâ”€â”€ README.md                      â† DocumentaciÃ³n
â”‚   â”œâ”€â”€ train_cnn.py                   â† Pipeline CNN2D + MC Dropout
â”‚   â”œâ”€â”€ train_cnn_da_kfold.py         â† Pipeline CNN2D_DA + K-fold
â”‚   â”œâ”€â”€ train_cnn_uncertainty.py      â† Pipeline con incertidumbre
â”‚   â””â”€â”€ train_lstm_da_kfold.py        â† Pipeline LSTM-DA + K-fold (NUEVO)
â”‚
â”œâ”€â”€ ğŸ“¦ modules/                        â† CÃ³digo compartido (REORGANIZADO v4.0)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                          â† MÃ³dulos base
â”‚   â”‚   â”œâ”€â”€ dataset.py                 â† GestiÃ³n de datasets
â”‚   â”‚   â”œâ”€â”€ sequence_dataset.py        â† Secuencias para LSTM (NUEVO)
â”‚   â”‚   â”œâ”€â”€ preprocessing.py           â† Preprocesamiento
â”‚   â”‚   â”œâ”€â”€ utils.py                   â† Utilidades generales
â”‚   â”‚   â””â”€â”€ visualization.py           â† Visualizaciones generales
â”‚   â”œâ”€â”€ data/                          â† Manejo de datos
â”‚   â”‚   â”œâ”€â”€ augmentation.py            â† Data augmentation
â”‚   â”‚   â””â”€â”€ cache_utils.py             â† GestiÃ³n de cache
â”‚   â””â”€â”€ models/                        â† Modelos de ML
â”‚       â”œâ”€â”€ common/                    â† Componentes compartidos (NUEVO)
â”‚       â”‚   â”œâ”€â”€ __init__.py            â† Exports
â”‚       â”‚   â””â”€â”€ layers.py              â† FeatureExtractor, GRL, ClassifierHead
â”‚       â”œâ”€â”€ cnn2d/                     â† CNN 2D
â”‚       â”‚   â”œâ”€â”€ model.py               â† CNN2D y CNN2D_DA
â”‚       â”‚   â”œâ”€â”€ training.py            â† Entrenamiento
â”‚       â”‚   â”œâ”€â”€ inference.py           â† Inferencia MC Dropout
â”‚       â”‚   â”œâ”€â”€ visualization.py       â† Visualizaciones
â”‚       â”‚   â””â”€â”€ utils.py               â† Utilidades CNN2D
â”‚       â”œâ”€â”€ cnn1d/                     â† CNN 1D
â”‚       â”‚   â”œâ”€â”€ model.py               â† CNN1D_DA
â”‚       â”‚   â”œâ”€â”€ training.py            â† Entrenamiento
â”‚       â”‚   â””â”€â”€ visualization.py       â† Visualizaciones
â”‚       â”œâ”€â”€ lstm_da/                   â† Time-CNN-BiLSTM (NUEVO)
â”‚       â”‚   â”œâ”€â”€ model.py               â† TimeCNNBiLSTM_DA
â”‚       â”‚   â”œâ”€â”€ training.py            â† Entrenamiento + K-fold
â”‚       â”‚   â””â”€â”€ visualization.py       â† Visualizaciones
â”‚       â””â”€â”€ uncertainty/               â† Modelos con incertidumbre
â”‚           â”œâ”€â”€ model.py               â† UncertaintyCNN
â”‚           â”œâ”€â”€ loss.py                â† Heteroscedastic loss
â”‚           â”œâ”€â”€ training.py            â† Entrenamiento
â”‚           â””â”€â”€ visualization.py       â† Visualizaciones
â”‚
â”œâ”€â”€ ğŸ’¾ cache/                          â† Datos preprocesados
â”‚   â”œâ”€â”€ healthy/
â”‚   â””â”€â”€ parkinson/
â”‚
â”œâ”€â”€ ğŸ“Š data/                           â† Datos raw
â”‚   â”œâ”€â”€ vowels_healthy/
â”‚   â””â”€â”€ vowels_pk/
â”‚
â”œâ”€â”€ ğŸ¯ results/                        â† Resultados de entrenamientos
â”‚   â”œâ”€â”€ cnn_no_da/                     â† Desde cnn_training.ipynb
â”‚   â”œâ”€â”€ cnn_da/                        â† Desde cnn_da_training.ipynb
â”‚   â””â”€â”€ cnn_da_kfold/                  â† Desde pipelines/
â”‚
â””â”€â”€ ğŸ“ DocumentaciÃ³n adicional
    â””â”€â”€ data_preparation/              â† GuÃ­as de preparaciÃ³n de datos
```

---

## Flujo de Trabajo

### Diagrama de Flujo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Paso 1: data_preprocessing.ipynb            â”‚
â”‚ Ejecutar UNA VEZ                             â”‚
â”‚ â±ï¸  2-3 minutos (sin augmentation)           â”‚
â”‚ â†“                                            â”‚
â”‚ Genera cache/*_ibarra.pkl (65Ã—41 pÃ­xeles)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Paso 2A:       â”‚   â”‚ Paso 2B:            â”‚
â”‚ CNN2D          â”‚   â”‚ CNN2D_DA            â”‚
â”‚ (con augment)  â”‚   â”‚ (sin augment)       â”‚
â”‚                â”‚   â”‚                     â”‚
â”‚ cnn_training   â”‚   â”‚ cnn_da_training     â”‚
â”‚                â”‚   â”‚                     â”‚
â”‚ Genera cache   â”‚   â”‚ Usa cache ibarra    â”‚
â”‚ *_augmented    â”‚   â”‚ (paper exacto)      â”‚
â”‚ (~5x datos)    â”‚   â”‚                     â”‚
â”‚                â”‚   â”‚                     â”‚
â”‚ â±ï¸ 15-20 min    â”‚   â”‚ â±ï¸ 10-15 min         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                       â†“
results/              results/
cnn_no_da/            cnn_da/
(con augment)         (sin augment)
    â†“                       â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            3. Comparar
               Resultados
```

### Estrategia de Augmentation

**SIN Augmentation (Paper Exacto)**:
- `data_preprocessing.ipynb` â†’ `cache/*_ibarra.pkl`
- Usado por: `cnn_da_training.ipynb`, `cnn1d_da_training.ipynb`, `time_cnn_lstm_training.ipynb`
- Objetivo: Seguir paper de Ibarra et al. (2023) exactamente

**CON Augmentation (Mejora GeneralizaciÃ³n)**:
- `cnn_training.ipynb` genera automÃ¡ticamente â†’ `cache/*_augmented.pkl`
- Usado solo por: `cnn_training.ipynb`
- Objetivo: Mejorar robustez del modelo baseline con mÃ¡s datos

| Notebook | Augmentation | Cache | PropÃ³sito |
|----------|--------------|-------|-----------|
| `cnn_training.ipynb` | âœ… SÃ | `*_augmented.pkl` | Baseline robusto |
| `cnn_da_training.ipynb` | âŒ NO | `*_ibarra.pkl` | Paper exacto |
| Otros notebooks | âŒ NO | `*_ibarra.pkl` | Paper exacto |

### Quick Start

```bash
# Primera vez (validar preprocesamiento):
python test/test_ibarra_preprocessing.py  # Validar que cumple paper

# Generar datos preprocesados:
jupyter notebook data_preprocessing.ipynb  # 1. Generar cache (~2-3 min)

# Entrenar modelos:
jupyter notebook cnn_training.ipynb        # 2A. Baseline (~10-15 min)
jupyter notebook cnn_da_training.ipynb     # 2B. Domain Adapt (~15-20 min)

# Pipelines automatizados:
python pipelines/train_cnn.py --lr 0.001
python pipelines/train_cnn_da_kfold.py --n_folds 10
python pipelines/train_lstm_da_kfold.py --n_frames 7 --lstm_units 64
```

### ValidaciÃ³n del Preprocesamiento

Ejecutar pruebas unitarias para verificar cumplimiento del paper:

```bash
python test/test_ibarra_preprocessing.py
```

Las pruebas validan:
- âœ… Constantes (SAMPLE_RATE=44100, N_MELS=65, etc.)
- âœ… NormalizaciÃ³n por max-abs
- âœ… SegmentaciÃ³n 400ms con 50% overlap
- âœ… Dimensiones finales 65Ã—41
- âœ… NormalizaciÃ³n z-score
- âœ… Sin augmentation (reproducibilidad)

---

## ğŸ““ Notebooks Disponibles

### 1ï¸âƒ£ `data_preprocessing.ipynb`

**PropÃ³sito**: Generar cache de espectrogramas preprocesados segÃºn Ibarra et al. (2023)

**Ejecutar**: UNA VEZ (o cuando cambies parÃ¡metros de preprocesamiento)

**Contenido**:
- VisualizaciÃ³n de audio raw
- Preprocesamiento exacto segÃºn paper (sin augmentation):
  - Resample 44.1 kHz + normalizaciÃ³n max-abs
  - SegmentaciÃ³n 400ms con 50% overlap
  - Mel spectrograms: 65 bandas, FFT 40ms, hop 10ms
  - ConversiÃ³n a dB + z-score individual
- GeneraciÃ³n y guardado de cache
- Espectrogramas individuales (65Ã—41) reutilizables para CNN2D y Time-CNN-LSTM

**Output**:
```
cache/
â”œâ”€â”€ healthy_ibarra.pkl     (~50-80 espectrogramas)
â””â”€â”€ parkinson_ibarra.pkl   (~50-80 espectrogramas)
```

**Tiempo**: ~2-3 minutos (sin augmentation, mÃ¡s rÃ¡pido)

---

### 2ï¸âƒ£ `cnn_training.ipynb`

**PropÃ³sito**: Entrenar modelo CNN2D baseline CON augmentation

**Prerequisito**: Tener archivos de audio en `data/`

**Contenido**:
- Carga/genera espectrogramas CON augmentation:
  - Pitch shifting
  - Time stretching
  - Noise injection
  - SpecAugment
- Factor: ~5x mÃ¡s datos (mejora generalizaciÃ³n)
- Split train/val/test (70/15/15)
- Modelo CNN2D con backbone Ibarra (sin DA)
- Input: un espectrograma (1, 65, 41) por vez
- Entrenamiento con Adam + early stopping
- EvaluaciÃ³n y visualizaciÃ³n

**Nota**: Este es el ÃšNICO notebook que usa augmentation. El objetivo es mejorar la generalizaciÃ³n del modelo baseline.

**Output**:
```
results/cnn_no_da/
â”œâ”€â”€ best_model.pth
â”œâ”€â”€ test_metrics.json
â”œâ”€â”€ training_progress.png
â””â”€â”€ confusion_matrix_test.png
```

**Tiempo**: ~10-15 minutos

---

### 3ï¸âƒ£ `cnn_da_training.ipynb`

**PropÃ³sito**: Entrenar modelo CNN2D_DA con Domain Adaptation (segÃºn paper exacto)

**Prerequisito**: Cache generado (ejecutar `data_preprocessing.ipynb` primero)

**Contenido**:
- Carga cache de espectrogramas SIN augmentation (paper exacto)
- Split train/val/test (70/15/15)
- Modelo CNN2D_DA (dual-head con GRL)
- Input: un espectrograma (1, 65, 41) por vez
- Entrenamiento multi-task con SGD
- EvaluaciÃ³n PD + Domain

**Nota**: Este notebook sigue el paper de Ibarra et al. (2023) exactamente (sin augmentation).

**Output**:
```
results/cnn_da/
â”œâ”€â”€ best_model_da.pth
â”œâ”€â”€ test_metrics_da.json
â”œâ”€â”€ training_progress_da.png
â””â”€â”€ confusion_matrix_test_da.png
```

**Tiempo**: ~15-20 minutos

---

## ğŸš€ Pipelines Automatizados

### `pipelines/train_cnn.py`

Pipeline completo para entrenar CNN2D con MC Dropout:

```bash
python pipelines/train_cnn.py --epochs 100 --lr 0.001
```

**CaracterÃ­sticas**:
- Entrenamiento automatizado CNN2D
- Implementa MC Dropout para incertidumbre
- ConfiguraciÃ³n vÃ­a argumentos de lÃ­nea de comandos

---

### `pipelines/train_cnn_da_kfold.py`

Pipeline completo para entrenar CNN2D_DA con validaciÃ³n cruzada:

```bash
python pipelines/train_cnn_da_kfold.py --n_folds 10
```

**CaracterÃ­sticas**:
- Entrenamiento automatizado CNN2D_DA
- K-fold cross-validation (10-fold por defecto)
- ImplementaciÃ³n segÃºn Ibarra (2023)

---

### `pipelines/train_lstm_da_kfold.py` (NUEVO)

Pipeline completo para entrenar Time-CNN-BiLSTM-DA con validaciÃ³n cruzada:

```bash
python pipelines/train_lstm_da_kfold.py --n_frames 7 --lstm_units 64 --n_folds 10
```

**CaracterÃ­sticas**:
- Entrenamiento automatizado Time-CNN-BiLSTM-DA
- Procesa secuencias de n espectrogramas (n=7, 9)
- BiLSTM con masking para secuencias de longitud variable
- K-fold cross-validation speaker-independent
- Lambda warm-up para GRL (0â†’1 en 5 Ã©pocas)
- SGD con momentum 0.9, LR scheduler StepLR
- ImplementaciÃ³n segÃºn Ibarra (2023)

**Argumentos principales**:
- `--n_frames`: NÃºmero de frames por secuencia (default: 7, paper sugiere: 3, 5, 7, 9)
- `--lstm_units`: Unidades LSTM por direcciÃ³n (default: 64, paper sugiere: 16, 32, 64)
- `--lambda_warmup`: Ã‰pocas de warm-up para lambda GRL (default: 5)

---

## ğŸ’» InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos del Sistema

- Python 3.8+
- PyTorch 1.8+
- CUDA (opcional, para GPU)

### InstalaciÃ³n

1. **Clonar el repositorio**:
```bash
git clone <repo-url>
cd parkinson-voice-uncertainty
```

2. **Crear entorno virtual**:
```bash
python -m venv parkinson_env
source parkinson_env/bin/activate  # Linux/Mac
# o
parkinson_env\Scripts\activate  # Windows
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

### Estructura de Datos

Colocar archivos de audio en:
```
data/
â”œâ”€â”€ vowels_healthy/  â† Archivos .egg de sujetos sanos
â””â”€â”€ vowels_pk/       â† Archivos .egg de pacientes Parkinson
```

---

## ğŸ“Š Resultados

### ComparaciÃ³n de Modelos

| Modelo | Accuracy | F1-Score | ParÃ¡metros | Tipo |
|--------|----------|----------|------------|------|
| CNN2D (baseline) | ~98.8% | ~98.8% | 674,562 | Sin DA |
| CNN2D_DA (con GRL) | TBD | TBD | ~800,000+ | Con DA |
| CNN1D_DA | TBD | TBD | ~350,000+ | Con DA |
| Time-CNN-BiLSTM-DA | TBD | TBD | ~950,000+ | Con DA + Temporal |

### âš ï¸ Diferencias ArquitectÃ³nicas Importantes

**Los modelos NO son idÃ©nticos**. Diferencias clave:

#### 1ï¸âƒ£ MaxPooling
- **CNN2D**: MaxPool **2Ã—2** (configuraciÃ³n estÃ¡ndar)
- **CNN2D_DA**: MaxPool **3Ã—3** (segÃºn paper Ibarra 2023)

#### 2ï¸âƒ£ Dimensiones de Features
```python
# DespuÃ©s de feature extraction:
CNN2D:    (B, 64, 16, 10) â†’ Flatten â†’ (B, 10,240)
CNN2D_DA: (B, 64, 17, 11) â†’ Flatten â†’ (B, 11,968)
```

#### 3ï¸âƒ£ Estructura
- **CNN2D**: Single-head (solo clasificaciÃ³n PD)
- **CNN2D_DA**: Dual-head (clasificaciÃ³n PD + Domain con GRL)

#### 4ï¸âƒ£ Entrenamiento
- **CNN2D**: Adam (LR=0.001), Loss simple
- **CNN2D_DA**: SGD (LR=0.1), Loss multi-task

### Tabla Comparativa Detallada

| CaracterÃ­stica | CNN2D | CNN2D_DA |
|----------------|-------|----------|
| **MaxPool** | 2Ã—2 | 3Ã—3 |
| **Feature Dim** | 10,240 | 11,968 |
| **Heads** | 1 (PD) | 2 (PD + Domain) |
| **GRL** | âŒ No | âœ… SÃ­ |
| **ParÃ¡metros** | 674,562 | ~800,000+ |
| **Loss** | CrossEntropy | Multi-task |
| **Optimizer** | Adam | SGD |
| **LR** | 0.001 | 0.1 |
| **Uso** | Baseline | Domain Adapt |

### CaracterÃ­sticas de los Modelos

**âš¡ Ambos modelos comparten el MISMO Feature Extractor para comparaciÃ³n justa:**
- 2 bloques Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool(3Ã—3) â†’ Dropout

#### CNN2D (Baseline)
- **Arquitectura**: Single-head CNN (solo cabeza PD)
- **Feature Extractor**: IdÃ©ntico a CNN2D_DA (arquitectura Ibarra 2023)
- **Entrenamiento**: Adam optimizer
- **Output**: ClasificaciÃ³n Healthy/Parkinson
- **Ventaja**: Simplicidad, sin Domain Adaptation

#### CNN2D_DA (Domain Adaptation)
- **Arquitectura**: Dual-head CNN con GRL
- **Feature Extractor**: Compartido con CNN2D (arquitectura Ibarra 2023)
- **Entrenamiento**: SGD optimizer (segÃºn paper)
- **Output**: ClasificaciÃ³n PD + Domain
- **Ventaja**: Robustez ante diferentes dominios
- **Paper**: ImplementaciÃ³n fiel a Ibarra et al. (2023)

**ğŸ”„ Ventaja del diseÃ±o modular:**
- Domain Adaptation es un mÃ³dulo que se puede agregar/quitar
- ComparaciÃ³n justa: mismo backbone, diferente cabeza
- Sin duplicaciÃ³n de cÃ³digo (FeatureExtractor compartido)

---

## ğŸ“ Conceptos Clave

| TÃ©rmino | Significado |
|---------|-------------|
| **Pipeline** | Flujo completo automatizado end-to-end |
| **Module** | CÃ³digo reutilizable (librerÃ­a) |
| **Notebook** | Experimento interactivo Jupyter |
| **Cache** | Datos preprocesados guardados en disco |
| **DA** | Domain Adaptation (adaptaciÃ³n de dominio) |
| **GRL** | Gradient Reversal Layer |
| **MC Dropout** | Monte Carlo Dropout (cuantificaciÃ³n de incertidumbre) |
| **K-fold** | ValidaciÃ³n cruzada en K particiones |
| **BiLSTM** | Bidirectional Long Short-Term Memory |
| **Time-distributed** | Aplicar mismas capas a cada frame de secuencia |
| **Masking** | Ignorar frames de padding en cÃ¡lculos |
| **Lambda warm-up** | Incremento gradual de lambda GRL durante entrenamiento |

---

## ğŸ“ GuÃ­a de Uso Paso a Paso

### Primera EjecuciÃ³n (Setup Completo)

**DÃ­a 1: PreparaciÃ³n y Entrenamiento (Total: ~35-45 min)**

1. **Generar Cache** (~7-10 min)
```bash
jupyter notebook data_preprocessing.ipynb
# Ejecutar todas las celdas (Cell â†’ Run All)
```
âœ… Resultado: Cache en `cache/healthy/` y `cache/parkinson/`

2. **Entrenar Baseline** (~10-15 min)
```bash
jupyter notebook cnn_training.ipynb
# Ejecutar todas las celdas
```
âœ… Resultado: Modelo en `results/cnn_no_da/`

3. **Entrenar con DA** (~15-20 min)
```bash
jupyter notebook cnn_da_training.ipynb
# Ejecutar todas las celdas
```
âœ… Resultado: Modelo en `results/cnn_da/`

---

### ExperimentaciÃ³n (Con Cache Existente)

**Solo Modificar y Entrenar (~10-15 min por experimento)**

```bash
# Abrir notebook
jupyter notebook cnn_training.ipynb

# Modificar hiperparÃ¡metros en la celda correspondiente:
N_EPOCHS = 150
LEARNING_RATE = 5e-4

# Ejecutar todas las celdas
```

---

## ğŸ”§ ConfiguraciÃ³n de ParÃ¡metros

### Preprocesamiento (en `modules/core/preprocessing.py`)

```python
SAMPLE_RATE = 44100      # Hz (actualizado desde 16k)
WINDOW_MS = 400          # ms
OVERLAP = 0.5            # 50%
N_MELS = 65              # Bandas Mel
TARGET_FRAMES = 41       # Frames por espectrograma
```

### Secuencias LSTM (en `modules/core/sequence_dataset.py`)

```python
N_FRAMES = 7             # Frames por secuencia
MIN_FRAMES = 3           # MÃ­nimo de frames para crear secuencia
NORMALIZE = True         # Normalizar POR SECUENCIA (no por frame)
```

### Data Augmentation

```python
AUGMENTATION_TYPES = [
    "original",
    "pitch_shift",
    "time_stretch", 
    "noise"
]
NUM_SPEC_AUGMENT_VERSIONS = 2
```

### Entrenamiento CNN2D

```python
N_EPOCHS = 100
LEARNING_RATE = 1e-3
BATCH_SIZE = 32
EARLY_STOPPING_PATIENCE = 15
```

### Entrenamiento CNN2D_DA

```python
N_EPOCHS = 100
LEARNING_RATE = 0.1      # SGD segÃºn Ibarra
ALPHA = 1.0              # Peso de loss_domain
LAMBDA_CONSTANT = 1.0    # Lambda para GRL
```

### Entrenamiento Time-CNN-BiLSTM-DA

```python
N_EPOCHS = 100
N_FRAMES = 7             # Secuencia de frames (paper: 3, 5, 7, 9)
LSTM_UNITS = 64          # Unidades por direcciÃ³n (paper: 16, 32, 64)
LEARNING_RATE = 0.1      # SGD con momentum 0.9
ALPHA = 1.0              # Peso de loss_domain
LAMBDA_WARMUP = 5        # Ã‰pocas para warm-up de GRL (0â†’1)
BATCH_SIZE = 32
```

---

## ğŸ” Detalles TÃ©cnicos

### Arquitectura CNN2D (sin DA)

```
Input: (B, 1, 65, 41)
â†“
[Feature Extractor - Ibarra 2023]
Block1: Conv2D(32, 3Ã—3) â†’ BN â†’ ReLU â†’ MaxPool(3Ã—3) â†’ Dropout
Block2: Conv2D(64, 3Ã—3) â†’ BN â†’ ReLU â†’ MaxPool(3Ã—3) â†’ Dropout
â†“
[PD Head]
Flatten â†’ FC(64) â†’ ReLU â†’ Dropout â†’ FC(2)
â†“
Output: Softmax (Healthy/Parkinson)
```

**Nota**: Usa el mismo FeatureExtractor que CNN2D_DA para comparaciÃ³n justa.

---

### Arquitectura CNN2D_DA (con DA)

```
Input: (B, 1, 65, 41)
â†“
[Feature Extractor - Ibarra 2023] (COMPARTIDO)
Block1: Conv2D(32, 3Ã—3) â†’ BN â†’ ReLU â†’ MaxPool(3Ã—3) â†’ Dropout
Block2: Conv2D(64, 3Ã—3) â†’ BN â†’ ReLU â†’ MaxPool(3Ã—3) â†’ Dropout
â†“
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [PD Head]               â”‚ [Domain Head]           â”‚
â”‚ Flatten â†’ FC(64) â†’ FC(2)â”‚ GRL â†’ FC(64) â†’ FC(n_dom)â”‚
â”‚ â†“                       â”‚ â†“                       â”‚
â”‚ Healthy/Parkinson       â”‚ Domain ID               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DiseÃ±o Modular**: El DA es un mÃ³dulo que se puede agregar/quitar sin duplicar cÃ³digo.

---

### Arquitectura Time-CNN-BiLSTM-DA (NUEVO)

```
Input: (B, T, 1, 65, 41)  donde T = n_frames (7, 9)
â†“
[Time-Distributed Feature Extractor] (REUTILIZA FeatureExtractor de CNN2D)
Para cada frame t en T:
  Block1: Conv2D(32, 3Ã—3) â†’ BN â†’ ReLU â†’ MaxPool(3Ã—3) â†’ Dropout
  Block2: Conv2D(64, 3Ã—3) â†’ BN â†’ ReLU â†’ MaxPool(3Ã—3) â†’ Dropout
  Projection: Flatten â†’ FC(128) â†’ ReLU â†’ Dropout
â†“
Output: (B, T, 128) embeddings

[BiLSTM Temporal con Masking]
BiLSTM(128 â†’ 64 bidirectional) con pack_padded_sequence
â†“
Output: (B, T, 128) LSTM hidden states

[Global Pooling Temporal]
Mean pooling considerando solo frames vÃ¡lidos (no padding)
â†“
Output: (B, 128) embedding global

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [PD Head]               â”‚ [Domain Head]           â”‚
â”‚ FC(64) â†’ ReLU â†’ FC(2)   â”‚ GRL â†’ FC(64) â†’ FC(4)    â”‚
â”‚ â†“                       â”‚ â†“                       â”‚
â”‚ Healthy/Parkinson       â”‚ Domain ID (4 corpus)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ventajas del modelo**:
- âœ… **No requiere post-proceso por paciente**: BiLSTM procesa toda la secuencia
- âœ… **Masking automÃ¡tico**: Ignora frames de padding
- âœ… **Reutiliza cÃ³digo**: FeatureExtractor compartido con CNN2D
- âœ… **Modelado temporal**: BiLSTM captura dependencias entre frames
- âœ… **Lambda warm-up**: GRL aumenta gradualmente (0â†’1 en 5 Ã©pocas)

**Diferencias con CNN2D/CNN1D**:
- CNN2D/CNN1D: Procesan espectrogramas individuales â†’ post-proceso por paciente
- LSTM-DA: Procesa secuencias completas â†’ predicciÃ³n directa por secuencia

---

## ğŸ’¡ Ventajas de la OrganizaciÃ³n Actual

### âœ… VersiÃ³n 4.0 - CÃ³digo Compartido Centralizado (NUEVO)

**Mejoras principales:**
- ğŸ¯ **modules/models/common/**: Componentes compartidos entre modelos
  - `FeatureExtractor`: CNN 2D usado por CNN2D y LSTM-DA
  - `GradientReversalLayer (GRL)`: Usado por CNN2D_DA, CNN1D_DA, LSTM-DA
  - `ClassifierHead`: Cabeza de clasificaciÃ³n reutilizable
- âœ… **Sin duplicaciÃ³n**: Un solo lugar para cÃ³digo compartido
- ğŸ”„ **FÃ¡cil mantenimiento**: Cambios en un lugar afectan todos los modelos
- ğŸ“ **Imports claros**: `from modules.models.common.layers import FeatureExtractor`

### âœ… VersiÃ³n 3.0 - Nueva Estructura Modular

**Cambios principales:**
- ğŸ“¦ **MÃ³dulos reorganizados por funcionalidad**:
  - `core/`: MÃ³dulos base compartidos (dataset, preprocessing, utils)
  - `data/`: Manejo de datos (augmentation, cache)
  - `models/`: Modelos organizados por tipo (cnn2d, cnn1d, lstm_da, uncertainty)
  - `models/common/`: Componentes compartidos entre modelos
- ğŸ”„ **CNN renombrado a CNN2D** para claridad
- ğŸ¯ **AgrupaciÃ³n lÃ³gica**: Cada carpeta agrupa funcionalidad relacionada
- ğŸ“ **Imports simplificados**: `from modules.models.cnn2d import ...`

### âœ… Antes (v2.0 - Problemas)
- âŒ Archivos sueltos en `/modules`
- âŒ `cnn_*.py` sin claridad si es 2D o 1D
- âŒ MÃ³dulos de uncertainty, cnn1d y cnn2d mezclados
- âŒ DifÃ­cil encontrar quÃ© archivo modificar

### âœ… Ahora (v3.0 - Soluciones)
- âœ… Estructura jerÃ¡rquica por funcionalidad
- âœ… CNN2D claramente separado de CNN1D
- âœ… Cada modelo tiene su carpeta con todo su cÃ³digo
- âœ… FÃ¡cil navegar y mantener
- âœ… Imports mÃ¡s descriptivos y organizados

---

## ğŸ†˜ Troubleshooting

### Error: "Cache not found"
**SoluciÃ³n**: Ejecutar `data_preprocessing.ipynb` primero

### Error: "ImportError"
**SoluciÃ³n**: Verificar que estÃ¡s en la raÃ­z del proyecto

### Error: "Out of memory"
**SoluciÃ³n**: Reducir `BATCH_SIZE` en notebook de entrenamiento

### Cache desactualizado
**SoluciÃ³n**:
```python
# En data_preprocessing.ipynb, modificar:
FORCE_REGENERATE = True  # â† Regenera cache
```

---

## ğŸ“ˆ ComparaciÃ³n: Notebooks vs Pipelines

| CaracterÃ­stica | Notebooks | Pipelines |
|---------------|-----------|-----------|
| **Interfaz** | Jupyter (interactivo) | CLI (automatizado) |
| **Uso** | ExploraciÃ³n, debugging | ProducciÃ³n, batch |
| **SupervisiÃ³n** | Paso a paso | Desatendido |
| **VisualizaciÃ³n** | Inline | Archivos PNG |
| **ConfiguraciÃ³n** | En celdas | Argumentos CLI |

---

## ğŸ¯ Casos de Uso

### ğŸ“Š ExploraciÃ³n y Desarrollo
**â†’ Usar Notebooks**
- Ver resultados paso a paso
- Modificar hiperparÃ¡metros fÃ¡cilmente
- Visualizaciones inline
- Ideal para entender el proceso

### ğŸš€ ProducciÃ³n y Batch
**â†’ Usar Pipelines**
- Ejecutar mÃºltiples experimentos
- Automatizar entrenamiento
- ConfiguraciÃ³n vÃ­a CLI
- Ideal para validaciÃ³n cruzada

---

## ğŸ“š InformaciÃ³n TÃ©cnica Adicional

### Cache de Datos

**UbicaciÃ³n**: `cache/healthy/` y `cache/parkinson/`

**Contenido**:
- Espectrogramas Mel augmentados
- ~1553 muestras Healthy
- ~1219 muestras Parkinson
- Total: ~2772 espectrogramas

**Ventaja**: 
- Carga instantÃ¡nea (~5 segundos)
- Ahorro de ~6 minutos por experimento
- Mismos datos para todos los modelos

### Resultados Guardados

Cada entrenamiento guarda:
- âœ“ Modelo entrenado (`.pth`)
- âœ“ MÃ©tricas de test (`.json`)
- âœ“ GrÃ¡ficas de progreso (`.png`)
- âœ“ Matriz de confusiÃ³n (`.png`)

---

## ğŸ”„ Variables Importantes

### DespuÃ©s de `data_preprocessing.ipynb`:
```python
X_healthy     # Tensor (1553, 1, 65, 41)
X_parkinson   # Tensor (1219, 1, 65, 41)
cache/        # Archivos .pkl para reutilizar
```

### DespuÃ©s de `cnn_training.ipynb`:
```python
model         # CNN2D entrenado
history       # Historial de entrenamiento
test_metrics  # Accuracy, F1, Precision, Recall
```

### DespuÃ©s de `cnn_da_training.ipynb`:
```python
model_da         # CNN2D_DA entrenado
history_da       # Historial multi-task
test_metrics_da  # MÃ©tricas PD + Domain
```

---

## âœ… Checklist de Inicio

### Primera Vez
- [ ] Instalar dependencias (`pip install -r requirements.txt`)
- [ ] Colocar datos en `data/vowels_healthy/` y `data/vowels_pk/`
- [ ] Ejecutar `data_preprocessing.ipynb`
- [ ] Verificar que `cache/` existe
- [ ] Ejecutar `cnn_training.ipynb`
- [ ] Ejecutar `cnn_da_training.ipynb`
- [ ] Comparar resultados en `results/`

### ExperimentaciÃ³n
- [ ] Cache ya existe
- [ ] Modificar hiperparÃ¡metros segÃºn necesidad
- [ ] Ejecutar notebook de entrenamiento
- [ ] Comparar con runs previos

---

## ğŸ§ª Tests de ValidaciÃ³n

### Suite de Tests para Secuencias LSTM

**Archivo**: `test/test_lstm_sequences.py`  
**Tests**: 14/14 pasando

**Validaciones implementadas:**
- âœ… Orden temporal (segment_id consecutivos)
- âœ… CorrelaciÃ³n entre frames adyacentes (>0.6)
- âœ… NormalizaciÃ³n por secuencia (no por frame)
- âœ… Padding correcto (ceros + masking)
- âœ… No mezcla de frames de diferentes audios
- âœ… SpecAugment consistente (cuando aplica)
- âœ… Compatibilidad con modelos LSTM

**Ejecutar tests:**
```bash
python test/test_lstm_sequences.py
# [PASS] TODOS LOS TESTS PASARON (14/14)
```

**DocumentaciÃ³n detallada**: Ver `LSTM_SEQUENCE_IMPROVEMENTS.md`

---

## ğŸ“– Referencias

**Paper Principal**:
- Ibarra et al. (2023): "Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"

**Papers Relacionados**:
- Park et al. (2019): "SpecAugment: A Simple Data Augmentation Method for ASR"
- Kendall & Gal (2017): "What Uncertainties Do We Need in Bayesian Deep Learning..."

**TÃ©cnicas Implementadas**:
- Domain Adaptation con Gradient Reversal Layer (GRL)
- Monte Carlo Dropout para cuantificaciÃ³n de incertidumbre
- Data Augmentation (SpecAugment global para LSTM)
- K-fold Cross-Validation
- NormalizaciÃ³n por secuencia para modelos temporales

---

## ğŸ¯ PrÃ³ximos Pasos (Futuro)

1. **MC Dropout**: Implementar inferencia con MC Dropout en notebooks
2. **AnÃ¡lisis de Incertidumbre**: Cuantificar incertidumbre en predicciones
3. **ComparaciÃ³n Completa**: Notebook dedicado a comparar CNN2D vs CNN2D_DA
4. **Limpieza**: Eliminar notebooks legacy si es necesario

---

## ğŸ’¬ Soporte

Para preguntas o problemas:
1. Revisar la documentaciÃ³n en `pipelines/README.md`
2. Verificar troubleshooting en esta guÃ­a
3. Revisar logs de ejecuciÃ³n

---

## ğŸ“„ Licencia

[Especificar licencia del proyecto]

---

**Ãšltima actualizaciÃ³n**: 2025-10-21

**Autor**: PHD Research Team

**VersiÃ³n**: 3.0 (ReorganizaciÃ³n modular + Pipeline LSTM optimizado)

**Tests**: 14/14 pasando en `test/test_lstm_sequences.py`
