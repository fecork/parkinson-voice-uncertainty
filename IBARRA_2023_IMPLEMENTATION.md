# Implementaci√≥n Completa seg√∫n Ibarra et al. (2023)

## üìÑ Referencia
**"Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation"**

---

## ‚úÖ Cumplimiento del Paper

### 1. Preprocesamiento de Datos ‚úì

| Especificaci√≥n | Implementaci√≥n | Archivo |
|----------------|----------------|---------|
| Resampleo a 44.1 kHz | ‚úÖ | `modules/preprocessing.py:20` |
| Segmentos de 400ms con 50% solape | ‚úÖ | `modules/preprocessing.py:21-22` |
| Mel-spectrogramas: 65 bandas | ‚úÖ | `modules/preprocessing.py:23` |
| Hop length: 10ms | ‚úÖ | `modules/preprocessing.py:24` |
| Ventana FFT: 40ms (vocales sostenidas) | ‚úÖ | `modules/preprocessing.py:25` |
| Dimensiones: 65√ó41 px | ‚úÖ | `modules/preprocessing.py:26` |
| Amplitud en dB | ‚úÖ | `modules/preprocessing.py:130` |
| Normalizaci√≥n z-score | ‚úÖ | `modules/preprocessing.py:143` |

### 2. Validaci√≥n Cruzada 10-Fold ‚úì

| Especificaci√≥n | Implementaci√≥n | Archivo |
|----------------|----------------|---------|
| 10-fold CV | ‚úÖ | `modules/cnn_utils.py:224-298` |
| Estratificada por PD | ‚úÖ | `modules/cnn_utils.py:267` (StratifiedKFold) |
| Independiente por hablante | ‚úÖ | `modules/cnn_utils.py:246-257` |
| Sin fugas entre folds | ‚úÖ | Garantizado por agrupaci√≥n de subject_id |

**Funci√≥n principal:** `create_10fold_splits_by_speaker()`

### 3. Arquitectura 2D-CNN con Domain Adaptation ‚úì

| Componente | Especificaci√≥n | Implementaci√≥n | Archivo |
|------------|----------------|----------------|---------|
| Bloques convolucionales | Conv2D ‚Üí BN ‚Üí ReLU ‚Üí **MaxPool(3√ó3)** ‚Üí Dropout | ‚úÖ | `modules/cnn_model.py:419-434` |
| N√∫mero de bloques | 2 | ‚úÖ | `modules/cnn_model.py` |
| Cabeza PD | FC ‚Üí ReLU ‚Üí Dropout ‚Üí FC (softmax) | ‚úÖ | `modules/cnn_model.py:541-547` |
| Cabeza Dominio | FC ‚Üí ReLU ‚Üí Dropout ‚Üí FC (softmax) | ‚úÖ | `modules/cnn_model.py:552-558` |
| GRL | Gradient Reversal Layer | ‚úÖ | `modules/cnn_model.py:339-396` |
| P√©rdida total | L = L_PD + Œ±¬∑L_dom | ‚úÖ | `modules/cnn_training.py:608` |

**Modelo principal:** `CNN2D_DA` en `modules/cnn_model.py:501-591`

### 4. Optimizador y Learning Rate ‚úì

| Especificaci√≥n | Implementaci√≥n | Archivo |
|----------------|----------------|---------|
| Optimizador: SGD | ‚úÖ | `modules/cnn_training.py:1136-1138` |
| LR inicial: 0.1 | ‚úÖ | `train_cnn_da_kfold.py:90` (default) |
| Momentum: 0.9 | ‚úÖ | `modules/cnn_training.py:1137` |
| Weight decay: 1e-4 | ‚úÖ | `modules/cnn_training.py:1137` |
| LR scheduler | ‚úÖ StepLR (step=30, gamma=0.1) | `modules/cnn_training.py:1141-1143` |

### 5. Cross-Entropy Ponderada Autom√°tica ‚úì

| Especificaci√≥n | Implementaci√≥n | Archivo |
|----------------|----------------|---------|
| Detecci√≥n autom√°tica de desbalance | ‚úÖ | `modules/cnn_utils.py:130-159` |
| Pesos para tarea PD | ‚úÖ | `modules/cnn_training.py:1116` |
| Pesos para tarea de dominio | ‚úÖ | `modules/cnn_training.py:1119` |
| Threshold: 40% | ‚úÖ | `modules/cnn_utils.py:132` (threshold=0.4) |

**Funci√≥n principal:** `compute_class_weights_auto()` en `modules/cnn_utils.py:130-159`

### 6. Lambda de GRL ‚úì

| Especificaci√≥n | Interpretaci√≥n | Implementaci√≥n | Archivo |
|----------------|----------------|----------------|---------|
| Lambda GRL | **Constante** (paper no especifica schedule) | ‚úÖ Œª = 1.0 | `modules/cnn_training.py:1152-1153` |

**Nota:** El paper menciona GRL pero no especifica schedule de Œª. Implementamos valor constante como en DA est√°ndar.

### 7. M√©tricas de Evaluaci√≥n ‚úì

| M√©trica | Implementaci√≥n | Archivo |
|---------|----------------|---------|
| Accuracy | ‚úÖ | `modules/cnn_training.py:636` |
| Precision | ‚úÖ | `modules/cnn_training.py:721` |
| Recall | ‚úÖ | `modules/cnn_training.py:722` |
| F1-Score | ‚úÖ | `modules/cnn_training.py:638` |
| Mean ¬± Std (K-fold) | ‚úÖ | `modules/cnn_training.py:1197-1198` |

### 8. Agregaci√≥n por Paciente ‚úì

| Especificaci√≥n | Implementaci√≥n | Archivo |
|----------------|----------------|---------|
| Predicci√≥n por espectrograma | ‚úÖ | `modules/cnn_training.py:939` |
| Agregaci√≥n por subject_id | ‚úÖ | `modules/cnn_training.py:950-954` |
| Probabilidad conjunta | ‚úÖ | `modules/cnn_training.py:962` (promedio) |

**Funci√≥n principal:** `evaluate_by_patient_da()` en `modules/cnn_training.py:907-994`

---

## üöÄ Uso

### Opci√≥n A: Entrenamiento Simple (Train/Val/Test)

Usar el notebook `parkinson_voice_analysis.ipynb` - **Celda 17** tiene la configuraci√≥n correcta seg√∫n Ibarra 2023.

### Opci√≥n B: 10-Fold Cross-Validation (Recomendado)

```bash
python train_cnn_da_kfold.py \
    --hc_dir data/vowels_healthy \
    --pd_dir data/vowels_pk \
    --n_folds 10 \
    --batch_size 32 \
    --lr 0.1 \
    --lambda_grl 1.0 \
    --epochs 100 \
    --output_dir results/cnn_da_kfold
```

**Par√°metros principales:**
- `--n_folds`: N√∫mero de folds (default: 10)
- `--batch_size`: Tama√±o de batch (paper sugiere: 16, 32, 64)
- `--lr`: Learning rate inicial (paper: 0.1)
- `--lambda_grl`: Lambda constante para GRL (default: 1.0)
- `--dropout_conv`: Dropout convolucional (paper: 0.2 o 0.5, default: 0.3)
- `--dropout_fc`: Dropout FC (paper: 0.2 o 0.5, default: 0.5)

---

## üìä Resultados

El script de 10-fold CV genera:
- `results/cnn_da_kfold/kfold_results.json`: M√©tricas agregadas (mean ¬± std)
- `results/cnn_da_kfold/fold_X/`: Modelos y m√©tricas por fold
- `results/cnn_da_kfold/config.json`: Configuraci√≥n utilizada

---

## üîç Diferencias Respecto al Paper (Justificadas)

### 1. Transfer Learning NO Implementado
**Raz√≥n:** No tenemos dataset SVDD (sano vs patolog√≠a de voz) para pre-entrenamiento.  
**Soluci√≥n futura:** Agregar cuando est√© disponible SVDD.

### 2. B√∫squeda de Hiperpar√°metros (Talos) NO Implementada
**Raz√≥n:** El paper usa Talos para buscar en espacio de hiperpar√°metros. Complejidad alta.  
**Soluci√≥n actual:** Usamos hiperpar√°metros razonables dentro del espacio del paper:
- Batch: 32 (paper: 16/32/64)
- Dropout conv: 0.3 (paper: 0.2/0.5)
- Dropout FC: 0.5 (paper: 0.2/0.5)

### 3. Lambda Schedule
**Interpretaci√≥n:** Paper menciona GRL pero no especifica schedule de Œª.  
**Implementaci√≥n:** Œª = 1.0 constante (est√°ndar en DA, m√°s conservador que schedule progresivo).

---

## üìù Archivos Modificados

### Nuevos archivos:
- `train_cnn_da_kfold.py`: Script principal para 10-fold CV
- `IBARRA_2023_IMPLEMENTATION.md`: Este documento

### Archivos modificados:
- `modules/cnn_utils.py`:
  - `create_10fold_splits_by_speaker()`: Splits K-fold estratificados
  - `compute_class_weights_auto()`: Detecci√≥n autom√°tica de desbalance
- `modules/cnn_training.py`:
  - `train_model_da()`: Agregado soporte para `lr_scheduler`
  - `train_model_da_kfold()`: Nueva funci√≥n para K-fold CV completo
- `parkinson_voice_analysis.ipynb`:
  - Celda 17: Configuraci√≥n actualizada (SGD LR=0.1, scheduler, pesos autom√°ticos, lambda constante)
  - Celda 20: Resumen actualizado con cumplimiento del paper

---

## ‚úÖ Checklist de Cumplimiento

- [x] Preprocesamiento: 44.1kHz, 400ms, 50% solape, Mel 65√ó41, z-score
- [x] 10-fold CV estratificada independiente por hablante
- [x] Arquitectura 2D-CNN-DA con MaxPool 3√ó3
- [x] SGD con LR inicial 0.1
- [x] LR scheduler (StepLR)
- [x] Cross-entropy ponderada autom√°tica (PD + dominio)
- [x] Lambda GRL constante = 1.0
- [x] M√©tricas: accuracy, precision, recall, F1
- [x] Agregaci√≥n por paciente
- [x] Reportar mean ¬± std sobre K folds
- [ ] Transfer Learning desde SVDD (pendiente: no hay dataset)
- [ ] B√∫squeda de hiperpar√°metros con Talos (pendiente: complejidad)

---

## üìö Referencias

```bibtex
@article{ibarra2023towards,
  title={Towards a Corpus (and Language)-Independent Screening of Parkinson's Disease from Voice and Speech through Domain Adaptation},
  author={Ibarra, et al.},
  year={2023}
}
```

---

## üë®‚Äçüíª Autor

Implementaci√≥n realizada siguiendo estrictamente las especificaciones del paper de Ibarra et al. (2023).

**Fecha:** Octubre 2025

