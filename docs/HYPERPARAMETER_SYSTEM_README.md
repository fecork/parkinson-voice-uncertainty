# Sistema de ConfiguraciÃ³n de HiperparÃ¡metros: Ibarra vs Optuna

## ğŸ¯ **DescripciÃ³n**

Este sistema permite elegir fÃ¡cilmente entre usar los hiperparÃ¡metros exactos del paper de Ibarra 2023 o los mejores hiperparÃ¡metros encontrados por Optuna, sin necesidad de modificar cÃ³digo manualmente.

## ğŸ“š **HiperparÃ¡metros de Ibarra (Paper)**

```python
# Valores exactos del paper de Ibarra 2023
kernel_size_1 = 6
kernel_size_2 = 9
depth_CL = 64          # filters_2
neurons_MLP = 32       # dense_units
drop_out = 0.2         # p_drop_conv
batch_size = 64
learning_rate = 0.1
momentum = 0.9
```

## ğŸ” **HiperparÃ¡metros de Optuna (Optimizados)**

```python
# Mejores valores encontrados por Optuna
kernel_size_1 = 4      # Optimizado
kernel_size_2 = 9      # Igual a Ibarra
filters_1 = 128        # Optimizado
filters_2 = 32         # Optimizado
dense_units = 64       # Optimizado
p_drop_conv = 0.2      # Igual a Ibarra
batch_size = 32        # Optimizado
learning_rate = 0.0005379125214937586  # Optimizado
```

## ğŸš€ **Uso RÃ¡pido**

### **OpciÃ³n 1: En el Notebook**

1. **Reemplaza la celda de configuraciÃ³n** con la celda del selector:

```python
# ============================================================
# SELECTOR DE HIPERPARÃMETROS: IBARRA vs OPTUNA
# ============================================================

# ğŸ”§ CONFIGURACIÃ“N PRINCIPAL - CAMBIA ESTE VALOR
USE_IBARRA_HYPERPARAMETERS = True  # True = Ibarra, False = Optuna

# ... resto del cÃ³digo del selector ...
```

2. **Cambia el valor** de `USE_IBARRA_HYPERPARAMETERS`:
   - `True` = Usar parÃ¡metros exactos del paper de Ibarra
   - `False` = Usar mejores parÃ¡metros de Optuna

3. **Ejecuta la celda** y el resto del notebook usarÃ¡ automÃ¡ticamente los parÃ¡metros seleccionados.

### **OpciÃ³n 2: En CÃ³digo Python**

```python
from modules.core.hyperparameter_config import get_hyperparameters

# Usar parÃ¡metros de Ibarra
ibarra_params = get_hyperparameters(use_ibarra=True)

# Usar parÃ¡metros de Optuna
optuna_params = get_hyperparameters(use_ibarra=False)

# Crear modelo
model = CNN2D(
    kernel_size_1=ibarra_params["kernel_size_1"],
    kernel_size_2=ibarra_params["kernel_size_2"],
    filters_1=ibarra_params["filters_1"],
    filters_2=ibarra_params["filters_2"],
    dense_units=ibarra_params["dense_units"],
    p_drop_conv=ibarra_params["p_drop_conv"],
    p_drop_fc=ibarra_params["p_drop_fc"],
)
```

## ğŸ“ **Archivos del Sistema**

```
modules/core/
â”œâ”€â”€ hyperparameter_config.py          # Sistema principal
config/
â”œâ”€â”€ hyperparameter_config.json        # ConfiguraciÃ³n guardada
research/
â”œâ”€â”€ hyperparameter_selector_cell.py   # Celda para notebook
â”œâ”€â”€ model_creation_cell.py            # Celda de creaciÃ³n de modelo
â”œâ”€â”€ training_config_cell.py           # Celda de configuraciÃ³n de entrenamiento
â”œâ”€â”€ notebook_integration_cells.py     # Todas las celdas para copiar
examples/
â”œâ”€â”€ hyperparameter_usage_example.py   # Ejemplos de uso
test/
â”œâ”€â”€ test_hyperparameter_system.py     # Pruebas unitarias
```

## ğŸ”§ **ConfiguraciÃ³n Avanzada**

### **GestiÃ³n de ConfiguraciÃ³n**

```python
from modules.core.hyperparameter_config import HyperparameterManager

manager = HyperparameterManager()

# Guardar configuraciÃ³n para usar Ibarra
manager.save_config(use_ibarra=True)

# Guardar configuraciÃ³n para usar Optuna
manager.save_config(use_ibarra=False)

# Cargar configuraciÃ³n guardada
config = manager.load_config()
```

### **ComparaciÃ³n de ParÃ¡metros**

```python
from modules.core.hyperparameter_config import compare_hyperparameters

# Mostrar tabla comparativa
compare_hyperparameters()
```

## ğŸ“Š **Tabla Comparativa**

| **ParÃ¡metro** | **Ibarra 2023** | **Optuna** | **Diferencia** |
|---------------|-----------------|------------|----------------|
| kernel_size_1 | 6 | 4 | -2 (mÃ¡s pequeÃ±o) |
| kernel_size_2 | 9 | 9 | 0 (igual) |
| filters_1 | 32 | 128 | +96 (mÃ¡s filtros) |
| filters_2 | 64 | 32 | -32 (menos filtros) |
| dense_units | 32 | 64 | +32 (mÃ¡s neuronas) |
| p_drop_conv | 0.2 | 0.2 | 0 (igual) |
| p_drop_fc | 0.5 | 0.5 | 0 (igual) |
| batch_size | 64 | 32 | -32 (menos muestras) |
| learning_rate | 0.1 | 0.0005 | -0.0995 (mucho menor) |

## ğŸ§ª **Pruebas**

```bash
# Ejecutar pruebas unitarias
python test/test_hyperparameter_system.py

# Ejecutar ejemplo de uso
python examples/hyperparameter_usage_example.py
```

## ğŸ’¡ **Ventajas del Sistema**

### **âœ… Flexibilidad**
- Cambio fÃ¡cil entre Ibarra y Optuna
- Sin modificaciÃ³n manual de cÃ³digo
- ConfiguraciÃ³n persistente

### **âœ… Transparencia**
- ComparaciÃ³n clara entre ambos enfoques
- DocumentaciÃ³n de diferencias
- Trazabilidad de parÃ¡metros

### **âœ… Robustez**
- Fallback automÃ¡tico a Ibarra si Optuna falla
- ValidaciÃ³n de parÃ¡metros
- Manejo de errores

### **âœ… Facilidad de Uso**
- Una sola variable para cambiar (`USE_IBARRA_HYPERPARAMETERS`)
- Variables globales preparadas (`BEST_PARAMS`)
- IntegraciÃ³n transparente con notebooks

## ğŸ¯ **Casos de Uso**

### **1. Reproducibilidad del Paper**
```python
USE_IBARRA_HYPERPARAMETERS = True  # Usar valores exactos del paper
```

### **2. OptimizaciÃ³n de Rendimiento**
```python
USE_IBARRA_HYPERPARAMETERS = False  # Usar mejores valores de Optuna
```

### **3. ComparaciÃ³n de MÃ©todos**
```python
# Entrenar con Ibarra
USE_IBARRA_HYPERPARAMETERS = True
# ... entrenar modelo ...

# Entrenar con Optuna
USE_IBARRA_HYPERPARAMETERS = False
# ... entrenar modelo ...

# Comparar resultados
```

## ğŸ”„ **MigraciÃ³n desde CÃ³digo Existente**

### **Antes:**
```python
# Valores hardcodeados
best_model = CNN2D(
    kernel_size_1=4,
    kernel_size_2=9,
    filters_1=128,
    filters_2=32,
    # ... mÃ¡s parÃ¡metros
)
```

### **DespuÃ©s:**
```python
# Valores dinÃ¡micos
BEST_PARAMS = get_hyperparameters(use_ibarra=True)  # o False

best_model = CNN2D(
    kernel_size_1=BEST_PARAMS["kernel_size_1"],
    kernel_size_2=BEST_PARAMS["kernel_size_2"],
    filters_1=BEST_PARAMS["filters_1"],
    filters_2=BEST_PARAMS["filters_2"],
    # ... mÃ¡s parÃ¡metros
)
```

## ğŸš¨ **Troubleshooting**

### **Error: "BEST_PARAMS no estÃ¡ definido"**
- Ejecuta primero la celda del selector de hiperparÃ¡metros

### **Error: "No se encontraron resultados de Optuna"**
- El sistema usarÃ¡ automÃ¡ticamente los parÃ¡metros de Ibarra como fallback

### **Error: "MÃ³dulo no encontrado"**
- AsegÃºrate de que el path del proyecto estÃ© correctamente configurado

## ğŸ“ **Notas Importantes**

1. **Los parÃ¡metros de Ibarra son exactos** del paper de 2023
2. **Los parÃ¡metros de Optuna son optimizados** para tu dataset especÃ­fico
3. **El sistema es retrocompatible** con cÃ³digo existente
4. **La configuraciÃ³n se guarda automÃ¡ticamente** en `config/hyperparameter_config.json`

## ğŸ‰ **ConclusiÃ³n**

Este sistema te permite:
- âœ… **Reproducir exactamente** el paper de Ibarra
- âœ… **Usar parÃ¡metros optimizados** de Optuna
- âœ… **Cambiar fÃ¡cilmente** entre ambos enfoques
- âœ… **Comparar resultados** de manera transparente
- âœ… **Mantener cÃ³digo limpio** y organizado

**Â¡Solo cambia `USE_IBARRA_HYPERPARAMETERS = True/False` y listo!** ğŸš€
