#!/usr/bin/env python3
"""
Ejemplo de uso del sistema de configuraci√≥n de hiperpar√°metros.
"""

import sys
from pathlib import Path

# Agregar m√≥dulos al path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from modules.core.hyperparameter_config import (
    HyperparameterManager,
    get_hyperparameters,
    compare_hyperparameters,
)


def example_ibarra_usage():
    """Ejemplo de uso con par√°metros de Ibarra."""
    print("=" * 80)
    print("üìö EJEMPLO: USANDO PAR√ÅMETROS DE IBARRA")
    print("=" * 80)

    # Opci√≥n 1: Usar funci√≥n de conveniencia
    ibarra_params = get_hyperparameters(use_ibarra=True)

    print("Par√°metros de Ibarra obtenidos:")
    for key, value in ibarra_params.items():
        print(f"  {key}: {value}")

    return ibarra_params


def example_optuna_usage():
    """Ejemplo de uso con par√°metros de Optuna."""
    print("\n" + "=" * 80)
    print("üîç EJEMPLO: USANDO PAR√ÅMETROS DE OPTUNA")
    print("=" * 80)

    # Opci√≥n 2: Usar manager directamente
    manager = HyperparameterManager()

    # Buscar archivos de Optuna
    optuna_paths = [
        Path("checkpoints/cnn2d_optuna_best_params.json"),
        Path("results/cnn_optuna_optimization/best_params.json"),
        Path("checkpoints/cnn2d_optuna_trials.json"),
    ]

    optuna_path = None
    for path in optuna_paths:
        if path.exists():
            optuna_path = path
            break

    if optuna_path:
        print(f"Usando archivo de Optuna: {optuna_path}")
        optuna_params = manager.get_optuna_hyperparameters(optuna_path)
    else:
        print("No se encontr√≥ archivo de Optuna, usando Ibarra como fallback")
        optuna_params = manager.get_optuna_hyperparameters()

    print("Par√°metros de Optuna obtenidos:")
    for key, value in optuna_params.items():
        print(f"  {key}: {value}")

    return optuna_params


def example_config_management():
    """Ejemplo de gesti√≥n de configuraci√≥n."""
    print("\n" + "=" * 80)
    print("‚öôÔ∏è  EJEMPLO: GESTI√ìN DE CONFIGURACI√ìN")
    print("=" * 80)

    manager = HyperparameterManager()

    # Guardar configuraci√≥n para usar Ibarra
    print("Guardando configuraci√≥n para usar Ibarra...")
    manager.save_config(use_ibarra=True)

    # Cargar configuraci√≥n
    print("Cargando configuraci√≥n...")
    config = manager.load_config()
    print(f"Configuraci√≥n cargada: {config}")

    # Cambiar a Optuna
    print("Cambiando a Optuna...")
    manager.save_config(use_ibarra=False)

    # Cargar nueva configuraci√≥n
    config = manager.load_config()
    print(f"Nueva configuraci√≥n: {config}")


def example_model_creation():
    """Ejemplo de creaci√≥n de modelo con par√°metros seleccionados."""
    print("\n" + "=" * 80)
    print("üèóÔ∏è  EJEMPLO: CREACI√ìN DE MODELO")
    print("=" * 80)

    # Simular selecci√≥n de par√°metros
    use_ibarra = True  # Cambiar a False para usar Optuna

    if use_ibarra:
        print("Usando par√°metros de Ibarra...")
        params = get_hyperparameters(use_ibarra=True)
    else:
        print("Usando par√°metros de Optuna...")
        params = get_hyperparameters(use_ibarra=False)

    # Simular creaci√≥n de modelo (sin PyTorch para el ejemplo)
    print(f"\nCreando modelo CNN2D con:")
    print(f"  - kernel_size_1: {params['kernel_size_1']}")
    print(f"  - kernel_size_2: {params['kernel_size_2']}")
    print(f"  - filters_1: {params['filters_1']}")
    print(f"  - filters_2: {params['filters_2']}")
    print(f"  - dense_units: {params['dense_units']}")
    print(f"  - p_drop_conv: {params['p_drop_conv']}")
    print(f"  - p_drop_fc: {params['p_drop_fc']}")
    print(f"  - batch_size: {params['batch_size']}")
    print(f"  - learning_rate: {params['learning_rate']}")

    return params


def example_notebook_integration():
    """Ejemplo de c√≥mo integrar en un notebook."""
    print("\n" + "=" * 80)
    print("üìì EJEMPLO: INTEGRACI√ìN EN NOTEBOOK")
    print("=" * 80)

    print("""
# CELDA 1: Selector de hiperpar√°metros
from modules.core.hyperparameter_config import get_hyperparameters

# Configuraci√≥n - CAMBIA ESTE VALOR
USE_IBARRA_HYPERPARAMETERS = True  # True = Ibarra, False = Optuna

# Obtener hiperpar√°metros
BEST_PARAMS = get_hyperparameters(use_ibarra=USE_IBARRA_HYPERPARAMETERS)
HYPERPARAMETER_SOURCE = "Ibarra 2023" if USE_IBARRA_HYPERPARAMETERS else "Optuna"

print(f"Usando par√°metros de: {HYPERPARAMETER_SOURCE}")
print(f"Batch size: {BEST_PARAMS['batch_size']}")
print(f"Learning rate: {BEST_PARAMS['learning_rate']}")

# CELDA 2: Crear modelo
from modules.models.cnn2d.model import CNN2D

model = CNN2D(
    n_classes=2,
    kernel_size_1=BEST_PARAMS["kernel_size_1"],
    kernel_size_2=BEST_PARAMS["kernel_size_2"],
    filters_1=BEST_PARAMS["filters_1"],
    filters_2=BEST_PARAMS["filters_2"],
    dense_units=BEST_PARAMS["dense_units"],
    p_drop_conv=BEST_PARAMS["p_drop_conv"],
    p_drop_fc=BEST_PARAMS["p_drop_fc"],
)

# CELDA 3: Configurar entrenamiento
import torch.optim as optim

optimizer = optim.SGD(
    model.parameters(),
    lr=BEST_PARAMS["learning_rate"],
    momentum=BEST_PARAMS["momentum"],
    weight_decay=BEST_PARAMS["weight_decay"]
)

scheduler = optim.lr_scheduler.StepLR(
    optimizer,
    step_size=BEST_PARAMS["step_size"],
    gamma=BEST_PARAMS["gamma"]
)
    """)


def main():
    """Funci√≥n principal con todos los ejemplos."""
    print("üöÄ EJEMPLOS DE USO DEL SISTEMA DE HIPERPAR√ÅMETROS")
    print("=" * 80)

    # Ejemplo 1: Usar Ibarra
    ibarra_params = example_ibarra_usage()

    # Ejemplo 2: Usar Optuna
    optuna_params = example_optuna_usage()

    # Ejemplo 3: Gesti√≥n de configuraci√≥n
    example_config_management()

    # Ejemplo 4: Creaci√≥n de modelo
    model_params = example_model_creation()

    # Ejemplo 5: Integraci√≥n en notebook
    example_notebook_integration()

    # Comparaci√≥n final
    print("\n" + "=" * 80)
    print("üìä COMPARACI√ìN FINAL")
    print("=" * 80)

    try:
        compare_hyperparameters()
    except Exception as e:
        print(f"Error en comparaci√≥n: {e}")

    print("\nüéâ TODOS LOS EJEMPLOS COMPLETADOS")
    print("=" * 80)


if __name__ == "__main__":
    main()
