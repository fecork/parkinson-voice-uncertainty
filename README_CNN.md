# CNN 2D para DetecciÃ³n de Parkinson

Pipeline completo de CNN 2D con MC Dropout y Grad-CAM siguiendo el estilo Ibarra/MARTA.

## ğŸ¯ CaracterÃ­sticas

- âœ… **Reutiliza pipeline existente**: No reprocesa, usa espectrogramas ya calculados
- âœ… **Split speaker-independent**: Evita data leakage
- âœ… **SpecAugment on-the-fly**: Solo durante entrenamiento
- âœ… **MC Dropout**: Inferencia con incertidumbre (30 muestras)
- âœ… **Grad-CAM**: Mapas de activaciÃ³n para explicabilidad
- âœ… **AgregaciÃ³n multinivel**: Segmento â†’ Archivo â†’ Paciente
- âœ… **Class weights**: Balanceo automÃ¡tico HC/PD
- âœ… **Early stopping**: Detiene cuando no mejora

## ğŸ“¦ MÃ³dulos Creados

### `modules/cnn_utils.py`
Utilidades que extienden el pipeline existente:
- `SpecAugment`: Transform on-the-fly
- `split_by_speaker()`: Split speaker-independent
- `create_dataloaders_from_existing()`: Crea loaders desde dataset existente
- `compute_class_weights_from_dataset()`: Calcula pesos para loss

### `modules/cnn_model.py`
Modelo y tÃ©cnicas de incertidumbre/explicabilidad:
- `CNN2D`: Red compacta (32â†’64 filtros, dropout 0.3/0.5)
- `mc_dropout_predict()`: Inferencia con MC Dropout
- `GradCAM`: GeneraciÃ³n de mapas de atenciÃ³n
- `get_last_conv_layer()`: Helper para Grad-CAM

### `modules/cnn_training.py`
Pipeline de entrenamiento:
- `EarlyStopping`: DetecciÃ³n de convergencia
- `train_one_epoch()`: Entrenamiento por Ã©poca
- `evaluate()`: EvaluaciÃ³n sin dropout
- `train_model()`: Pipeline completo con checkpoints
- `detailed_evaluation()`: MÃ©tricas y matriz de confusiÃ³n

### `modules/cnn_inference.py`
Inferencia con incertidumbre:
- `mc_dropout_inference()`: MC Dropout sobre dataset completo
- `aggregate_by_file()`: Agrega segmentos por archivo
- `aggregate_by_patient()`: Agrega por paciente (speaker)
- `analyze_uncertainty()`: EstadÃ­sticas de entropÃ­a/varianza
- `find_interesting_cases()`: Casos para anÃ¡lisis (aciertos/errores con alta/baja confianza)

### `modules/cnn_visualization.py`
Visualizaciones:
- `visualize_gradcam()`: Visualiza Grad-CAM individual
- `visualize_multiple_gradcam()`: MÃºltiples casos
- `visualize_interesting_cases_with_gradcam()`: Casos interesantes
- `plot_uncertainty_distribution()`: DistribuciÃ³n de incertidumbre
- `plot_aggregated_results()`: Resultados por archivo
- `plot_training_history()`: Curvas de entrenamiento
- `generate_visual_report()`: Reporte completo

## ğŸš€ Uso RÃ¡pido

```bash
# Entrenamiento bÃ¡sico
python train_cnn.py

# Con configuraciÃ³n personalizada
python train_cnn.py \
  --hc_dir data/vowels_healthy \
  --pd_dir data/vowels_pk \
  --batch_size 32 \
  --epochs 100 \
  --lr 1e-3 \
  --mc_samples 30 \
  --use_class_weights \
  --output_dir results/cnn_experiment_1
```

## âš™ï¸ ParÃ¡metros Principales

### Datos
- `--hc_dir`: Directorio con audios HC (default: `data/vowels_healthy`)
- `--pd_dir`: Directorio con audios PD (default: `data/vowels_pk`)
- `--train_ratio`: ProporciÃ³n train (default: 0.6)
- `--val_ratio`: ProporciÃ³n val (default: 0.15)
- `--test_ratio`: ProporciÃ³n test (default: 0.25)

### Modelo
- `--dropout_conv`: Dropout convolucional (default: 0.3)
- `--dropout_fc`: Dropout FC (default: 0.5)

### SpecAugment
- `--freq_mask`: Frequency masking (default: 8 bins)
- `--time_mask`: Time masking (default: 6 frames)
- `--spec_augment_prob`: Probabilidad (default: 0.5)

### Entrenamiento
- `--batch_size`: TamaÃ±o de batch (default: 32)
- `--epochs`: Ã‰pocas mÃ¡ximas (default: 100)
- `--lr`: Learning rate (default: 1e-3)
- `--patience`: Early stopping (default: 10)
- `--use_class_weights`: Flag para usar class weights

### MC Dropout
- `--mc_samples`: Muestras estocÃ¡sticas (default: 30)

## ğŸ“Š Output

El script genera en `output_dir`:

```
results/cnn_training/
â”œâ”€â”€ config.json                    # ConfiguraciÃ³n del experimento
â”œâ”€â”€ best_model.pth                 # Checkpoint del mejor modelo
â”œâ”€â”€ training_history.json          # MÃ©tricas por Ã©poca
â”œâ”€â”€ mc_dropout_results.npz         # Resultados MC Dropout (nivel segmento)
â”œâ”€â”€ file_level_results.npz         # Resultados agregados por archivo
â”œâ”€â”€ patient_level_results.npz      # Resultados agregados por paciente
â”œâ”€â”€ uncertainty_analysis.json      # AnÃ¡lisis de incertidumbre
â””â”€â”€ visualizations/
    â”œâ”€â”€ training_history.png       # Curvas loss/acc/F1
    â”œâ”€â”€ uncertainty_distribution.png  # DistribuciÃ³n de incertidumbre
    â”œâ”€â”€ aggregated_results.png     # Resultados por archivo
    â””â”€â”€ gradcam/
        â”œâ”€â”€ gradcam_correct_confident.png
        â”œâ”€â”€ gradcam_incorrect_uncertain.png
        â””â”€â”€ gradcam_incorrect_confident.png
```

## ğŸ”¬ Pipeline Detallado

### 1. Carga de Datos (Reutiliza preprocesamiento existente)
```python
hc_result = build_full_pipeline(hc_files)  # modules/dataset.py
pd_result = build_full_pipeline(pd_files)
combined_dataset = ConcatDataset([hc_result['torch_ds'], pd_result['torch_ds']])
```
**No reprocesa**: Usa `preprocessing.preprocess_audio_paper()` que ya genera espectrogramas (65Ã—41).

### 2. Split Speaker-Independent
```python
split_indices = split_by_speaker(all_metas, train_ratio=0.6, val_ratio=0.15)
```
Agrupa segmentos por `subject_id` y divide por speaker, no por archivo individual.

### 3. DataLoaders con SpecAugment
```python
loaders = create_dataloaders_from_existing(
    combined_dataset,
    split_indices,
    spec_augment_params={'freq_mask_param': 8, 'time_mask_param': 6, 'prob': 0.5}
)
```
SpecAugment se aplica **solo en train** como transform on-the-fly.

### 4. Entrenamiento
```python
training_results = train_model(
    model, train_loader, val_loader,
    optimizer, criterion, device,
    n_epochs=100, early_stopping_patience=10
)
```
Con early stopping por `val_loss`.

### 5. MC Dropout Inference
```python
mc_results = mc_dropout_inference(model, test_loader, device, n_samples=30)
# mc_results contiene: predictions, probabilities_mean, probabilities_std, entropy, variance
```

### 6. AgregaciÃ³n Multinivel
```python
file_results = aggregate_by_file(mc_results, aggregation_method='mean')
patient_results = aggregate_by_patient(mc_results, aggregation_method='mean')
```

### 7. Visualizaciones
```python
generate_visual_report(model, test_loader, mc_results, file_results, history, save_dir)
```
Genera todas las grÃ¡ficas incluyendo Grad-CAM de casos interesantes.

## ğŸ§ª Ejemplo de Uso en Notebook

```python
# En tu notebook despuÃ©s de tener los espectrogramas
from modules.dataset import build_full_pipeline
from modules.cnn_utils import split_by_speaker, create_dataloaders_from_existing
from modules.cnn_model import CNN2D
from modules.cnn_training import train_model
from modules.cnn_inference import mc_dropout_inference, aggregate_by_file
import torch

# 1. Cargar datos (reutiliza pipeline existente)
hc_result = build_full_pipeline(audio_files_hc)
pd_result = build_full_pipeline(audio_files_pd)

# 2. Combinar
from torch.utils.data import ConcatDataset
combined = ConcatDataset([hc_result['torch_ds'], pd_result['torch_ds']])
all_metas = hc_result['metadata'] + pd_result['metadata']

# 3. Split speaker-independent
splits = split_by_speaker(all_metas, seed=42)

# 4. DataLoaders con SpecAugment
loaders = create_dataloaders_from_existing(combined, splits, batch_size=32)

# 5. Modelo
model = CNN2D(n_classes=2, p_drop_conv=0.3, p_drop_fc=0.5)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# 6. Entrenar
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = torch.nn.CrossEntropyLoss()

results = train_model(
    model, loaders['train'], loaders['val'],
    optimizer, criterion, device,
    n_epochs=50, early_stopping_patience=10
)

# 7. MC Dropout en test
mc_results = mc_dropout_inference(model, loaders['test'], device, n_samples=30)

# 8. AgregaciÃ³n
file_results = aggregate_by_file(mc_results)

# 9. MÃ©tricas
from sklearn.metrics import classification_report
print(classification_report(
    file_results['file_labels'],
    file_results['file_predictions'],
    target_names=['HC', 'PD']
))
```

## ğŸ“‹ Checklist Papers Ibarra/MARTA

- âœ… Segmentos 400ms con 50% overlap
- âœ… Mel-spectrograms 65 bins Ã— 41 frames
- âœ… Ventana FFT 40ms para vocales (10ms hop)
- âœ… Z-score normalizaciÃ³n por espectrograma
- âœ… SpecAugment (freq mask + time mask)
- âœ… Split speaker-independent
- âœ… AgregaciÃ³n por archivo/paciente
- âœ… MC Dropout para incertidumbre
- âœ… Grad-CAM para explicabilidad

## ğŸ”§ Troubleshooting

### Error: "No module named 'modules.cnn_dataloader'"
**SoluciÃ³n**: El mÃ³dulo `cnn_dataloader.py` fue eliminado para evitar duplicaciÃ³n. Ahora usamos `cnn_utils.py` que reutiliza el pipeline existente.

### Advertencia: "Solo 1 speaker PD detectado"
**Causa**: El dataset PD solo tiene 1 speaker (1580).
**Impacto**: Causa data leakage porque el mismo speaker aparece en train/val/test.
**SoluciÃ³n ideal**: Conseguir mÃ¡s speakers PD para split real.
**Workaround actual**: Se usa el mismo speaker en todos los splits pero se reporta la advertencia.

### VRAM insuficiente
**SoluciÃ³n**: Reducir `--batch_size` (probar 16 u 8).

### Entrenamiento lento en CPU
**SoluciÃ³n**: 
- Reducir `--mc_samples` (probar 10-20)
- Usar GPU si estÃ¡ disponible
- Reducir `--epochs`

## ğŸ“ Referencias

- Ibarra et al.: Domain adaptation para Parkinson
- MARTA: Multi-task learning para speech disorders
- SpecAugment: Park et al., 2019
- MC Dropout: Gal & Ghahramani, 2016
- Grad-CAM: Selvaraju et al., 2017

