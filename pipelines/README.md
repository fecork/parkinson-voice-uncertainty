# ğŸš€ Pipelines de Entrenamiento

Esta carpeta contiene **pipelines completos end-to-end** para entrenar modelos CNN de detecciÃ³n de Parkinson.

## ğŸ¯ Â¿QuÃ© son los Pipelines?

Los pipelines son programas automatizados que ejecutan un flujo completo de trabajo desde la carga de datos hasta la generaciÃ³n de resultados finales. A diferencia de los mÃ³dulos (que son componentes individuales) o notebooks (que son interactivos), los pipelines:

- âœ… Se ejecutan desde lÃ­nea de comandos
- âœ… Procesan todo automÃ¡ticamente (sin intervenciÃ³n)
- âœ… Son reproducibles y configurables
- âœ… Ideales para producciÃ³n, experimentos batch, y HPC

---

## ğŸ“ Pipelines Disponibles

### 1. `train_cnn.py` - CNN2D sin Domain Adaptation

**Pipeline completo para modelo baseline con MC Dropout**

**Flujo**:
```
Datos â†’ Preprocesar â†’ Split por Speaker â†’ Entrenar CNN2D â†’ 
Evaluar â†’ MC Dropout Inference â†’ Agregar por Archivo/Paciente â†’ 
Visualizaciones
```

**CaracterÃ­sticas**:
- Modelo: CNN2D simple (single-head)
- ValidaciÃ³n: Train/Val/Test split speaker-independent
- Incluye: MC Dropout para cuantificaciÃ³n de incertidumbre
- Salida: `results/cnn_training/`

**Uso** (desde la raÃ­z del proyecto):
```bash
# BÃ¡sico
python pipelines/train_cnn.py

# Personalizado
python pipelines/train_cnn.py \
    --hc_dir data/vowels_healthy \
    --pd_dir data/vowels_pk \
    --epochs 100 \
    --lr 0.001 \
    --mc_samples 30 \
    --output_dir results/my_experiment
```

**ParÃ¡metros principales**:
- `--hc_dir`: Directorio con datos Healthy
- `--pd_dir`: Directorio con datos Parkinson
- `--epochs`: NÃºmero mÃ¡ximo de Ã©pocas (default: 100)
- `--lr`: Learning rate (default: 0.001)
- `--batch_size`: TamaÃ±o de batch (default: 32)
- `--mc_samples`: Muestras para MC Dropout (default: 30)
- `--patience`: Early stopping patience (default: 10)
- `--output_dir`: Directorio de salida (default: results/cnn_training)

**Tiempo estimado**: ~15-20 minutos (CPU)

---

### 2. `train_cnn_da_kfold.py` - CNN2D_DA con 10-Fold CV

**Pipeline completo segÃºn Ibarra et al. (2023) con validaciÃ³n cruzada**

**Flujo**:
```
Datos â†’ Preprocesar â†’ 10-Fold Split por Speaker â†’ 
Para cada Fold: Entrenar CNN2D_DA con GRL â†’ 
Agregar MÃ©tricas â†’ Reportar Mean Â± Std
```

**CaracterÃ­sticas**:
- Modelo: CNN2D_DA (dual-head con Gradient Reversal Layer)
- ValidaciÃ³n: 10-fold cross-validation speaker-independent
- SegÃºn paper: SGD, LR=0.1, StepLR scheduler
- Salida: `results/cnn_da_kfold/`

**Uso** (desde la raÃ­z del proyecto):
```bash
# BÃ¡sico
python pipelines/train_cnn_da_kfold.py

# Personalizado
python pipelines/train_cnn_da_kfold.py \
    --hc_dir data/vowels_healthy \
    --pd_dir data/vowels_pk \
    --n_folds 10 \
    --epochs 100 \
    --lr 0.1 \
    --alpha 1.0 \
    --lambda_grl 1.0 \
    --output_dir results/my_kfold_experiment
```

**ParÃ¡metros principales**:
- `--hc_dir`: Directorio con datos Healthy
- `--pd_dir`: Directorio con datos Parkinson
- `--n_folds`: NÃºmero de folds (default: 10)
- `--epochs`: NÃºmero mÃ¡ximo de Ã©pocas por fold (default: 100)
- `--lr`: Learning rate inicial (default: 0.1, segÃºn paper)
- `--alpha`: Peso de pÃ©rdida de dominio (default: 1.0)
- `--lambda_grl`: Lambda constante para GRL (default: 1.0)
- `--batch_size`: TamaÃ±o de batch (default: 32)
- `--output_dir`: Directorio de salida (default: results/cnn_da_kfold)

**Tiempo estimado**: ~2-3 horas (CPU, 10 folds Ã— 100 epochs)

---

## ğŸ”„ Pipelines vs Notebooks vs Modules

| Aspecto | Pipelines | Notebooks | Modules |
|---------|-----------|-----------|---------|
| **UbicaciÃ³n** | `pipelines/` | RaÃ­z del proyecto | `modules/` |
| **Tipo** | Scripts CLI | Jupyter | LibrerÃ­as Python |
| **EjecuciÃ³n** | `python pipelines/xxx.py` | Celda por celda | Se importan |
| **PropÃ³sito** | AutomatizaciÃ³n completa | ExploraciÃ³n interactiva | CÃ³digo reutilizable |
| **CuÃ¡ndo usar** | ProducciÃ³n, batch, HPC | Desarrollo, anÃ¡lisis | Siempre (base) |
| **InteracciÃ³n** | No (desatendido) | SÃ­ (paso a paso) | N/A (componentes) |

---

## ğŸ’¡ Â¿CuÃ¡l Usar?

### Usa Pipelines cuando:
- âœ… Quieres entrenar sin supervisiÃ³n (ej. dejar corriendo toda la noche)
- âœ… Necesitas ejecutar mÃºltiples experimentos en batch
- âœ… EstÃ¡s en un servidor/cluster sin interfaz grÃ¡fica
- âœ… Quieres reproducibilidad exacta con parÃ¡metros guardados
- âœ… Necesitas el pipeline completo: datos â†’ modelo â†’ resultados â†’ visualizaciones

### Usa Notebooks cuando:
- âœ… EstÃ¡s explorando datos o probando ideas
- âœ… Quieres ver resultados intermedios paso a paso
- âœ… EstÃ¡s haciendo debugging
- âœ… Necesitas presentar resultados de forma visual
- âœ… Quieres modificar cÃ³digo y re-ejecutar rÃ¡pidamente

---

## ğŸ“Š Ejemplos de Uso

### Experimento RÃ¡pido (Baseline)
```bash
# Entrenar CNN2D baseline con configuraciÃ³n por defecto
python pipelines/train_cnn.py

# Ver resultados
ls results/cnn_training/
```

### Experimento con Diferentes HiperparÃ¡metros
```bash
# Probar diferentes learning rates
python pipelines/train_cnn.py --lr 0.001 --output_dir results/lr_001
python pipelines/train_cnn.py --lr 0.01  --output_dir results/lr_01
python pipelines/train_cnn.py --lr 0.1   --output_dir results/lr_1

# Comparar resultados
cat results/lr_*/test_metrics.json
```

### ValidaciÃ³n Cruzada Completa (Paper)
```bash
# 10-fold CV segÃºn Ibarra et al. (2023)
python pipelines/train_cnn_da_kfold.py \
    --n_folds 10 \
    --epochs 100 \
    --lr 0.1 \
    --output_dir results/paper_replication

# Ver mÃ©tricas agregadas
cat results/paper_replication/kfold_results.json
```

### Batch de Experimentos
```bash
# Probar mÃºltiples configuraciones
for dropout in 0.3 0.5 0.7; do
    python pipelines/train_cnn.py \
        --dropout_conv $dropout \
        --dropout_fc $dropout \
        --output_dir results/dropout_$dropout
done
```

---

## ğŸ” Estructura de Salida

### `train_cnn.py` genera:
```
results/cnn_training/
â”œâ”€â”€ config.json                     # ConfiguraciÃ³n usada
â”œâ”€â”€ best_model.pth                  # Mejor modelo entrenado
â”œâ”€â”€ training_history.json           # Historial de entrenamiento
â”œâ”€â”€ test_metrics.json               # MÃ©tricas en test set
â”œâ”€â”€ mc_dropout_results.npz          # Resultados MC Dropout
â”œâ”€â”€ file_level_results.npz          # AgregaciÃ³n por archivo
â”œâ”€â”€ patient_level_results.npz       # AgregaciÃ³n por paciente
â”œâ”€â”€ uncertainty_analysis.json       # AnÃ¡lisis de incertidumbre
â””â”€â”€ visualizations/                 # GrÃ¡ficas
    â”œâ”€â”€ training_history.png
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ uncertainty_distribution.png
    â””â”€â”€ ...
```

### `train_cnn_da_kfold.py` genera:
```
results/cnn_da_kfold/
â”œâ”€â”€ config.json                     # ConfiguraciÃ³n usada
â”œâ”€â”€ kfold_results.json              # MÃ©tricas agregadas (mean Â± std)
â”œâ”€â”€ fold_1/
â”‚   â”œâ”€â”€ best_model_da.pth
â”‚   â””â”€â”€ training_history.json
â”œâ”€â”€ fold_2/
â”‚   â””â”€â”€ ...
â””â”€â”€ fold_10/
    â””â”€â”€ ...
```

---

## ğŸ“š MÃ¡s InformaciÃ³n

- **Modules**: Ver `modules/README.md` para componentes individuales
- **Notebooks**: Ver notebooks en raÃ­z para exploraciÃ³n interactiva
- **DocumentaciÃ³n general**: Ver `README.md` en raÃ­z del proyecto

---

## ğŸ†˜ Ayuda

Para ver todos los parÃ¡metros disponibles:
```bash
python pipelines/train_cnn.py --help
python pipelines/train_cnn_da_kfold.py --help
```

Para reportar problemas o sugerencias, consulta la documentaciÃ³n principal del proyecto.

