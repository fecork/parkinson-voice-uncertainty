{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH7omjwwttPo"
   },
   "source": [
    "# CNN 2D para Detección de Parkinson (Baseline con Augmentation + Optuna)\n",
    "## Baseline Model - Train/Val/Test Split + Hyperparameter Optimization\n",
    "\n",
    "Este notebook entrena un modelo **CNN2D simple** (sin Domain Adaptation) para clasificación binaria Parkinson vs Healthy **usando data augmentation** y **optimización automática de hiperparámetros con Optuna**.\n",
    "\n",
    "### Pipeline:\n",
    "1. **Setup**: Configuración del entorno\n",
    "2. **Data Loading**: Carga de datos CON augmentation\n",
    "3. **Split**: Train/Val/Test estratificado (70/15/15)\n",
    "4. **Optuna Optimization**: Optimización automática de hiperparámetros (20 configuraciones)\n",
    "5. **Final Training**: Re-entrenamiento con mejores hiperparámetros + early stopping\n",
    "6. **Evaluation**: Métricas completas en test set\n",
    "7. **Visualization**: Gráficas de progreso y resultados\n",
    "\n",
    "### Arquitectura:\n",
    "Este modelo usa el **mismo Feature Extractor** que CNN2D_DA (arquitectura Ibarra 2023) pero **sin Domain Adaptation**:\n",
    "- 2 bloques Conv2D → BN → ReLU → MaxPool(3×3) → Dropout\n",
    "- Solo cabeza de clasificación PD (sin GRL ni cabeza de dominio)\n",
    "\n",
    "### Data Augmentation:\n",
    "- Pitch shifting\n",
    "- Time stretching\n",
    "- Noise injection\n",
    "- SpecAugment (máscaras de frecuencia/tiempo)\n",
    "- Factor: ~5x más datos\n",
    "\n",
    "### Comparación:\n",
    "- **Este notebook**: Modelo CNN2D con augmentation (mejora generalización)\n",
    "- **cnn_da_training.ipynb**: Modelo CNN2D_DA sin augmentation (paper exacto)\n",
    "- El augmentation permite entrenar con más datos y mejorar robustez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158385,
     "status": "ok",
     "timestamp": 1761427869243,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "LYIbsc8VBC2x",
    "outputId": "8d1830a6-6a36-49f1-89f0-fa233a3a12f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "$ git config --global --add safe.directory /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty\n",
      "\n",
      "$ git -C /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty fetch --all --prune\n",
      "Fetching origin\n",
      "\n",
      "$ git -C /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty branch --show-current\n",
      "feature/feature/firstTraining\n",
      "\n",
      "$ git -C /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty checkout feature/feature/firstTraining\n",
      "M\t.gitignore\n",
      "M\t.ipynb_checkpoints/parkinson_voice_analysis-checkpoint.ipynb\n",
      "M\tREADME.md\n",
      "M\tbash.exe.stackdump\n",
      "M\tdata/README.md\n",
      "M\tdata/vowels_healthy/healthy_diverse_metadata.json\n",
      "M\tdata_preparation/sample_healthy_data.py\n",
      "M\tdata_preparation/verify_sampling.py\n",
      "M\tdocs/CONFIGURACION_VALIDATION.md\n",
      "M\tdocs/CORRECCIONES_APLICADAS.md\n",
      "M\tdocs/MIGRATION_TALOS_TO_OPTUNA.md\n",
      "M\tdocs/TEST_RESULTS_SUMMARY.md\n",
      "M\texamples/environment_example.py\n",
      "M\tmodules/README.md\n",
      "M\tmodules/__init__.py\n",
      "M\tmodules/core/README.md\n",
      "M\tmodules/core/__init__.py\n",
      "M\tmodules/core/cnn2d_optuna_wrapper.py\n",
      "M\tmodules/core/data_augmentation.ipynb\n",
      "M\tmodules/core/dataset.py\n",
      "M\tmodules/core/dependency_manager.py\n",
      "M\tmodules/core/deprecated/README.md\n",
      "M\tmodules/core/deprecated/cnn2d_talos_wrapper.py\n",
      "M\tmodules/core/deprecated/talos_analysis.py\n",
      "M\tmodules/core/deprecated/talos_evaluator.py\n",
      "M\tmodules/core/deprecated/talos_optimization.py\n",
      "M\tmodules/core/deprecated/talos_optimization_models.py\n",
      "M\tmodules/core/deprecated/talos_visualization.py\n",
      "M\tmodules/core/environment.py\n",
      "M\tmodules/core/model_evaluation.py\n",
      "M\tmodules/core/notebook_setup.py\n",
      "M\tmodules/core/optuna_optimization.py\n",
      "M\tmodules/core/preprocessing.py\n",
      "M\tmodules/core/sequence_dataset.py\n",
      "M\tmodules/core/utils.py\n",
      "M\tmodules/core/visualization.py\n",
      "M\tmodules/data/__init__.py\n",
      "M\tmodules/data/augmentation.py\n",
      "M\tmodules/data/cache_utils.py\n",
      "M\tmodules/models/__init__.py\n",
      "M\tmodules/models/cnn1d/__init__.py\n",
      "M\tmodules/models/cnn1d/model.py\n",
      "M\tmodules/models/cnn1d/training.py\n",
      "M\tmodules/models/cnn1d/visualization.py\n",
      "M\tmodules/models/cnn2d/__init__.py\n",
      "M\tmodules/models/cnn2d/inference.py\n",
      "M\tmodules/models/cnn2d/model.py\n",
      "M\tmodules/models/cnn2d/training.py\n",
      "M\tmodules/models/cnn2d/utils.py\n",
      "M\tmodules/models/cnn2d/visualization.py\n",
      "M\tmodules/models/common/__init__.py\n",
      "M\tmodules/models/common/layers.py\n",
      "M\tmodules/models/common/training_utils.py\n",
      "M\tmodules/models/common/visualization_utils.py\n",
      "M\tmodules/models/lstm_da/__init__.py\n",
      "M\tmodules/models/lstm_da/model.py\n",
      "M\tmodules/models/lstm_da/training.py\n",
      "M\tmodules/models/lstm_da/visualization.py\n",
      "M\tmodules/models/uncertainty/__init__.py\n",
      "M\tmodules/models/uncertainty/loss.py\n",
      "M\tmodules/models/uncertainty/model.py\n",
      "M\tmodules/models/uncertainty/training.py\n",
      "M\tmodules/models/uncertainty/visualization.py\n",
      "M\tnotebooks/cnn_uncertainty_training.ipynb\n",
      "M\tnotebooks/colab_setup_example.py\n",
      "M\tnotebooks/data_augmentation.ipynb\n",
      "M\tnotebooks/gradcam_inference.ipynb\n",
      "M\tnotebooks/svdd_data_preparation.ipynb\n",
      "M\tpipelines/README.md\n",
      "M\tpipelines/generate_lstm_sequences.py\n",
      "M\tpipelines/train_cnn.py\n",
      "M\tpipelines/train_cnn_da_kfold.py\n",
      "M\tpipelines/train_cnn_uncertainty.py\n",
      "M\tpipelines/train_lstm_da_kfold.py\n",
      "M\trequirements.txt\n",
      "M\tresearch/README.md\n",
      "M\tresearch/cnn1d_da_training.ipynb\n",
      "M\tresearch/cnn_da_training.ipynb\n",
      "M\tresearch/cnn_training.ipynb\n",
      "M\tresearch/colab_reload_fix.py\n",
      "M\tresearch/lstm_da_training.ipynb\n",
      "M\tresearch/verify_fix.py\n",
      "M\tresults/README.md\n",
      "M\tresults/cnn1d_da/test_metrics_1d_da.json\n",
      "M\tresults/cnn_da/test_metrics_da.json\n",
      "M\tresults/cnn_no_da/test_metrics.json\n",
      "M\tresults/cnn_talos_optimization/best_params.json\n",
      "M\tresults/cnn_talos_optimization/talos_scan_results.csv\n",
      "M\tresults/cnn_uncertainty/gradcam_config.json\n",
      "M\tresults/cnn_uncertainty/test_metrics_uncertainty.json\n",
      "M\ttest/Feature_Extractor_2D_CNN_Visualization.ipynb\n",
      "M\ttest/PAPER_VALIDATION_REPORT.md\n",
      "M\ttest/README.md\n",
      "M\ttest/README_TESTS.md\n",
      "M\ttest/deprecated/README.md\n",
      "M\ttest/deprecated/evaluate_talos.py\n",
      "M\ttest/deprecated/test_core_talos.py\n",
      "M\ttest/deprecated/test_talos_basic.py\n",
      "M\ttest/deprecated/test_talos_file_generation.py\n",
      "M\ttest/deprecated/test_talos_integration.py\n",
      "M\ttest/deprecated/test_talos_optimization.py\n",
      "M\ttest/deprecated/test_talos_real_files.py\n",
      "M\ttest/paper_requirements.json\n",
      "M\ttest/test_cnn1d_attention.py\n",
      "M\ttest/test_cnn1d_implementation.py\n",
      "M\ttest/test_cnn2d_optuna.py\n",
      "M\ttest/test_cnn_architectures.py\n",
      "M\ttest/test_environment.py\n",
      "M\ttest/test_gradcam_math.py\n",
      "M\ttest/test_grl_completo.py\n",
      "M\ttest/test_ibarra_implementation.py\n",
      "M\ttest/test_ibarra_preprocessing.py\n",
      "M\ttest/test_learning_rate_scheduler.py\n",
      "M\ttest/test_lstm_da_implementation.py\n",
      "M\ttest/test_lstm_sequences.py\n",
      "M\ttest/test_optuna_basic.py\n",
      "M\ttest/test_papeAlready on 'feature/feature/firstTraining'\n",
      "r_compliance.py\n",
      "M\ttest/test_uncertainty_math.py\n",
      "M\ttest/test_yarin_gal_implementation.py\n",
      "M\ttest/validate_paper_replication.py\n",
      "M\ttest/verify_labels.py\n",
      "\n",
      "$ git -C /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty pull origin feature/feature/firstTraining\n",
      "From https://github.com/fecork/parkinson-voice-uncertainty\n",
      " * branch            feature/feature/firstTraining -> FETCH_HEAD\n",
      "Already up to date.\n",
      "\n",
      "Instalando dependencias...\n",
      "$ python -m pip install -q optuna>=3.0.0\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 400.9/400.9 kB 6.5 MB/s eta 0:00:00\n",
      "\n",
      "$ python -m pip install -q torch>=1.9.0\n",
      "\n",
      "$ python -m pip install -q torchvision>=0.10.0\n",
      "\n",
      "$ python -m pip install -q scikit-learn>=1.0.0\n",
      "\n",
      "$ python -m pip install -q librosa>=0.8.1\n",
      "\n",
      "$ python -m pip install -q soundfile>=0.10.3\n",
      "\n",
      "$ python -m pip install -q -r /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/requirements.txt\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250.6/250.6 kB 6.1 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 106.4 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 70.7 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.7/76.7 kB 7.5 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.8/59.8 kB 4.6 MB/s eta 0:00:00\n",
      "\n",
      "Dependencias instaladas correctamente\n",
      "✅ Optuna 4.5.0 disponible\n",
      "No se activó autoreload: No module named 'imp'\n",
      "Repo listo en: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty\n",
      "$ git -C /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty branch --show-current\n",
      "feature/feature/firstTraining\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURACIÓN PARA GOOGLE COLAB\n",
    "# ============================================================\n",
    "# DESCOMENTA TODO EL BLOQUE SI EJECUTAS EN COLAB\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import os, sys, subprocess\n",
    "\n",
    "# Configuración - AJUSTA ESTOS VALORES SI ES NECESARIO\n",
    "COMPUTER_NAME = \"ZenBook\"\n",
    "PROJECT_DIR = \"parkinson-voice-uncertainty\"\n",
    "BRANCH = \"feature/feature/firstTraining\"\n",
    "\n",
    "BASE = \"/content/drive/Othercomputers\"\n",
    "PROJ = os.path.join(BASE, COMPUTER_NAME, PROJECT_DIR)\n",
    "\n",
    "# Función auxiliar\n",
    "def sh(*args, check=False):\n",
    "    print(\"$\", \" \".join(args))\n",
    "    res = subprocess.run(args, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    print(res.stdout)\n",
    "    if check and res.returncode != 0:\n",
    "        raise RuntimeError(\"Command failed\")\n",
    "    return res.returncode\n",
    "\n",
    "# Verificaciones\n",
    "assert os.path.isdir(os.path.join(BASE, COMPUTER_NAME)), f\"No encuentro {COMPUTER_NAME} en {BASE}\"\n",
    "assert os.path.isdir(PROJ), f\"No encuentro el repo en: {PROJ}\"\n",
    "\n",
    "# Agregar al path\n",
    "if PROJ not in sys.path:\n",
    "    sys.path.insert(0, PROJ)\n",
    "\n",
    "# Configurar Git\n",
    "sh(\"git\", \"config\", \"--global\", \"--add\", \"safe.directory\", PROJ)\n",
    "sh(\"git\", \"-C\", PROJ, \"fetch\", \"--all\", \"--prune\")\n",
    "sh(\"git\", \"-C\", PROJ, \"branch\", \"--show-current\")\n",
    "\n",
    "# Cambiar a rama\n",
    "rc = sh(\"git\", \"-C\", PROJ, \"checkout\", BRANCH)\n",
    "if rc != 0:\n",
    "    sh(\"git\", \"-C\", PROJ, \"checkout\", \"-b\", BRANCH, f\"origin/{BRANCH}\")\n",
    "\n",
    "# Actualizar\n",
    "sh(\"git\", \"-C\", PROJ, \"pull\", \"origin\", BRANCH)\n",
    "\n",
    "# Instalar dependencias con manejo de errores mejorado\n",
    "req = os.path.join(PROJ, \"requirements.txt\")\n",
    "if os.path.exists(req):\n",
    "    os.chdir(\"/content\")\n",
    "    print(\"Instalando dependencias...\")\n",
    "    # Instalar dependencias críticas primero\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"optuna>=3.0.0\")\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"torch>=1.9.0\")\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"torchvision>=0.10.0\")\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"scikit-learn>=1.0.0\")\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"librosa>=0.8.1\")\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"soundfile>=0.10.3\")\n",
    "    # Instalar el resto\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"-r\", req)\n",
    "    print(\"Dependencias instaladas correctamente\")\n",
    "else:\n",
    "    print(\"⚠️  No se encontró requirements.txt, instalando dependencias básicas...\")\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"optuna>=3.0.0\", \"torch>=1.9.0\", \"scikit-learn>=1.0.0\")\n",
    "\n",
    "os.chdir(PROJ)\n",
    "\n",
    "# Verificar que optuna esté disponible\n",
    "try:\n",
    "    import optuna\n",
    "    print(f\"✅ Optuna {optuna.__version__} disponible\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importando optuna: {e}\")\n",
    "    print(\"Reinstalando optuna...\")\n",
    "    sh(\"python\", \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"optuna>=3.0.0\")\n",
    "\n",
    "# Autoreload\n",
    "try:\n",
    "    get_ipython().run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    get_ipython().run_line_magic(\"autoreload\", \"2\")\n",
    "    print(\"Autoreload activo\")\n",
    "except Exception as e:\n",
    "    print(f\"No se activó autoreload: {e}\")\n",
    "\n",
    "print(f\"Repo listo en: {PROJ}\")\n",
    "sh(\"git\", \"-C\", PROJ, \"branch\", \"--show-current\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 957,
     "status": "ok",
     "timestamp": 1761427905925,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "-jjfqJs0ttPt",
    "outputId": "6522e63b-6f02-48b7-f3ce-54e316f3ab5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Configurando entorno para notebook...\n",
      "🔍 Información del entorno:\n",
      "   python_version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "   platform: linux\n",
      "   is_colab: True\n",
      "   is_jupyter: True\n",
      "   working_directory: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty\n",
      "   torch_version: 2.8.0+cu126\n",
      "   cuda_available: False\n",
      "🔍 Estado de dependencias:\n",
      "   ✅ PyTorch\n",
      "   ✅ TorchVision\n",
      "   ✅ NumPy\n",
      "   ✅ Pandas\n",
      "   ✅ Scikit-learn\n",
      "   ✅ Matplotlib\n",
      "   ✅ Seaborn\n",
      "   ✅ Librosa\n",
      "   ✅ SoundFile\n",
      "   ✅ Optuna\n",
      "   ✅ Jupyter\n",
      "\n",
      "✅ Entorno listo - todas las dependencias disponibles\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURAR ENTORNO Y DEPENDENCIAS\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Agregar el directorio raíz del proyecto al path\n",
    "# El notebook está en research/, pero modules/ está en el directorio raíz\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Importar el gestor de dependencias centralizado\n",
    "from modules.core.dependency_manager import setup_notebook_environment\n",
    "\n",
    "# Configurar el entorno automáticamente\n",
    "# Esto verifica e instala todas las dependencias necesarias\n",
    "success = setup_notebook_environment(auto_install=True, verbose=True)\n",
    "\n",
    "if not success:\n",
    "    print(\"Error configurando el entorno\")\n",
    "    print(\"Intenta instalar manualmente: pip install -r requirements.txt\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1761427905969,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "sPHApIZxttPy",
    "outputId": "c62ca50f-2f73-42da-9384-49b976edf6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONFIGURACIÓN DEL EXPERIMENTO - PAPER IBARRA 2023\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURACIÓN COMPLETA DEL EXPERIMENTO (PAPER IBARRA 2023)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURACIÓN DEL EXPERIMENTO - PAPER IBARRA 2023\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DEL OPTIMIZADOR (SGD como en el paper)\n",
    "# ============================================================\n",
    "OPTIMIZER_CONFIG = {\n",
    "    \"type\": \"SGD\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,  # Cambiado de 0.0 a 1e-4 para regularización\n",
    "    \"nesterov\": True  # Agregado Nesterov momentum para mejor convergencia\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DEL SCHEDULER (StepLR como en el paper)\n",
    "# ============================================================\n",
    "SCHEDULER_CONFIG = {\n",
    "    \"type\": \"StepLR\",\n",
    "    \"step_size\": 10,\n",
    "    \"gamma\": 0.1\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DEL K-FOLD CROSS-VALIDATION\n",
    "# ============================================================\n",
    "KFOLD_CONFIG = {\n",
    "    \"n_splits\": 10,\n",
    "    \"shuffle\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"stratify_by_speaker\": True\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DE CLASS WEIGHTS (para balancear clases)\n",
    "# ============================================================\n",
    "CLASS_WEIGHTS_CONFIG = {\n",
    "    \"enabled\": True,\n",
    "    \"method\": \"inverse_frequency\"  # 1/frequency\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DE FILTRADO DE VOCAL /a/\n",
    "# ============================================================\n",
    "VOCAL_FILTER_CONFIG = {\n",
    "    \"enabled\": True,\n",
    "    \"target_vocal\": \"a\",  # Solo vocal /a/ como en el paper\n",
    "    \"filter_healthy\": True,\n",
    "    \"filter_parkinson\": True\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DE ENTRENAMIENTO\n",
    "# ============================================================\n",
    "TRAINING_CONFIG = {\n",
    "    \"n_epochs\": 100,\n",
    "    \"early_stopping_patience\": 10,  # Reducido de 15 a 10 para evitar overfitting\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"save_best_model\": True\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DE OPTUNA (OPTIMIZACIÓN DE HIPERPARÁMETROS)\n",
    "# ============================================================\n",
    "# Optuna reemplaza a Optuna - más moderno, sin problemas de instalación\n",
    "OPTUNA_CONFIG = {\n",
    "    \"enabled\": True,\n",
    "    \"experiment_name\": \"cnn2d_optuna_optimization\",\n",
    "    \"n_trials\": 30,  # Número de configuraciones a probar\n",
    "    \"n_epochs_per_trial\": 20,  # Épocas por configuración\n",
    "    \"metric\": \"f1\",  # Métrica a optimizar\n",
    "    \"direction\": \"maximize\"  # maximize o minimize\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN DE DATOS\n",
    "# ============================================================\n",
    "DATA_CONFIG = {\n",
    "    \"test_size\": 0.15,\n",
    "    \"val_size\": 0.15,\n",
    "    \"random_state\": 42,\n",
    "    \"stratify\": True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1761427906628,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "haj4mxa1BC20",
    "outputId": "42144d37-10a8-4083-9929-c3e1374e89b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raíz del proyecto agregada al path: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty\n",
      "======================================================================\n",
      "CONFIGURACIÓN DE ENTORNO\n",
      "======================================================================\n",
      "Entorno detectado: COLAB\n",
      "Ruta base: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty\n",
      "Cache original: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/cache/original\n",
      "Cache augmented: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/cache/augmented\n",
      "\n",
      "MODO COLAB: Usando rutas de Google Drive\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DETECTAR ENTORNO Y CONFIGURAR RUTAS\n",
    "# ============================================================\n",
    "\n",
    "# Este import funciona desde cualquier subdirectorio del proyecto\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Buscar y agregar la raíz del proyecto al path\n",
    "current_dir = Path.cwd()\n",
    "for _ in range(10):\n",
    "    if (current_dir / \"modules\").exists():\n",
    "        if str(current_dir) not in sys.path:\n",
    "            sys.path.insert(0, str(current_dir))\n",
    "        break\n",
    "    current_dir = current_dir.parent\n",
    "\n",
    "# Importar la función de configuración de notebooks\n",
    "from modules.core.notebook_setup import setup_notebook\n",
    "\n",
    "# Configurar automáticamente: path + entorno (Local/Colab) + rutas\n",
    "ENV, PATHS = setup_notebook(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4OEii7wttPz"
   },
   "source": [
    "## 1. Setup y Configuración\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1761427906653,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "LgRftyW3ttP0",
    "outputId": "fbf5ab11-9ac0-4cf6-9e11-50402edfaf6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CNN 2D TRAINING - BASELINE CON AUGMENTATION\n",
      "======================================================================\n",
      "Librerías cargadas correctamente\n",
      "Dispositivo: cpu\n",
      "PyTorch: 2.8.0+cu126\n",
      "Data augmentation: ACTIVADO (~5x datos)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORTS Y CONFIGURACIÓN\n",
    "# ============================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Agregar módulos propios al path\n",
    "# El notebook está en research/, pero modules/ está en el directorio raíz\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Importar módulos propios\n",
    "from modules.models.cnn2d.model import CNN2D\n",
    "from modules.models.common.training_utils import print_model_summary\n",
    "from modules.models.cnn2d.training import train_model, detailed_evaluation, print_evaluation_report\n",
    "from modules.models.cnn2d.visualization import plot_training_history, analyze_spectrogram_stats\n",
    "from modules.models.cnn2d.utils import plot_confusion_matrix\n",
    "from modules.core.utils import create_10fold_splits_by_speaker\n",
    "from modules.core.dataset import (\n",
    "    load_spectrograms_cache,\n",
    "    to_pytorch_tensors,\n",
    "    DictDataset,\n",
    ")\n",
    "\n",
    "\n",
    "# Imports para Optuna (optimización de hiperparámetros - reemplaza Optuna)\n",
    "from modules.core.cnn2d_optuna_wrapper import optimize_cnn2d, create_cnn2d_optimizer\n",
    "from modules.core.optuna_optimization import OptunaOptimizer\n",
    "\n",
    "# Configuración de matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Configuración de PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Reporte de configuración\n",
    "print(\"=\"*70)\n",
    "print(\"CNN 2D TRAINING - BASELINE CON AUGMENTATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Librerías cargadas correctamente\")\n",
    "print(f\"Dispositivo: {device}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Data augmentation: ACTIVADO (~5x datos)\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xinu3UYHttP1"
   },
   "source": [
    "## 2. Carga de Datos\n",
    "\n",
    "Carga de datos preprocesados CON augmentation para mejorar generalización del modelo baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15220,
     "status": "ok",
     "timestamp": 1761427921882,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "LBHKgFgnttP1",
    "outputId": "1ad95fe7-71fd-4018-d6b1-941794b7f182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos Healthy desde cache original...\n",
      "============================================================\n",
      "Cache cargado: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/cache/original/healthy_ibarra.pkl\n",
      "   Tamaño: 933.5 MB\n",
      "   Muestras: 12029\n",
      "PyTorch tensors listos:\n",
      "  - X: (12029, 1, 65, 41)\n",
      "  - y_task: (12029,)  (dist={0: 12029})\n",
      "  - y_domain: (12029,)  (K dominios=4)\n",
      "Healthy cargado exitosamente:\n",
      "   - Espectrogramas: 12029\n",
      "   - Shape: torch.Size([12029, 1, 65, 41])\n",
      "   - Ruta: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/cache/original/healthy_ibarra.pkl\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CARGAR DATOS HEALTHY DESDE CACHE ORIGINAL\n",
    "# ============================================================\n",
    "\n",
    "print(\"Cargando datos Healthy desde cache original...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from modules.core.dataset import load_spectrograms_cache\n",
    "\n",
    "# Cargar datos healthy desde cache original usando rutas dinámicas\n",
    "cache_healthy_path = PATHS['cache_original'] / \"healthy_ibarra.pkl\"\n",
    "healthy_dataset = load_spectrograms_cache(str(cache_healthy_path))\n",
    "\n",
    "if healthy_dataset is None:\n",
    "    raise FileNotFoundError(f\"No se encontró el cache de datos healthy en {cache_healthy_path}\")\n",
    "\n",
    "# Convertir a tensores PyTorch\n",
    "X_healthy, y_task_healthy, y_domain_healthy, meta_healthy = to_pytorch_tensors(healthy_dataset)\n",
    "\n",
    "print(f\"Healthy cargado exitosamente:\")\n",
    "print(f\"   - Espectrogramas: {X_healthy.shape[0]}\")\n",
    "print(f\"   - Shape: {X_healthy.shape}\")\n",
    "print(f\"   - Ruta: {cache_healthy_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27421,
     "status": "ok",
     "timestamp": 1761427949305,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "YSBflzwNBC22",
    "outputId": "0051c443-7185-4ff4-878b-3b10113f81ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos Parkinson desde cache original...\n",
      "============================================================\n",
      "Cache cargado: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/cache/original/parkinson_ibarra.pkl\n",
      "   Tamaño: 1792.3 MB\n",
      "   Muestras: 23097\n",
      "PyTorch tensors listos:\n",
      "  - X: (23097, 1, 65, 41)\n",
      "  - y_task: (23097,)  (dist={0: 23097})\n",
      "  - y_domain: (23097,)  (K dominios=4)\n",
      "Parkinson cargado exitosamente:\n",
      "   - Espectrogramas: 23097\n",
      "   - Shape: torch.Size([23097, 1, 65, 41])\n",
      "   - Ruta: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/cache/original/parkinson_ibarra.pkl\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CARGAR DATOS PARKINSON DESDE CACHE ORIGINAL\n",
    "# ============================================================\n",
    "\n",
    "print(\"Cargando datos Parkinson desde cache original...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar datos parkinson desde cache original usando rutas dinámicas\n",
    "cache_parkinson_path = PATHS['cache_original'] / \"parkinson_ibarra.pkl\"\n",
    "parkinson_dataset = load_spectrograms_cache(str(cache_parkinson_path))\n",
    "\n",
    "if parkinson_dataset is None:\n",
    "    raise FileNotFoundError(f\"No se encontró el cache de datos parkinson en {cache_parkinson_path}\")\n",
    "\n",
    "# Convertir a tensores PyTorch\n",
    "X_parkinson, y_task_parkinson, y_domain_parkinson, meta_parkinson = to_pytorch_tensors(parkinson_dataset)\n",
    "\n",
    "print(f\"Parkinson cargado exitosamente:\")\n",
    "print(f\"   - Espectrogramas: {X_parkinson.shape[0]}\")\n",
    "print(f\"   - Shape: {X_parkinson.shape}\")\n",
    "print(f\"   - Ruta: {cache_parkinson_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1761427949400,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "yUtR4xu4ttP2",
    "outputId": "907e37ad-bce9-4813-e63e-606a15e835a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INFORMACIÓN DE DATOS CARGADOS\n",
      "======================================================================\n",
      "Datos Healthy (desde cache original):\n",
      "   - Muestras: 12029\n",
      "   - Shape de espectrogramas: torch.Size([12029, 1, 65, 41])\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INFORMACIÓN DE DATOS CARGADOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INFORMACIÓN DE DATOS CARGADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Datos Healthy (desde cache original):\")\n",
    "print(f\"   - Muestras: {len(healthy_dataset)}\")\n",
    "print(f\"   - Shape de espectrogramas: {X_healthy.shape}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1872,
     "status": "ok",
     "timestamp": 1761427951282,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "fl80VAx4ttP3",
    "outputId": "69e6836d-d2ef-468e-bfa9-fe31d99c6d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANÁLISIS ESTADÍSTICO BÁSICO\n",
      "======================================================================\n",
      "\n",
      "HEALTHY:\n",
      "   • Número de espectrogramas: 12029\n",
      "   • Shape típico: (65, 41)\n",
      "   • Media: 0.000\n",
      "   • Desviación estándar: 1.000\n",
      "   • Min: -2.465\n",
      "   • Max: 6.155\n",
      "\n",
      "PARKINSON:\n",
      "   • Número de espectrogramas: 23097\n",
      "   • Shape típico: (65, 41)\n",
      "   • Media: 0.000\n",
      "   • Desviación estándar: 1.000\n",
      "   • Min: -3.360\n",
      "   • Max: 3.726\n",
      "\n",
      "DIFERENCIAS ENTRE CLASES:\n",
      "   - Diferencia en media: 0.000\n",
      "   - Diferencia en std: 0.000\n",
      "\n",
      "Configuración del experimento:\n",
      "   - Healthy: datos originales (baseline)\n",
      "   - Parkinson: datos con augmentation (mejor generalización)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ANÁLISIS ESTADÍSTICO BÁSICO\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ANÁLISIS ESTADÍSTICO BÁSICO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Análisis estadístico básico\n",
    "healthy_stats = analyze_spectrogram_stats(healthy_dataset, \"HEALTHY\")\n",
    "parkinson_stats = analyze_spectrogram_stats(parkinson_dataset, \"PARKINSON\")\n",
    "\n",
    "# Comparar diferencias\n",
    "print(f\"\\nDIFERENCIAS ENTRE CLASES:\")\n",
    "print(f\"   - Diferencia en media: {abs(healthy_stats['mean'] - parkinson_stats['mean']):.3f}\")\n",
    "print(f\"   - Diferencia en std: {abs(healthy_stats['std'] - parkinson_stats['std']):.3f}\")\n",
    "\n",
    "print(\"\\nConfiguración del experimento:\")\n",
    "print(\"   - Healthy: datos originales (baseline)\")\n",
    "print(\"   - Parkinson: datos con augmentation (mejor generalización)\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1761427951373,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "3ad1dCwieTUo",
    "outputId": "9b97ffc3-0bd3-46be-a14b-31c9baaef3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMBINANDO DATASETS\n",
      "======================================================================\n",
      "\n",
      "DATASET COMBINADO:\n",
      "   - Total muestras: 35126\n",
      "   - Shape: torch.Size([35126, 1, 65, 41])\n",
      "   - Healthy (0): 12029 (34.2%)\n",
      "   - Parkinson (1): 23097 (65.8%)\n",
      "   ⚠ Dataset desbalanceado - class weights habilitados en config\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COMBINAR DATASETS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMBINANDO DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combinar espectrogramas\n",
    "X_combined = torch.cat([X_healthy, X_parkinson], dim=0)\n",
    "\n",
    "# Crear labels: 0=Healthy, 1=Parkinson\n",
    "y_combined = torch.cat([\n",
    "    torch.zeros(len(X_healthy), dtype=torch.long),  # Healthy = 0\n",
    "    torch.ones(len(X_parkinson), dtype=torch.long)  # Parkinson = 1\n",
    "], dim=0)\n",
    "\n",
    "print(f\"\\nDATASET COMBINADO:\")\n",
    "print(f\"   - Total muestras: {len(X_combined)}\")\n",
    "print(f\"   - Shape: {X_combined.shape}\")\n",
    "print(f\"   - Healthy (0): {(y_combined == 0).sum().item()} ({(y_combined == 0).sum()/len(y_combined)*100:.1f}%)\")\n",
    "print(f\"   - Parkinson (1): {(y_combined == 1).sum().item()} ({(y_combined == 1).sum()/len(y_combined)*100:.1f}%)\")\n",
    "\n",
    "balance_pct = (y_combined == 1).sum() / len(y_combined) * 100\n",
    "if abs(balance_pct - 50) < 10:\n",
    "    print(f\"   ✓ Dataset razonablemente balanceado\")\n",
    "else:\n",
    "    print(f\"   ⚠ Dataset desbalanceado - class weights habilitados en config\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1761427951409,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "iIspxysweTUp",
    "outputId": "5c8ad842-774a-46cc-d1a0-77d0d7367f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICANDO METADATOS\n",
      "======================================================================\n",
      "\n",
      "✓ meta_healthy disponible: 12029 muestras\n",
      "  Ejemplo de metadata[0]:\n",
      "    Tipo: <class 'modules.core.dataset.SampleMeta'>\n",
      "    Valor: SampleMeta(subject_id='10', vowel_type='a_n', condition='unknown', filename='10-a_n.wav', segment_id=0, sr=44100)\n",
      "\n",
      "✓ meta_parkinson disponible: 23097 muestras\n",
      "  Ejemplo de metadata[0]:\n",
      "    Tipo: <class 'modules.core.dataset.SampleMeta'>\n",
      "    Valor: SampleMeta(subject_id='1037', vowel_type='a_h', condition='unknown', filename='1037-a_h.wav', segment_id=0, sr=44100)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INSPECCIONAR METADATOS PARA SPEAKER IDS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICANDO METADATOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verificar estructura de metadatos\n",
    "if meta_healthy and len(meta_healthy) > 0:\n",
    "    print(f\"\\n✓ meta_healthy disponible: {len(meta_healthy)} muestras\")\n",
    "    print(f\"  Ejemplo de metadata[0]:\")\n",
    "    sample_meta = meta_healthy[0]\n",
    "    if isinstance(sample_meta, dict):\n",
    "        for key, value in list(sample_meta.items())[:5]:\n",
    "            print(f\"    - {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"    Tipo: {type(sample_meta)}\")\n",
    "        print(f\"    Valor: {sample_meta}\")\n",
    "else:\n",
    "    print(\"  ✗ meta_healthy no disponible o vacío\")\n",
    "\n",
    "if meta_parkinson and len(meta_parkinson) > 0:\n",
    "    print(f\"\\n✓ meta_parkinson disponible: {len(meta_parkinson)} muestras\")\n",
    "    print(f\"  Ejemplo de metadata[0]:\")\n",
    "    sample_meta = meta_parkinson[0]\n",
    "    if isinstance(sample_meta, dict):\n",
    "        for key, value in list(sample_meta.items())[:5]:\n",
    "            print(f\"    - {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"    Tipo: {type(sample_meta)}\")\n",
    "        print(f\"    Valor: {sample_meta}\")\n",
    "else:\n",
    "    print(\"  ✗ meta_parkinson no disponible o vacío\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMZElStXttP3"
   },
   "source": [
    "## 3. Split Train/Val/Test\n",
    "\n",
    "Split estratificado 70/15/15 para mantener proporciones de clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1761427951777,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "rj5q0QU5ttP4",
    "outputId": "d639f2ac-4952-4e75-ca5e-0abcd44c227b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "10-FOLD CROSS-VALIDATION (PAPER IBARRA 2023)\n",
      "======================================================================\n",
      "\n",
      "📊 Dataset info:\n",
      "   • Total samples: 35126\n",
      "   • Metadata entries: 35126\n",
      "\n",
      "📊 10-Fold CV speaker-independent creado:\n",
      "   Total hablantes: 2042\n",
      "   Total muestras: 35126\n",
      "   Folds: 10\n",
      "\n",
      "   Fold 1 (ejemplo):\n",
      "      Train: 31789 muestras\n",
      "      Val:   3337 muestras\n",
      "\n",
      "TAMAÑOS DE SPLITS:\n",
      "   - Train: 31789 (90.5%)\n",
      "   - Val:   3337 (9.5%)\n",
      "   - Test:  5269 (15.0%)\n",
      "\n",
      "DISTRIBUCIÓN POR SPLIT:\n",
      "   Train: HC=10916 (34.3%), PD=20873 (65.7%)\n",
      "   Val  : HC=1113 (33.4%), PD=2224 (66.6%)\n",
      "   Test : HC=1804 (34.2%), PD=3465 (65.8%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 10-FOLD CROSS-VALIDATION ESTRATIFICADO POR HABLANTE\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"10-FOLD CROSS-VALIDATION (PAPER IBARRA 2023)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Preparar metadata combinada para create_10fold_splits_by_speaker\n",
    "# La metadata ya fue cargada antes con meta_healthy y meta_parkinson\n",
    "\n",
    "# Crear lista de metadata combinada con labels\n",
    "metadata_combined = []\n",
    "\n",
    "# Agregar metadata de healthy (label=0)\n",
    "for meta in meta_healthy:\n",
    "    metadata_combined.append({\n",
    "        \"subject_id\": meta.subject_id,\n",
    "        \"label\": 0,  # Healthy\n",
    "        \"filename\": meta.filename\n",
    "    })\n",
    "\n",
    "# Agregar metadata de parkinson (label=1)\n",
    "for meta in meta_parkinson:\n",
    "    metadata_combined.append({\n",
    "        \"subject_id\": meta.subject_id,\n",
    "        \"label\": 1,  # Parkinson\n",
    "        \"filename\": meta.filename\n",
    "    })\n",
    "\n",
    "print(f\"\\n📊 Dataset info:\")\n",
    "print(f\"   • Total samples: {len(X_combined)}\")\n",
    "print(f\"   • Metadata entries: {len(metadata_combined)}\")\n",
    "\n",
    "# Crear 10-fold splits usando la función centralizada\n",
    "# Esta función asegura que todos los samples de un speaker están en el mismo fold\n",
    "fold_splits = create_10fold_splits_by_speaker(\n",
    "    metadata_list=metadata_combined,\n",
    "    n_folds=KFOLD_CONFIG[\"n_splits\"],\n",
    "    seed=KFOLD_CONFIG[\"random_state\"]\n",
    ")\n",
    "\n",
    "# Para este notebook, usaremos el primer fold como ejemplo\n",
    "# En el paper real se promedian los resultados de los 10 folds\n",
    "train_indices = fold_splits[0][\"train\"]\n",
    "val_indices = fold_splits[0][\"val\"]\n",
    "\n",
    "# Crear splits de train/val usando los índices\n",
    "X_train = X_combined[train_indices]\n",
    "y_train = y_combined[train_indices]\n",
    "X_val = X_combined[val_indices]\n",
    "y_val = y_combined[val_indices]\n",
    "\n",
    "# Para test, usamos un split separado del 15%\n",
    "# TODO: Esto debería también usar split por speaker para evitar leakage\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_combined, y_combined,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=y_combined\n",
    ")\n",
    "\n",
    "print(f\"\\nTAMAÑOS DE SPLITS:\")\n",
    "print(f\"   - Train: {len(X_train)} ({len(X_train)/len(X_combined)*100:.1f}%)\")\n",
    "print(f\"   - Val:   {len(X_val)} ({len(X_val)/len(X_combined)*100:.1f}%)\")\n",
    "print(f\"   - Test:  {len(X_test)} ({len(X_test)/len(X_combined)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDISTRIBUCIÓN POR SPLIT:\")\n",
    "for split_name, y_split in [(\"Train\", y_train), (\"Val\", y_val), (\"Test\", y_test)]:\n",
    "    n_healthy = (y_split == 0).sum().item()\n",
    "    n_parkinson = (y_split == 1).sum().item()\n",
    "    print(f\"   {split_name:5s}: HC={n_healthy:4d} ({n_healthy/len(y_split)*100:.1f}%), PD={n_parkinson:4d} ({n_parkinson/len(y_split)*100:.1f}%)\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1761427951813,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "asWglEGTttP5",
    "outputId": "9b8009e6-3dea-487c-e519-b605116a3a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 CREANDO DATALOADERS...\n",
      "✅ DataLoaders creados:\n",
      "   • Train batches: 994\n",
      "   • Val batches:   53\n",
      "   • Test batches:  83\n",
      "   • Batch size:    32\n"
     ]
    }
   ],
   "source": [
    "# Agregar módulos propios al path\n",
    "# El notebook está en research/, pero modules/ está en el directorio raíz\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# ============================================================\n",
    "# CREAR DATALOADERS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n📦 CREANDO DATALOADERS...\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Importar DictDataset desde el módulo core\n",
    "\n",
    "# Crear datasets con formato de diccionario\n",
    "train_dataset = DictDataset(X_train, y_train)\n",
    "val_dataset = DictDataset(X_val, y_val)\n",
    "test_dataset = DictDataset(X_test, y_test)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"✅ DataLoaders creados:\")\n",
    "print(f\"   • Train batches: {len(train_loader)}\")\n",
    "print(f\"   • Val batches:   {len(val_loader)}\")\n",
    "print(f\"   • Test batches:  {len(test_loader)}\")\n",
    "print(f\"   • Batch size:    {BATCH_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW21Fj0QttP6"
   },
   "source": [
    "## 4. Optimización de Hiperparámetros con Optuna\n",
    "\n",
    "Optimización automática de hiperparámetros usando Optuna para encontrar la mejor configuración del modelo CNN2D.\n",
    "\n",
    "### Configuración:\n",
    "- **Método**: Optuna con búsqueda aleatoria\n",
    "- **Configuraciones**: 30% de todas las combinaciones posibles\n",
    "- **Épocas por config**: 20 épocas (búsqueda rápida)\n",
    "- **Métrica**: F1-score en validación\n",
    "- **Espacio de búsqueda**: Según tabla del paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1761427951873,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "ijmy_JiDttP6",
    "outputId": "c3311f09-8385-46aa-a4d8-5b6625bf76e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONFIGURANDO OPTIMIZACIÓN CON OPTUNA\n",
      "======================================================================\n",
      "Módulos de Optuna importados\n",
      "Directorio de resultados: /content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/results/cnn_optuna_optimization\n",
      "Trials a ejecutar: 30\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURAR OPTIMIZACIÓN CON OPTUNA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURANDO OPTIMIZACIÓN CON OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear directorio para resultados de Optuna usando rutas dinámicas\n",
    "optuna_results_dir = PATHS['results'] / \"cnn_optuna_optimization\"\n",
    "optuna_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Módulos de Optuna importados\")\n",
    "print(f\"Directorio de resultados: {optuna_results_dir}\")\n",
    "print(f\"Trials a ejecutar: {OPTUNA_CONFIG['n_trials']}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREAR CHECKPOINT INICIAL DESDE LOGS PREVIOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CREANDO CHECKPOINT INICIAL DESDE LOGS PREVIOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ejecutar el script de creación de checkpoint\n",
    "exec(open('research/create_initial_checkpoint.py').read())\n",
    "\n",
    "print(\"\\n🚀 Checkpoint inicial creado - Ahora puedes continuar desde donde se quedó\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1761427951905,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "dPNAfUw_ttP7",
    "outputId": "eb2dc3e6-d499-43e4-cb1c-dc41f72a57ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREPARANDO DATOS PARA OPTUNA\n",
      "======================================================================\n",
      "📊 Datos preparados para Optuna:\n",
      "   - Train: torch.Size([31789, 1, 65, 41]) (labels: torch.Size([31789]))\n",
      "   - Val:   torch.Size([3337, 1, 65, 41]) (labels: torch.Size([3337]))\n",
      "   - Test:  torch.Size([5269, 1, 65, 41]) (labels: torch.Size([5269]))\n",
      "\n",
      "📈 Distribución de clases:\n",
      "   Train - HC: 10916, PD: 20873\n",
      "   Val   - HC: 1113, PD: 2224\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PREPARAR DATOS PARA OPTUNA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARANDO DATOS PARA OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Optuna trabaja directamente con PyTorch tensors (no requiere numpy)\n",
    "# Los tensors ya están listos desde la carga de datos\n",
    "\n",
    "print(f\"📊 Datos preparados para Optuna:\")\n",
    "print(f\"   - Train: {X_train.shape} (labels: {y_train.shape})\")\n",
    "print(f\"   - Val:   {X_val.shape} (labels: {y_val.shape})\")\n",
    "print(f\"   - Test:  {X_test.shape} (labels: {y_test.shape})\")\n",
    "\n",
    "# Verificar distribución de clases\n",
    "print(f\"\\n📈 Distribución de clases:\")\n",
    "print(f\"   Train - HC: {(y_train == 0).sum().item()}, PD: {(y_train == 1).sum().item()}\")\n",
    "print(f\"   Val   - HC: {(y_val == 0).sum().item()}, PD: {(y_val == 1).sum().item()}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VENTAJAS DEL SISTEMA DE CHECKPOINTING\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VENTAJAS DEL SISTEMA DE CHECKPOINTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"💡 Beneficios del checkpointing automático:\")\n",
    "print(\"   ✅ Continúa desde donde se quedó automáticamente\")\n",
    "print(\"   ✅ Guarda progreso en tiempo real (cada trial)\")\n",
    "print(\"   ✅ No pierde trabajo si se corta la GPU\")\n",
    "print(\"   ✅ Puede reanudar múltiples veces\")\n",
    "print(\"   ✅ Guarda mejores parámetros en tiempo real\")\n",
    "print(\"   ✅ Resistente a interrupciones de red/GPU\")\n",
    "\n",
    "print(\"\\n🔄 Flujo de trabajo:\")\n",
    "print(\"   1. Primera ejecución: Crea checkpoint inicial desde logs\")\n",
    "print(\"   2. Ejecución normal: Guarda progreso automáticamente\")\n",
    "print(\"   3. Si se corta: Reanuda desde el último trial guardado\")\n",
    "print(\"   4. Múltiples reanudaciones: Puede continuar indefinidamente\")\n",
    "\n",
    "print(\"\\n📊 Lo que guarda automáticamente:\")\n",
    "print(\"   - Cada trial: Parámetros, métricas, estado\")\n",
    "print(\"   - Mejores parámetros: Se actualiza en tiempo real\")\n",
    "print(\"   - Progreso: Trials completados, mejor F1, etc.\")\n",
    "print(\"   - Estado del estudio: Para reanudar exactamente donde se quedó\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a9747fbd453c4e50af39c282f787a62c",
      "27a764741a964ac18443dd2703920ac7",
      "be76252b9db24ba98f4322edc4829aaa",
      "737970eb89ed45d7aaece1042d010f9f",
      "f3f1eabf7f604a7dbdb0d80fc18b9e23",
      "68d0a70631024c37a4717d1314c469ca",
      "74b1c6ed1cfa453292cd08aa592c947b",
      "f7cdd4c9a0ee4ddcb7bfde941b5f4557",
      "c5f1a881c85044a6a0bb294e60e0a93e",
      "821855eda1764ef8a621192e972602ca",
      "205d6bfdf92f4588b12caeb4e6e54f0b"
     ]
    },
    "executionInfo": {
     "elapsed": 22157,
     "status": "error",
     "timestamp": 1761427974072,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "EulPu2cHttP8",
    "outputId": "d3d2d886-e375-4f00-d44f-ab17233b6951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-25 21:32:31,840] A new study created in memory with name: cnn2d_optuna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICANDO RESULTADOS PREVIOS DE OPTUNA\n",
      "======================================================================\n",
      "❌ No se encontraron resultados previos de Optuna\n",
      "   - Iniciando optimización desde cero\n",
      "\n",
      "⚙️  Configuración:\n",
      "   - Trials a ejecutar: 30\n",
      "   - Épocas por trial: 20\n",
      "   - Métrica a optimizar: f1 (maximize)\n",
      "\n",
      "🚀 Iniciando búsqueda de hiperparámetros con Optuna...\n",
      "   (Esto puede tomar varios minutos)\n",
      "Iniciando optimización con 30 trials...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9747fbd453c4e50af39c282f787a62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-10-25 21:32:53,953] Trial 0 failed with parameters: {'filters_1': 32, 'filters_2': 32, 'kernel_size_1': 5, 'kernel_size_2': 5, 'p_drop_conv': 0.20617534828874073, 'p_drop_fc': 0.5909729556485983, 'dense_units': 32, 'learning_rate': 3.5498788321965036e-05, 'weight_decay': 8.179499475211674e-06, 'optimizer': 'adam', 'batch_size': 32} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/optuna_optimization.py\", line 240, in <lambda>\n",
      "    lambda trial: self._objective(trial, X_train, y_train, X_val, y_val),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/optuna_optimization.py\", line 201, in _objective\n",
      "    metric_value, metrics_dict = self.model_wrapper.train_model(\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/cnn2d_optuna_wrapper.py\", line 152, in train_model\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-10-25 21:32:53,982] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2179426938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Ejecutar optimización\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     optuna_results = optimize_cnn2d(\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/cnn2d_optuna_wrapper.py\u001b[0m in \u001b[0;36moptimize_cnn2d\u001b[0;34m(X_train, y_train, X_val, y_val, input_shape, n_trials, n_epochs_per_trial, device, save_dir)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;31m# Ejecutar optimización\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iniciando optimización con {n_trials} trials...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# Obtener resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/optuna_optimization.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, X_train, y_train, X_val, y_val, show_progress)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Ejecutar optimización\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         self.study.optimize(\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     ):\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/optuna_optimization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Ejecutar optimización\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         self.study.optimize(\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/optuna_optimization.py\u001b[0m in \u001b[0;36m_objective\u001b[0;34m(self, trial, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# Entrenar modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         metric_value, metrics_dict = self.model_wrapper.train_model(\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs_per_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         )\n",
      "\u001b[0;32m/content/drive/Othercomputers/ZenBook/parkinson-voice-uncertainty/modules/core/cnn2d_optuna_wrapper.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, train_loader, val_loader, trial, n_epochs)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VERIFICAR SI YA EXISTEN RESULTADOS DE OPTUNA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICANDO RESULTADOS PREVIOS DE OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Configuración de la optimización usando configuración centralizada\n",
    "# (OPTUNA_CONFIG ya está definido en la configuración centralizada)\n",
    "\n",
    "# Verificar si ya existen resultados previos\n",
    "results_csv_path = optuna_results_dir / \"optuna_trials_results.csv\"\n",
    "best_params_path = optuna_results_dir / \"best_params.json\"\n",
    "\n",
    "if results_csv_path.exists() and best_params_path.exists():\n",
    "    print(\"✅ Se encontraron resultados previos de Optuna\")\n",
    "    print(f\"   - Archivo de resultados: {results_csv_path}\")\n",
    "    print(f\"   - Archivo de mejores parámetros: {best_params_path}\")\n",
    "\n",
    "    # Cargar resultados previos\n",
    "    results_df = pd.read_csv(results_csv_path)\n",
    "    with open(best_params_path, 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "\n",
    "    print(f\"\\n📊 Resultados previos encontrados:\")\n",
    "    print(f\"   - Total trials evaluados: {len(results_df)}\")\n",
    "    print(f\"   - Mejor F1-score encontrado: {results_df['value'].max():.4f}\")\n",
    "    print(f\"   - F1-score promedio: {results_df['value'].mean():.4f} ± {results_df['value'].std():.4f}\")\n",
    "\n",
    "    print(f\"\\n🏆 Mejores hiperparámetros encontrados:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"   - {param}: {value}\")\n",
    "\n",
    "    # Crear diccionario de resultados para compatibilidad\n",
    "    optuna_results = {\n",
    "        \"results_df\": results_df,\n",
    "        \"best_params\": best_params,\n",
    "        \"study\": None  # El study se carga separadamente si es necesario\n",
    "    }\n",
    "\n",
    "    print(f\"\\n⏭️  Saltando optimización - usando resultados previos\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "else:\n",
    "    print(\"❌ No se encontraron resultados previos de Optuna\")\n",
    "    print(\"   - Iniciando optimización desde cero\")\n",
    "\n",
    "    print(f\"\\n⚙️  Configuración:\")\n",
    "    print(f\"   - Trials a ejecutar: {OPTUNA_CONFIG['n_trials']}\")\n",
    "    print(f\"   - Épocas por trial: {OPTUNA_CONFIG['n_epochs_per_trial']}\")\n",
    "    print(f\"   - Métrica a optimizar: {OPTUNA_CONFIG['metric']} ({OPTUNA_CONFIG['direction']})\")\n",
    "\n",
    "    print(f\"\\n🚀 Iniciando búsqueda de hiperparámetros con Optuna...\")\n",
    "    print(\"   (Esto puede tomar varios minutos)\")\n",
    "\n",
    "    # Ejecutar optimización con checkpointing\n",
    "    optuna_results = optimize_cnn2d(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        input_shape=(1, 65, 41),  # (C, H, W)\n",
    "        n_trials=OPTUNA_CONFIG[\"n_trials\"],\n",
    "        n_epochs_per_trial=OPTUNA_CONFIG[\"n_epochs_per_trial\"],\n",
    "        device=device,\n",
    "        save_dir=str(optuna_results_dir),\n",
    "        checkpoint_dir=\"checkpoints\",  # ← NUEVO: Directorio para checkpoints\n",
    "        resume=True  # ← NUEVO: Reanudar desde checkpoint si existe\n",
    "    )\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"OPTIMIZACIÓN COMPLETADA\")\n",
    "    print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 94,
     "status": "aborted",
     "timestamp": 1761427974131,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "88jfG5bVttP8"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANÁLISIS DE RESULTADOS DE OPTUNA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ANÁLISIS DE RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extraer resultados\n",
    "results_df = optuna_results[\"results_df\"]\n",
    "best_params = optuna_results[\"best_params\"]\n",
    "analysis = optuna_results[\"analysis\"]\n",
    "\n",
    "print(f\"📊 Resumen de la optimización:\")\n",
    "print(f\"   - Total configuraciones evaluadas: {len(results_df)}\")\n",
    "print(f\"   - Mejor F1-score encontrado: {results_df['f1'].max():.4f}\")\n",
    "print(f\"   - F1-score promedio: {results_df['f1'].mean():.4f} ± {results_df['f1'].std():.4f}\")\n",
    "\n",
    "print(f\"\\n🏆 Mejores hiperparámetros encontrados:\")\n",
    "for param, value in best_params.items():\n",
    "    if param not in ['f1', 'accuracy', 'precision', 'recall', 'val_loss', 'train_loss']:\n",
    "        print(f\"   - {param}: {value}\")\n",
    "\n",
    "# Mostrar top 10 configuraciones\n",
    "print(f\"\\n📈 Top 10 configuraciones:\")\n",
    "print(\"-\" * 80)\n",
    "top_10 = results_df.nlargest(10, 'f1')\n",
    "for i, (idx, row) in enumerate(top_10.iterrows(), 1):\n",
    "    print(f\"{i:2d}. F1: {row['f1']:.4f} | \"\n",
    "          f\"Acc: {row['accuracy']:.4f} | \"\n",
    "          f\"Batch: {row['batch_size']} | \"\n",
    "          f\"LR: {row['learning_rate']} | \"\n",
    "          f\"Dropout: {row['p_drop_conv']}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263374,
     "status": "aborted",
     "timestamp": 1761427974137,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "o888G9VGttP9"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GUARDAR RESULTADOS DE OPTUNA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GUARDANDO RESULTADOS DE OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Guardar DataFrame completo con todas las configuraciones\n",
    "results_csv_path = optuna_results_dir / \"optuna_scan_results.csv\"\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"💾 Resultados completos guardados: {results_csv_path}\")\n",
    "\n",
    "# Guardar mejores parámetros\n",
    "best_params_path = optuna_results_dir / \"best_params.json\"\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(f\"💾 Mejores parámetros guardados: {best_params_path}\")\n",
    "\n",
    "# Guardar resumen de optimización\n",
    "summary_path = optuna_results_dir / \"optimization_summary.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"RESUMEN DE OPTIMIZACIÓN OPTUNA\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    f.write(f\"Total configuraciones evaluadas: {len(results_df)}\\n\")\n",
    "    f.write(f\"Mejor F1-score: {results_df['f1'].max():.4f}\\n\")\n",
    "    f.write(f\"F1-score promedio: {results_df['f1'].mean():.4f} ± {results_df['f1'].std():.4f}\\n\\n\")\n",
    "    f.write(\"MEJORES HIPERPARÁMETROS:\\n\")\n",
    "    f.write(\"-\"*30 + \"\\n\")\n",
    "    for param, value in best_params.items():\n",
    "        if param not in ['f1', 'accuracy', 'precision', 'recall', 'val_loss', 'train_loss']:\n",
    "            f.write(f\"{param}: {value}\\n\")\n",
    "    f.write(\"\\nTOP 5 CONFIGURACIONES:\\n\")\n",
    "    f.write(\"-\"*30 + \"\\n\")\n",
    "    top_5 = results_df.nlargest(5, 'f1')\n",
    "    for i, (idx, row) in enumerate(top_5.iterrows(), 1):\n",
    "        f.write(f\"{i}. F1: {row['f1']:.4f} | Acc: {row['accuracy']:.4f} | \"\n",
    "                f\"Batch: {row['batch_size']} | LR: {row['learning_rate']}\\n\")\n",
    "\n",
    "print(f\"💾 Resumen guardado: {summary_path}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263374,
     "status": "aborted",
     "timestamp": 1761427974141,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "f0dr_0HlttP-"
   },
   "outputs": [],
   "source": [
    "# Agregar módulos propios al path\n",
    "# El notebook está en research/, pero modules/ está en el directorio raíz\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# ============================================================\n",
    "# EVALUAR RESULTADOS DE OPTUNA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EVALUACIÓN DE RESULTADOS DE OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Importar evaluador\n",
    "\n",
    "# Evaluar el proceso de optimización\n",
    "# evaluation = check_optuna_results(str(optuna_results_dir))\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wihb557SttP-"
   },
   "source": [
    "## 5. Re-entrenamiento con Mejores Hiperparámetros\n",
    "\n",
    "Re-entrenar el modelo CNN2D usando los mejores hiperparámetros encontrados por Optuna, con early stopping para obtener el modelo final optimizado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263377,
     "status": "aborted",
     "timestamp": 1761427974147,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "2NVWEzLkttP_"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREAR MODELO CON MEJORES HIPERPARÁMETROS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CREANDO MODELO CON MEJORES HIPERPARÁMETROS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear modelo con mejores parámetros encontrados por Optuna\n",
    "best_model = CNN2D(\n",
    "    n_classes=2,\n",
    "    p_drop_conv=best_params[\"p_drop_conv\"],\n",
    "    p_drop_fc=best_params[\"p_drop_fc\"],\n",
    "    input_shape=(65, 41),\n",
    "    filters_1=best_params[\"filters_1\"],\n",
    "    filters_2=best_params[\"filters_2\"],\n",
    "    kernel_size_1=best_params[\"kernel_size_1\"],\n",
    "    kernel_size_2=best_params[\"kernel_size_2\"],\n",
    "    dense_units=best_params[\"dense_units\"],\n",
    ").to(device)\n",
    "\n",
    "print(f\"✅ Modelo creado con mejores hiperparámetros:\")\n",
    "print(f\"   - Filters 1: {best_params['filters_1']}\")\n",
    "print(f\"   - Filters 2: {best_params['filters_2']}\")\n",
    "print(f\"   - Kernel 1: {best_params['kernel_size_1']}\")\n",
    "print(f\"   - Kernel 2: {best_params['kernel_size_2']}\")\n",
    "print(f\"   - Dense units: {best_params['dense_units']}\")\n",
    "print(f\"   - Dropout conv: {best_params['p_drop_conv']}\")\n",
    "print(f\"   - Dropout fc: {best_params['p_drop_fc']}\")\n",
    "\n",
    "# Mostrar arquitectura\n",
    "print_model_summary(best_model)\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263377,
     "status": "aborted",
     "timestamp": 1761427974150,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "86kelbHEttP_"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURAR ENTRENAMIENTO CON MEJORES PARÁMETROS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURANDO ENTRENAMIENTO FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Configuración de entrenamiento final usando configuración centralizada\n",
    "FINAL_TRAINING_CONFIG = {\n",
    "    \"n_epochs\": 100,\n",
    "    \"early_stopping_patience\": 10,  # Reducido de 15 a 10 (recomendación)\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": best_params[\"batch_size\"]\n",
    "}\n",
    "\n",
    "# Crear DataLoaders con el mejor batch size\n",
    "train_loader_final = DataLoader(\n",
    "    train_dataset,\n",
    "    best_params[\"batch_size\"],  # Usar batch_size de Optuna\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader_final = DataLoader(\n",
    "    val_dataset,\n",
    "    best_params[\"batch_size\"],  # Usar batch_size de Optuna\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "test_loader_final = DataLoader(\n",
    "    test_dataset,\n",
    "    best_params[\"batch_size\"],  # Usar batch_size de Optuna\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Optimizador SGD con momentum usando configuración centralizada\n",
    "# CORREGIDO: Agregado nesterov=True y weight_decay=1e-4\n",
    "optimizer_final = optim.SGD(\n",
    "    best_model.parameters(),\n",
    "    lr=FINAL_TRAINING_CONFIG['learning_rate'],\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4,  # Cambiado de 0.0 a 1e-4\n",
    "    nesterov=True  # Agregado Nesterov momentum\n",
    ")\n",
    "\n",
    "# Calcular class weights para balancear las clases usando configuración centralizada\n",
    "if CLASS_WEIGHTS_CONFIG[\"enabled\"]:\n",
    "    class_counts = torch.bincount(y_train)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "    criterion_final = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    print(f\"✅ Class weights habilitados: {class_weights.tolist()}\")\n",
    "else:\n",
    "    criterion_final = nn.CrossEntropyLoss()\n",
    "    print(\"⚠️  Class weights deshabilitados\")\n",
    "\n",
    "# Scheduler StepLR usando configuración centralizada\n",
    "scheduler_final = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer_final,\n",
    "    step_size=SCHEDULER_CONFIG[\"step_size\"],\n",
    "    gamma=SCHEDULER_CONFIG[\"gamma\"]\n",
    ")\n",
    "\n",
    "print(f\"\\n⚙️  Configuración final:\")\n",
    "print(f\"   - Learning rate inicial: {FINAL_TRAINING_CONFIG['learning_rate']}\")\n",
    "print(f\"   - Momentum: 0.9 (Nesterov: True)\")\n",
    "print(f\"   - Weight decay: 1e-4\")\n",
    "print(f\"   - Scheduler: StepLR (step={SCHEDULER_CONFIG['step_size']}, gamma={SCHEDULER_CONFIG['gamma']})\")\n",
    "print(f\"   - Batch size: {FINAL_TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"   - Épocas máximas: {FINAL_TRAINING_CONFIG['n_epochs']}\")\n",
    "print(f\"   - Early stopping patience: {FINAL_TRAINING_CONFIG['early_stopping_patience']}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263380,
     "status": "aborted",
     "timestamp": 1761427974157,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "2fg5tzkUttQA"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ENTRENAR MODELO FINAL CON EARLY STOPPING\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENTRENANDO MODELO FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entrenar modelo con mejores hiperparámetros\n",
    "# CORREGIDO: Usar keyword arguments y monitorear val_f1 (mejor para datasets desbalanceados)\n",
    "final_training_results = train_model(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader_final,\n",
    "    val_loader=val_loader_final,\n",
    "    optimizer=optimizer_final,\n",
    "    criterion=criterion_final,\n",
    "    device=device,\n",
    "    n_epochs=FINAL_TRAINING_CONFIG['n_epochs'],\n",
    "    early_stopping_patience=FINAL_TRAINING_CONFIG['early_stopping_patience'],\n",
    "    save_dir=optuna_results_dir,\n",
    "    verbose=True,\n",
    "    scheduler=scheduler_final,\n",
    "    monitor_metric=\"f1\"  # Monitorear F1 en lugar de loss (recomendado para desbalance)\n",
    ")\n",
    "\n",
    "# Extraer resultados\n",
    "final_model = final_training_results[\"model\"]\n",
    "final_history = final_training_results[\"history\"]\n",
    "final_best_val_loss = final_training_results[\"best_val_loss\"]\n",
    "final_total_time = final_training_results[\"total_time\"]\n",
    "\n",
    "# Calcular mejor época\n",
    "final_best_epoch = final_history[\"val_loss\"].index(min(final_history[\"val_loss\"])) + 1\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENTRENAMIENTO FINAL COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✅ Resultados:\")\n",
    "print(f\"   - Mejor época: {final_best_epoch}\")\n",
    "print(f\"   - Mejor val loss: {final_best_val_loss:.4f}\")\n",
    "print(f\"   - Tiempo total: {final_total_time/60:.1f} minutos\")\n",
    "print(f\"   - Modelo guardado en: {optuna_results_dir / 'best_model_optuna.pth'}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263381,
     "status": "aborted",
     "timestamp": 1761427974161,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "43bNxSHMttQA"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUACIÓN FINAL EN TEST SET\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EVALUACIÓN FINAL EN TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluar modelo final en test set\n",
    "final_test_metrics = detailed_evaluation(\n",
    "    model=final_model,\n",
    "    loader=test_loader_final,\n",
    "    device=device,\n",
    "    class_names=[\"Healthy\", \"Parkinson\"]\n",
    ")\n",
    "\n",
    "# Imprimir reporte\n",
    "print_evaluation_report(final_test_metrics, class_names=[\"Healthy\", \"Parkinson\"])\n",
    "\n",
    "# Guardar métricas finales\n",
    "final_metrics_path = optuna_results_dir / \"test_metrics_optuna.json\"\n",
    "\n",
    "# Extraer métricas del classification_report\n",
    "final_report = final_test_metrics[\"classification_report\"]\n",
    "final_metrics_to_save = {\n",
    "    \"accuracy\": float(final_test_metrics[\"accuracy\"]),\n",
    "    \"f1_macro\": float(final_test_metrics[\"f1_macro\"]),\n",
    "    \"precision_macro\": float(final_report[\"macro avg\"][\"precision\"]),\n",
    "    \"recall_macro\": float(final_report[\"macro avg\"][\"recall\"]),\n",
    "    \"f1_weighted\": float(final_report[\"weighted avg\"][\"f1-score\"]),\n",
    "    \"confusion_matrix\": final_test_metrics[\"confusion_matrix\"].tolist(),\n",
    "    \"classification_report\": final_report,\n",
    "    \"best_hyperparameters\": best_params,\n",
    "    \"training_config\": FINAL_TRAINING_CONFIG,\n",
    "    \"final_epoch\": final_best_epoch,\n",
    "    \"final_val_loss\": final_best_val_loss,\n",
    "    \"training_time_minutes\": final_total_time / 60\n",
    "}\n",
    "\n",
    "with open(final_metrics_path, \"w\") as f:\n",
    "    json.dump(final_metrics_to_save, f, indent=2)\n",
    "\n",
    "print(f\"\\n💾 Métricas finales guardadas en: {final_metrics_path}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263381,
     "status": "aborted",
     "timestamp": 1761427974164,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "28JxR5lgttQB"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZACIÓN FINAL\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GENERANDO VISUALIZACIONES FINALES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Graficar progreso del entrenamiento final\n",
    "final_progress_fig = plot_training_history(\n",
    "    final_history,\n",
    "    save_path=optuna_results_dir / \"training_progress_optuna.png\"\n",
    ")\n",
    "\n",
    "# Matriz de confusión final\n",
    "final_cm = final_test_metrics[\"confusion_matrix\"]\n",
    "final_cm_fig = plot_confusion_matrix(\n",
    "    final_cm,\n",
    "    class_names=[\"Healthy\", \"Parkinson\"],\n",
    "    title=\"Matriz de Confusión - Test Set (CNN2D Optimizado con Optuna)\",\n",
    "    save_path=optuna_results_dir / \"confusion_matrix_optuna.png\",\n",
    "    show=True\n",
    ")\n",
    "\n",
    "print(f\"💾 Visualizaciones guardadas:\")\n",
    "print(f\"   - Progreso de entrenamiento: {optuna_results_dir / 'training_progress_optuna.png'}\")\n",
    "print(f\"   - Matriz de confusión: {optuna_results_dir / 'confusion_matrix_optuna.png'}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263496,
     "status": "aborted",
     "timestamp": 1761427974282,
     "user": {
      "displayName": "Ferney Cordoba Canchala",
      "userId": "08591795942797397856"
     },
     "user_tz": 300
    },
    "id": "GQP-xbe3ttQB"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RESUMEN FINAL DE OPTIMIZACIÓN\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RESUMEN FINAL DE OPTIMIZACIÓN CON OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n🔍 PROCESO DE OPTIMIZACIÓN:\")\n",
    "print(f\"   - Configuraciones evaluadas: {len(results_df)}\")\n",
    "print(f\"   - Mejor F1-score en validación: {results_df['f1'].max():.4f}\")\n",
    "print(f\"   - F1-score promedio: {results_df['f1'].mean():.4f} ± {results_df['f1'].std():.4f}\")\n",
    "\n",
    "print(f\"\\n🏆 MEJORES HIPERPARÁMETROS ENCONTRADOS:\")\n",
    "for param, value in best_params.items():\n",
    "    if param not in ['f1', 'accuracy', 'precision', 'recall', 'val_loss', 'train_loss']:\n",
    "        print(f\"   - {param}: {value}\")\n",
    "\n",
    "print(f\"\\n📊 RESULTADOS FINALES EN TEST SET:\")\n",
    "final_report = final_test_metrics[\"classification_report\"]\n",
    "print(f\"   - Accuracy:  {final_test_metrics['accuracy']:.4f}\")\n",
    "print(f\"   - Precision: {final_report['macro avg']['precision']:.4f}\")\n",
    "print(f\"   - Recall:    {final_report['macro avg']['recall']:.4f}\")\n",
    "print(f\"   - F1-Score:  {final_test_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n💾 ARCHIVOS GUARDADOS EN {optuna_results_dir}:\")\n",
    "print(f\"   - optuna_scan_results.csv          # Todas las configuraciones probadas\")\n",
    "print(f\"   - best_params.json                # Mejores hiperparámetros\")\n",
    "print(f\"   - optimization_summary.txt        # Resumen de optimización\")\n",
    "print(f\"   - best_model_optuna.pth           # Modelo final optimizado\")\n",
    "print(f\"   - test_metrics_optuna.json        # Métricas en test set\")\n",
    "print(f\"   - training_progress_optuna.png    # Gráfica de entrenamiento\")\n",
    "print(f\"   - confusion_matrix_optuna.png   # Matriz de confusión\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"OPTIMIZACIÓN CON OPTUNA COMPLETADA EXITOSAMENTE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxUMjAU2ttQF"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5glXtwxNttQG"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stg5s-gEttQH"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3DWVC1JttQI"
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "parkinson_env",
   "language": "python",
   "name": "parkinson_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "205d6bfdf92f4588b12caeb4e6e54f0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27a764741a964ac18443dd2703920ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68d0a70631024c37a4717d1314c469ca",
      "placeholder": "​",
      "style": "IPY_MODEL_74b1c6ed1cfa453292cd08aa592c947b",
      "value": "  0%"
     }
    },
    "2a53d2612e41418993ae265e6d1dff94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c70e176870d430fbaa3f4f159007c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fa829167c884d65abeda13720c0ec11",
      "placeholder": "​",
      "style": "IPY_MODEL_db0fe1abf27343fa8a9eb7925dd14b16",
      "value": " 1/1 [00:07&lt;00:00,  7.28s/it]"
     }
    },
    "607e690c03c64d8fa8438fcfef1cdd3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a53d2612e41418993ae265e6d1dff94",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed4a1f30fbf248fda5ceefefaae8feb2",
      "value": 1
     }
    },
    "68d0a70631024c37a4717d1314c469ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fa829167c884d65abeda13720c0ec11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "737970eb89ed45d7aaece1042d010f9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_821855eda1764ef8a621192e972602ca",
      "placeholder": "​",
      "style": "IPY_MODEL_205d6bfdf92f4588b12caeb4e6e54f0b",
      "value": " 0/30 [00:22&lt;?, ?it/s]"
     }
    },
    "74b1c6ed1cfa453292cd08aa592c947b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "821855eda1764ef8a621192e972602ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9747fbd453c4e50af39c282f787a62c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27a764741a964ac18443dd2703920ac7",
       "IPY_MODEL_be76252b9db24ba98f4322edc4829aaa",
       "IPY_MODEL_737970eb89ed45d7aaece1042d010f9f"
      ],
      "layout": "IPY_MODEL_f3f1eabf7f604a7dbdb0d80fc18b9e23"
     }
    },
    "af5af19c7b0e42898b6ffd6ef764a70e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be76252b9db24ba98f4322edc4829aaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7cdd4c9a0ee4ddcb7bfde941b5f4557",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5f1a881c85044a6a0bb294e60e0a93e",
      "value": 0
     }
    },
    "c09d2809572c4c468c55ece6e02a818c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdcf3e25d0ca4026ab39ed9ddc017a29",
      "placeholder": "​",
      "style": "IPY_MODEL_af5af19c7b0e42898b6ffd6ef764a70e",
      "value": "Best trial: 0. Best value: 0.375: 100%"
     }
    },
    "c5f1a881c85044a6a0bb294e60e0a93e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cdcf3e25d0ca4026ab39ed9ddc017a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfda79d722d744a6a03192cb625a7497": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db0fe1abf27343fa8a9eb7925dd14b16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6b38ad91a25420495c9843beb560c7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c09d2809572c4c468c55ece6e02a818c",
       "IPY_MODEL_607e690c03c64d8fa8438fcfef1cdd3c",
       "IPY_MODEL_4c70e176870d430fbaa3f4f159007c9d"
      ],
      "layout": "IPY_MODEL_cfda79d722d744a6a03192cb625a7497"
     }
    },
    "ed4a1f30fbf248fda5ceefefaae8feb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f3f1eabf7f604a7dbdb0d80fc18b9e23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7cdd4c9a0ee4ddcb7bfde941b5f4557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
